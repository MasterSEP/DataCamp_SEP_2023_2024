% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
  
\fi
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm} % pour les symboles en gras
\usepackage{mathtools} % pour des fonctionnalit√©s math√©matiques √©tendues
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={DATA Camp M1},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{DATA Camp M1}
\author{}
\date{}

\begin{document}
\maketitle


\section{Math√©matiques}\label{mathuxe9matiques}

\subsection{Alg√®bre Lin√©aire et quelques notions en M1 SEP sur les
matrices}\label{alguxe8bre-linuxe9aire-et-quelques-notions-en-m1-sep-sur-les-matrices}

\subsubsection{Trace d'une matrice}\label{trace-dune-matrice}

La \textbf{trace} d'une matrice carr√©e \(A\) est la somme de ses
√©l√©ments diagonaux : \[\text{Tr}(A) = \sum_{i=1}^{n} a_{ii}\]

Propri√©t√©s :

\begin{itemize}
\tightlist
\item
  La trace est lin√©aire :
  \[\text{Tr}(A + B) = \text{Tr}(A) + \text{Tr}(B)\]
\item
  Invariance par similitude : \[\text{Tr}(AB) = \text{Tr}(BA)\]
\end{itemize}

\subsubsection{Inverse d'une matrice}\label{inverse-dune-matrice}

Une matrice carr√© \(A\) d'ordre \(n\) est dite inversible s'il existe
\(B\) tel que : \[AB = BA = I_n\]

B est alors not√© \(A^{-1}\) l'inverse de A.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-tip-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, opacitybacktitle=0.6]

Si le d√©terminant d'une matrice \(A\) est diff√©rent de 0 alors la
matrice est inversible.

\end{tcolorbox}

\subsubsection{\texorpdfstring{Inverse d'une matrice
\((2 \times 2)\)}{Inverse d'une matrice (2 \textbackslash times 2)}}\label{inverse-dune-matrice-2-times-2}

Inverse d'une matrice \(A\in \mathcal{M}_{2 \times 2}\) de d√©terminant
non nul (\(det(A) = ad -bc \ne 0\)) :

\[A^{-1} = \left(\begin{array}{cc} a & b \\ c & d \end{array} \right)^{-1}
= \frac{1}{ad-bc}\left(\begin{array}{cc} d & -b \\ a & -c \end{array} \right)
\]

\subsubsection{Inverse d'une matrice
diagonale}\label{inverse-dune-matrice-diagonale}

Inverse d'une matrice \(A\in \mathcal{M}_{n \times n}\) de d√©terminant
non nul (\(det(A) = d_1 \times d_2 \times \cdots \times d_n \ne 0\)) :
\[D^{-1} = 
\left(\begin{array}{cccc}
d_1 & 0 & \cdots & 0 \\
0 & d_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & d_n
\end{array}  \right)^{-1}
= \left(\begin{array}{cccc}
\frac{1}{d_1} & 0 & \cdots & 0 \\
0 & \frac{1}{d_2} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & \frac{1}{d_n}
\end{array} \right)\]

\subsubsection{Espace vectoriel}\label{espace-vectoriel}

Un espace vectoriel est un ensemble de vecteurs qui peuvent √™tre
combin√©s entre eux par des op√©rations comme l'addition et la
multiplication. Ces combinaisons permettent de construire de nouveaux
vecteurs dans le m√™me ensemble. Un vecteur \(v = (v_1,...,v_d)\) n'a pas
de dimension mais admet une longueur de taille \(d\) ( = d
coefficients). Mais, il est d'usage de repr√©senter \(v\) avec sa
repr√©sentation matricielle not√©e \(V = \left(\begin{array}{c} v_1 \\
\cdots \\
v_d
\end{array}
\right)\), matrice de \(d\) lignes et une colonne. On √©crit donc
\(V = v^t\).

Soient \(v,u\) deux vecteurs d'un espace vectoriel r√©el de dimension
finie muni d'un \textbf{produit scalaire} usuel :
\[\langle v, u \rangle_2 = v_1 u_1 + v_2 u_2 + \cdots + v_n u_n\] (le
produit scalaire est associ√©e √† la norme 2
\(\langle v, v \rangle_2 = \|v\|_2^2\))

Quelques propri√©t√©s importantes du produit scalaire :

\begin{itemize}
\item
  \(\langle v, v \rangle_2 = \|v\|_2^2 = \sum_{i=1}^{n} v_i^2\)
\item
  \(\langle v, u \rangle_2 = \langle u, v \rangle_2\) (sym√©trie)
\item
  \(\langle v, u \rangle_2 > 0\) si \(x\) \ne \(0\)
\item
  \(\langle v, w \rangle_2 = v^t w = \text{trace}(vw^t)\) -
  \(\langle v, w \rangle_2 = \langle w, v \rangle_2\)
\end{itemize}

Quelques in√©galit√©s √† conna√Ætre :

\begin{itemize}
\tightlist
\item
  In√©galit√© de Cauchy-Schwarz :
  \[|\langle x, y \rangle| \leqslant \|x\| \|y\|\]
\item
  In√©galit√© triangulaire : \[\|x + y\| \leqslant \|x\| + \|y\|\]
\end{itemize}

\subsubsection{Orthogonalit√©}\label{orthogonalituxe9}

Soient \(v\) et \(w\), deux vecteurs appartenant √† un espace vectoriel
\(E\) de dimension \(n\), muni du produit scalaire
\(\langle \cdot, \cdot \rangle\).

\paragraph{Normalisation d'un vecteur}\label{normalisation-dun-vecteur}

La normalisation d'un vecteur \(v\) est donn√©e par : \[
x = \frac{v}{\|v\|_2}
\] Ainsi, \(\|v\|_2 = 1\).

Deux vecteurs \(v\) et \(u\) sont \textbf{orthogonaux} si leur produit
scalaire est nul : \[\langle v, u \rangle = 0\] et on note \(v \perp u\)

\paragraph{Matrice de projection
orthogonale}\label{matrice-de-projection-orthogonale}

Soit \(E\) un espace vectoriel muni d'un produit scalaire
\(\langle \cdot, \cdot \rangle\) et \(W\) un sous-espace vectoriel de
\(E\). La projection orthogonale d'un √©l√©ment \(B\) de \(E\) sur \(W\)
est d√©finie par : \[\Pi_W B = \underset{a \in W}{argmin} \|B - a\|_2\]
La matrice de projection orthogonale de \(E\) sur \(W\) est not√©e
\(\Pi_W\).

\subparagraph{Propri√©t√©s}\label{propriuxe9tuxe9s}

\begin{itemize}
\tightlist
\item
  \(\Pi_W^t = \Pi_W\)
\item
  \(\Pi_W^2 = \Pi_W\)
\item
  \(\text{trace}(\Pi_W) = \dim(\Pi_W)\)
\item
  \(\Pi_W^\perp = I_E - \Pi_W\)
\end{itemize}

Pour tout \(B\), √©l√©ment de \(E\) : \[\Pi_{W^\perp} B = B - \Pi_{W} B\]

\paragraph{Construction de matrice de projection
orthogonale}\label{construction-de-matrice-de-projection-orthogonale}

Une base \(E\) est un ensemble de vecteurs lin√©airement ind√©pendants qui
permet de d√©crire tous les vecteurs d'un espace (par combinaison
lin√©aire). On note alors
\(E = \text{Vect}(\mathbf{v_1}, \mathbf{v_2}, \dots, \mathbf{v_n})\).
Cette notation d√©signe l'ensemble de tous les vecteurs qui peuvent
s'√©crire comme une combinaison lin√©aire de
\(\mathbf{v_1}, \mathbf{v_2}, \dots, \mathbf{v_n}\).

Soient \(v_1, \ldots, v_p\), \(p\) vecteurs de \(\mathbb{R}^n\) avec
\(p \leqslant n\). Si \((v_1, \ldots, v_p)\) est une base orthogonale de
\(\mathbb{R}^p\) et \(\text{W} = \text{vect}(v_1, \ldots, v_p)\), alors
la matrice de projection W de \(\mathbb{R}^n\) sur W est :
\[\text{W} = V (V^t V)^{-1} V^t
\] o√π \(V\) est la matrice dont les colonnes sont les vecteurs
\(v_1, \ldots, v_p\).

Si \((v_1, \ldots, v_p)\) est une base orthonormale de W, alors : \[
\text{W} = V V^t
\]

\paragraph{Proc√©d√© d'orthogonalisation de
Gram-Schmidt}\label{procuxe9duxe9-dorthogonalisation-de-gram-schmidt}

Le but du proc√©d√© de Gram-Schmidt est de prendre un ensemble de vecteurs
lin√©airement ind√©pendants \(( {v_1, v_2, \ldots, v_n})\) et de produire
un ensemble de vecteurs orthogonaux \(( {u_1, u_2, \ldots, u_n} )\) qui
engendrent le m√™me sous-espace.

\textbf{√âtapes du Proc√©d√©}

Le premier vecteur orthogonal ( \(u_1\) ) est le premier vecteur de
l'ensemble original : \[u_1 = v_1\]

Pour chaque vecteur \(( v_k )\) (o√π \$ k \geq 2 \$), on soustrait les
projections orthogonales de \(( v_k )\) sur les vecteurs orthogonaux
pr√©c√©demment calcul√©s \(( u_1, u_2, \ldots, u_{k-1})\) :
\[ u_k = v_k - \sum_{j=1}^{k-1} \frac{\langle v_k, u_j \rangle}{\langle u_j, u_j \rangle} u_j \]

Si l'on souhaite obtenir une base orthonormale, chaque vecteur
\(( u_k )\) est normalis√© pour obtenir \(( e_k )\) :
\[ e_k = \frac{u_k}{||u_k||} \]

\subsubsection{Base duale}\label{base-duale}

Pour une base \(\{e_1, e_2, \ldots, e_n\}\) d'un espace vectoriel \(E\),
la \textbf{base duale} \((e^1, e^2, \ldots, e^n)\) est d√©finie par :
\[e^i(e_j) = \delta_{ij}\] o√π \(\delta_{ij}\) est le symbole de
Kronecker.

La base duale permet de d√©finir des formes lin√©aires et de travailler
avec des espaces vectoriels de mani√®re plus abstraite.

Pour plus d'informations sur la base duale cliquez
\href{https://www.math.univ-paris13.fr/~schwartz/L2/dual.pdf}{\textbf{ici}}

\subsubsection{Diagonalisation d'une
matrice}\label{diagonalisation-dune-matrice}

Une matrice carr√©e \(A\) est dite \textbf{diagonalisable} s'il existe
une matrice diagonale \(D\) et une matrice inversible \(P\) telles que :
\[A = PDP^{-1}\] \(D\) est une matrice diagonale contenant les valeurs
propres de \(A\) et \(P\) est form√© de vecteurs propres dans l'ordre des
valeurs propres mis dans \(D\).

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-tip-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, opacitybacktitle=0.6]

Si les vecteurs propres sont normalis√©s alors \(P^{-1} = P^t\) et
\(A = PDP^t\).

\end{tcolorbox}

\paragraph{Diagonalisation d'une matrice sym√©trique
r√©elle}\label{diagonalisation-dune-matrice-symuxe9trique-ruxe9elle}

Pour les matrices sym√©triques r√©elles, on peut toujours trouver une base
orthonormale de vecteurs propres, ce qui permet de les diagonaliser par
une matrice orthogonale \(Q\) : \[A = QDQ^T\]

\subsection{Probabilit√©s}\label{probabilituxe9s}

\subsubsection{Qu'est-ce qui caract√©rise une variable al√©atoire
?}\label{quest-ce-qui-caractuxe9rise-une-variable-aluxe9atoire}

En th√©orie, on repr√©sente la moyenne comme l'esp√©rance : Dans le cas
discret : \[E(X) = \sum k \cdot P(X = k)\] \[k \in X(\Omega)\] Alors que
dans le cas continu : \[E(X) = \int x \cdot f_X(x) \, dx\]
\[x \in X(\Omega)\]

\paragraph{Fonction de r√©partition}\label{fonction-de-ruxe9partition}

La fonction de r√©partition est d√©finie par :
\[F_X(x) = P(X \leqslant x)\]

Pour tout \(x\), \(0 \leqslant F_X(x) \leqslant 1\), \(F_X\) est une
fonction croissante. De plus, \(\lim_{x \to -\infty} F_X(x) = 0\) et
\(\lim_{x \to \infty} F_X(x) = 1\)

\begin{center}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images/fonction_repartition.png}
\end{center}

\paragraph{Loi marginale}\label{loi-marginale}

La loi marginale de X est d√©finie comme suit :
\[f_X(x) = \int f_{X, Y}(x, y) \, dy, \text{ o√π } -\infty < x < \infty,\]
dans le cas continu, ou encore :
\[f_X(x_i) = \sum p_{ij}, \text{ o√π } j \text{ tel que } y_j \leqslant y\]

Si X et Y sont ind√©pendants, alors :
\[f_{X, Y}(x, y) = f_X(x) \cdot f_Y(y)\] \newpage

\subsubsection{Savoir-faire de
probabilit√©s}\label{savoir-faire-de-probabilituxe9s}

\paragraph{Centrage et r√©duction}\label{centrage-et-ruxe9duction}

Le centrage consiste √† localiser la distribution autour de l'origine et
la r√©duction consiste √† normaliser la dispersion. On cr√©e une nouvelle
variable al√©atoire \(Y\) issu de \(X\) dont l'esp√©rance est null et la
variable est √©gale √† 1. \[Y = \frac{X - E(X)}{\sqrt{\sigma(X)^2}}\] o√π
\(E(X)\) repr√©sente l'esp√©rance de X et \(\sigma^2\) est la variance de
\(X\).

\paragraph{Moments d'ordre r}\label{moments-dordre-r}

Le moment d'ordre r est d√©fini par : \[\mu_r = E(X^r)\] Le moment centr√©
d'ordre r est d√©fini par : \[\muÃÉ_r = E((X - E(X))^r)\]

\paragraph{Couples al√©atoires}\label{couples-aluxe9atoires}

\subparagraph{Fonction de r√©partition et
densit√©}\label{fonction-de-ruxe9partition-et-densituxe9}

La fonction conjointe est appel√©e la distribution conjointe de X et Y.
\[F_{X, Y}(x, y) = P(X \leqslant x \cap Y \leqslant y)\]

Dans le cas continu, la fonction d√©finie par :
\[f_{X, Y}(x, y) = \frac{\partial^2 F_{X, Y}(x, y)}{\partial x \partial y}\]
est la densit√© conjointe du couple (X, Y). On a donc :
\[F_{X, Y}(x, y) = \int \int f_{X, Y}(t, u) \, dt \, du, \text{ o√π } -\infty < x, y < +\infty,\]

Dans le cas discret, on d√©finit la fonction de probabilit√© conjointe :
\[P(X = x_i, Y = y_j) = p_{ij}\] On a donc :
\[F_{X, Y}(x, y) = \sum \sum p_{ij}, \text{ o√π } x_i \leqslant x \text{ et } y_j \leqslant y\]

\subparagraph{Covariance}\label{covariance}

La covariance mesure l'intensit√© de la relation lin√©aire entre deux
variables al√©atoires X et Y. Elle est d√©finie comme suit :
\[Cov(X, Y) = E(XY) - E(X) \cdot E(Y)\]

Si X et Y sont ind√©pendants, alors : \[Cov(X, Y) = 0\]

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-warning-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, opacitybacktitle=0.6]

Il est important de noter que la r√©ciproque n'est pas vraie : la
covariance n'implique pas n√©cessairement l'ind√©pendance entre X et Y.

\end{tcolorbox}

\newpage

\subsubsection{Propri√©t√©s √† conna√Ætre de l'esp√©rance, variance et
covariance}\label{propriuxe9tuxe9s-uxe0-connauxeetre-de-lespuxe9rance-variance-et-covariance}

\textbf{Esp√©rance} \[
\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y)
\]

\[
\mathbb{E}(a) = a
\] \textbf{Variance}

\[
\text{Var}(aX) = a^2\text{Var}(X)
\] \[
\text{Var}(a) = 0
\] \[
\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X,Y)
\]

\[ \text{Si } X \coprod Y \text{ alors } \text{Var}(X+Y) = \text{Var}(X) + \text{Var}(Y)\]

\textbf{Covariance} \[
\text{Cov}(X, Y) = \text{Cov}(Y, X)
\]

\[
\text{Cov}(aX + bY, cU + dV) = ac\text{Cov}(X, U) + ad\text{Cov}(X, V) + bc\text{Cov}(Y, U) + bd\text{Cov}(Y, V)
\]

\newpage

\subsubsection{Vecteurs al√©atoires}\label{vecteurs-aluxe9atoires}

L'esp√©rance d'un vecteur al√©atoire \(X = (X_1, X_2, \vdots, X_n)^t\) de
X est le vecteur des esp√©rances de \(X_i\) c'est-√†-dire
\(\mathbb{E}(X) = \left(\begin{array}{c} E(X_1) \\ \ldots \\ \mathbb{E}(X_n) \end{array} \right)\).

L'esp√©rance reste lin√©aire, en particulier pour \(X\) et \(Y\)
appartenant √† \(R^n\) on a :

\[\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y) \text{ o√π } a,b \in \mathbb{R}\]
\[\mathbb{E}(AX + B) = A\mathbb{E}(X)+B\]

La variance-covariance de X not√©e \(\Sigma\) une matrice \(n \times n\)
o√π chaque √©l√©ment \(\Sigma_{ij}\) repr√©sente la covariance entre les
variables al√©atoires \(X_i\) et \(X_j\). Les √©l√©ments diagonaux de
\(\Sigma\) correspondent aux variances des composantes \(X_i\), tandis
que les √©l√©ments hors-diagonaux repr√©sentent les covariances entre les
diff√©rentes composantes de \(X\). La matrice \(\Sigma\) est donc d√©finie
comme suit :

\[
\Sigma = \begin{pmatrix}
\text{Var}(X_1) & \text{Cov}(X_1, X_2) & \dots & \text{Cov}(X_1, X_n) \\
\text{Cov}(X_2, X_1) & \text{Var}(X_2) & \dots & \text{Cov}(X_2, X_n) \\
\vdots & \vdots & \ddots & \vdots \\
\text{Cov}(X_n, X_1) & \text{Cov}(X_n, X_2) & \dots & \text{Var}(X_n)
\end{pmatrix}
\] \[ \Sigma_{AX + B} = A\Sigma_X(X)A^t\] o√π \(\Sigma\) est la variance
de X et A,B sont des matrices (deterministe)

\subsubsection{Lois usuelles}\label{lois-usuelles}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-tip-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, opacitybacktitle=0.6]

Les variables \(X_1, \ldots, X_n\) sont ind√©pendantes et identiquement
distribu√©es (i.i.d.) si et seulement si :

Dans le cas discret :
\[P(X_1 = x_1, \ldots, X_n = x_n) = P(X_1 = x_1) \times \ldots \times P(X_n = x_n)\]

Dans le cas continu :

\[P(X_1 \leq x_1, X_2 \leq x_2, \ldots, X_n \leq x_n) = P(X_1 \leq x_1) \cdot P(X_2 \leq x_2) \cdots P(X_n \leq x_n)\]

\end{tcolorbox}

Ces tableaux r√©capitulent les lois usuelles que vous pourrez rencontrer
dans diff√©rents cours du master.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0889}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2444}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1556}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.2148}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1481}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Nom
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(X(\Omega)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(P(X = k)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(E[X]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(Var(X)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniforme & \(X \sim U(\{1, 2, \ldots, n\})\) & \(\{1, 2, \ldots, n\}\) &
\(\frac{1}{n}\) & \(\frac{n+1}{2}\) & \(\frac{n^2-1}{12}\) \\
Bernouilli & \(X \sim B(p), 0 < p < 1\) & \(\{0, 1\}\) &
\(P(X = 1) = p\) & \(p\) & \(p(1-p)\) \\
& & & \(P(X = 0) = 1 - p\) & & \\
Binomiale & \(X \sim B(n, p), 0 < p < 1\) & \(\{1, 2, \ldots, n\}\) &
\(C_k^n p^k (1 - p)^{n-k}\) & \(np\) & \(np(1-p)\) \\
G√©om√©trique & \(X \sim G(p), 0 < p < 1\) & \(\mathbb{N}^{*}\) &
\(p(1-p)^{k}\) & \(\frac{1-p}{p}\) & \(\frac{1-p}{p^2}\) \\
Poisson & \(X \sim P(\lambda), \lambda > 0\) & \(\mathbb{N}\) &
\(\frac{\lambda^k}{k!}e^{-\lambda}\) & \(\lambda\) & \(\lambda\) \\
\end{longtable}

\section{Tableau des lois de
probabilit√©}\label{tableau-des-lois-de-probabilituxe9}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0850}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1741}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.0688}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.3644}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1417}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1660}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Nom
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notation
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(X(\Omega)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(f_X(x)\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(E[X]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(V(X)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniforme & \(X \sim U([a, b]), a < b\) & \([a, b]\) &
\(\frac{1}{b - a}1_{[a, b]}(x)\) & \(\frac{a + b}{2}\) &
\(\frac{(a - b)^2}{12}\) \\
Exponentielle & \(X \sim \mathcal{E}(\lambda), \lambda > 0\) &
\(\mathbb{R}^+\) & \(\lambda e^{-\lambda x}1_{\mathbb{R}^+}(x)\) &
\(\frac{1}{\lambda}\) & \(\frac{1}{\lambda^2}\) \\
& \(\mathcal{E}(\lambda) = \gamma(1, \lambda)\) & & & & \\
Normale ou Gaussienne & \(X \sim N(m, \sigma^2), \sigma > 0\) &
\(\mathbb{R}\) &
\(\frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(x - m)^2}{2\sigma^2}\right)\)
& \(m\) & \(\sigma^2\) \\
Gamma & \(X \sim \gamma(\alpha, \theta), \alpha > 0, \theta > 0\) &
\(\mathbb{R}^+\) &
\(\frac{\theta^\alpha}{\Gamma(\alpha)}x^{\alpha - 1}e^{-\theta x}1_{\mathbb{R}^+}(x)\)
& \(\frac{\alpha}{\theta}\) & \(\frac{\alpha}{\theta^2}\) \\
& \(\Gamma(\alpha) = \int_0^\infty e^{-x}x^{\alpha-1} \, dx\) & & & & \\
Khi-2 & \(X \sim \chi^2(n), n \in \mathbb{N}^+\) & \(\mathbb{R}^+\) &
\(\gamma\left(\frac{n}{2}, \frac{1}{2}\right)\) & \(n\) & \(2n\) \\
& \(Y_1, Y_2, \ldots, Y_n \text{ i.i.d},\) & & & & \\
& \(Y_i \sim \mathcal{N}(0, 1), \quad X = \sum_{i=1}^{n} Y_i^2\) & & &
& \\
B√™ta & \(X \sim B(\alpha, \theta), \alpha > 0, \theta > 0\) & \([0, 1]\)
&
\(\frac{x^{\alpha-1}(1-x)^{\theta-1}}{B(\alpha, \theta)}1_{[0, 1]}(x)\)
& \(\frac{\alpha}{\alpha+\theta}\) &
\(\frac{\alpha\theta}{(\alpha+\theta)^2(\alpha+\theta+1)}\) \\
& \(B(\alpha, \theta) = \int_0^1 x^{\alpha-1}(1-x)^{\theta-1} \, dx\) &
& & & \\
& \(X = \frac{Z}{1 + Z}, \quad Z \sim B'(\alpha, \theta)\) & & & & \\
B√™ta (prime) & \(Z ‚àº B'(\alpha, \theta), \alpha > 0, \theta > 0\) &
\(\mathbb{R}^+\) &
\(\frac{z^{\alpha-1}}{B(\alpha,\theta) \cdot (1+z)^{\alpha+\theta}} \cdot 1_{\mathbb{R}^+}(z)\)
& \(\frac{\alpha}{\theta - 1}\) &
\(\frac{\alpha(\alpha+\theta-1)}{(\theta-1)^2(\theta-2)}\) \\
&
\(X \sim \gamma(\alpha, 1), Y \sim \gamma(\theta, 1), X \perp\!\!\!\perp Y\)
& & & \(\theta > 1\) & \(\theta > 2\) \\
Student T & \(T \sim T(n), n \in \mathbb{N}^*\) & \(\mathbb{R}\) &
\(\frac{\left(1 + \frac{t^2}{n}\right)^{-(n+\frac{1}{2})}}{\sqrt{n}\cdot B(\frac{1}{2},\frac{n}{2})}\)
& \(0\) & \(\frac{n}{n - 2}\) \\
& \(T = \frac{X}{\sqrt{Y/n}}, \quad T^2/n \sim B'(1/2, n/2)\) & & & &
\(n > 2\) \\
Fisher & \(X \sim F(n, m)\) & \(\mathbb{R}^+\) &
\(\frac{Kx^{n/2-1}}{(m+nx)^{(n+m)/2}}1_{\mathbb{R}^+}(x)\) &
\(\frac{m}{m-2}\) & \(\frac{2m^2(n+m-2)}{n(m-2)^2(m-4)}\) \\
& \(N \sim \chi^2(n), M \sim \chi^2(m), N \perp\!\!\!\perp M\) & & &
\(m > 2\) & \(m > 4\) \\
\end{longtable}

\newpage

Conna√Ætre les densit√©s ne servirait pas √† grand chose, mais ceci nous
√©vitera de parler de lois dont nous ne connaissons pas leur
construction.

\newpage

\subsubsection{Notions de convergence}\label{notions-de-convergence}

Si l'on pense √† des donn√©es, vues comme r√©alisation de variables
al√©atoires \(X_1, \ldots, X_n\), il serait int√©ressant de se poser la
question de savoir comment √©volue cette suite lorsque \(n\) tend vers
l'infini.

On dit que \((X_n)\) converge presque s√ªrement vers \(X\) et on note
\(X_n \underset{n \rightarrow \infty}{\xrightarrow{\text{p.s.}}}{} X\)
si et seulement si :
\(P\left(\underset{n\to+\infty}{\lim} X_n = X\right) = 1\)

On dit que \((X_n)\) converge en probabilit√© vers \(X\) et on note
\(X_n \underset{n \rightarrow \infty}{\xrightarrow{\text{p}}} X\) si et
seulement si :
\(\forall \varepsilon > 0, \quad P(|X_n - X| > \varepsilon) \rightarrow 0\)

On dit que \((X_n)\) converge en loi vers \(X\) et on note
\(X_n \xrightarrow{\mathcal{L}} X\) si et seulement si :
\(F_{X_n} \underset{n \to +\infty}{\rightarrow} F_X\) O√π \(F_X\) d√©note
la fonction de r√©partition de \(X\).

On dit que \((X_n)\) converge en moyenne quadratique vers \(X\) et on
note \(X_n \underset{n \rightarrow \infty}{\xrightarrow{m.q.}}X\) si et
seulement si : \(\mathbb{E}((X_n - X)^2) \rightarrow 0\)

\begin{center}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images/convergence.png}
\end{center}

\subsubsection{Loi faible des grands
nombres}\label{loi-faible-des-grands-nombres}

Soit \(X_1, \ldots, X_n\) une suite de variables al√©atoires
ind√©pendantes et de m√™me loi telles que : \(\mathbb{E}(X_i) = \mu\) et
\(\text{Var}(X_i) = \sigma^2\) alors :\\
\[\frac{1}{n} \sum_{i=1}^{n} X_i \xrightarrow{P} \mu \]

Soit \(Z_1,\ldots, Z_n\) une suite de vecteurs al√©atoires o√π \(Z_i\) est
un vecteur al√©atoire √† p dimensions :
\[Z_i = \begin{pmatrix} Z_{i1} \\ Z_{i2} \\ \vdots \\ Z_{ip} \end{pmatrix}\]

On suppose que les vecteurs \(Z_1, Z_2, \dots, Z_n\) sont i.i.d. , avec
une esp√©rance \(\mathbb{E}[Z_i] = \mu\), o√π \(\mu\) est un vecteur
constant de dimension \(p\) et chaque composante \(Z_{ij}\) a une
variance finie.
\[\mu = \begin{pmatrix} \mu_1 \\ \mu_2 \\ \vdots \\ \mu_p \end{pmatrix}\]

Alors, la \textbf{moyenne empirique} \(\bar{Z}_n\) converge en
\textbf{probabilit√©} vers l'esp√©rance \(\mu\) lorsque \(n \to \infty\) :

\[\bar{Z}_n  = \frac{1}{n} \sum_{i=1}^{n} Z_i = \begin{pmatrix} \frac{1}{n} \sum_{i=1}^{n} Z_{i1} \\ \frac{1}{n} \sum_{i=1}^{n} Z_{i2} \\ \vdots \\ \frac{1}{n} \sum_{i=1}^{n} Z_{ip} \end{pmatrix} \xrightarrow{P} \mu \quad \text{lorsque} \quad n \to \infty\]

\subsubsection{Th√©or√®me central
limite}\label{thuxe9oruxe8me-central-limite}

Soit \(X_1, \ldots, X_n\) une suite de variables al√©atoires
ind√©pendantes et de m√™me loi telles que : \(\mathbb{E}(X_i) = \mu\) et
\(\text{Var}(X_i) = \sigma^2\), alors :
\[\sqrt{n}\frac{\overline{X}_n - \mu}{\sigma} \xrightarrow{\mathcal{Loi}} \mathcal{N}(0, 1)\]

Soit \(Z_1,\ldots, Z_n\) une suite de vecteurs al√©atoires o√π \(Z_i\) est
un vecteur al√©atoire √† p dimensions et si les vecteurs al√©atoires
suivent les m√™mes hypoth√®ses que pr√©cedement alors
\[\Sigma_X^{-\frac{1}{2}}(\bar{Z}_n-\mathbb{E}(Z) )\xrightarrow{\mathcal{Loi}} \mathcal{N}_d(0, 1)\]

\newpage

\subsection{Statistique
inf√©rentielle}\label{statistique-infuxe9rentielle}

\subsubsection{Echantillon / Estimateur}\label{echantillon-estimateur}

Le point de d√©part est un vecteur (ou un tableau dans le cas
multidimensionnel) de donn√©es. Ces donn√©es peuvent √™tre vues comme les
r√©alisations \((x_1, x_2, \ldots, x_n)\) d'une variable al√©atoire \(X\)
qui d√©pend d'un certain param√®tre \(\theta\) que nous allons chercher √†
estimer. Pour ce faire, nous allons construire un √©chantillon de cette
variable. Un √©chantillon \((X_1, X_2, \ldots, X_n)\) est un n-uplet de
variables al√©atoires ind√©pendantes qui suivent toutes la m√™me loi (celle
de \(X\)). Un estimateur de \(\theta\) est une fonction
\(\hat{\theta} = f(X_1, X_2, \ldots, X_n)\) de notre √©chantillon, qui
poss√®de une loi de probabilit√©. Lorsque l'al√©a est r√©alis√©,
\(\hat{\theta}(\omega) = f(x_1, x_2, \ldots, x_n)\) est une estimation
de \(\theta\). Le but de ce cours est de construire le meilleur
estimateur possible de \(\theta\).

\subsubsection{Estimateur sans biais}\label{estimateur-sans-biais}

Pour que l'estimation soit bonne, il faut que \(\hat{\theta}\) soit
proche de \(\theta\). Comme \(\hat{\theta} = f(X_1, X_2, \ldots, X_n)\)
est une variable al√©atoire, on ne peut imposer de condition qu'√† sa
valeur moyenne.

On d√©finit ainsi le biais :
\[b_n(\hat{\theta}, \theta) = \mathbb{E}(\hat{\theta}_n) - \theta\]

Un estimateur est dit sans biais si \(b_n(\hat{\theta}, \theta) = 0\),
c'est-√†-dire : \[\mathbb{E}(\hat{\theta}_n) = \theta\]

Le plus souvent, on veut estimer la moyenne et la variance.

\paragraph{Estimations de la moyenne}\label{estimations-de-la-moyenne}

Soit un √©chantillon de variables al√©atoires \(X_1, X_2, \dots, X_n\)
tir√©es d'une population avec une moyenne \(\mu = \mathbb{E}[X_i]\).

La moyenne empirique (ou moyenne d'√©chantillon) est d√©finie par :

\[
\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} X_i
\]

L'esp√©rance de cet estimateur est :

\[
\mathbb{E}[\hat{\mu}] = \mathbb{E}\left[\frac{1}{n} \sum_{i=1}^{n} X_i\right] = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}[X_i] = \mu
\]

La moyenne empirique est donc \textbf{non biais√©e}. Son esp√©rance est
√©gale √† la vraie moyenne de la population.

\paragraph{Estimation de la variance}\label{estimation-de-la-variance}

Soit \(X_1, X_2, \dots, X_n\) un √©chantillon de variables al√©atoires
\(X_i\) avec une variance \(\sigma^2 = \mathbb{V}[X_i]\).

L'estimateur classique de la variance bas√© sur l'√©chantillon est :

\[
\hat{\sigma}^2_{\text{biais√©}} = \frac{1}{n} \sum_{i=1}^{n} (X_i - \hat{\mu})^2
\]

Cependant, cet estimateur est \textbf{biais√©}. En effet, l'esp√©rance de
cet estimateur n'est pas √©gale √† \(\sigma^2\) :

\[
\mathbb{E}[\hat{\sigma}^2_{\text{biais√©}}] = \frac{n-1}{n} \sigma^2
\]

Pour corriger ce biais, on peut utiliser un estimateur non biais√© de la
variance. Cela se fait en divisant la somme des carr√©s par \(n - 1\) au
lieu de \(n\). Ainsi, l'estimateur non biais√© de la variance est :

\[
\hat{\sigma}^2_{\text{non biais√©}} = \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \hat{\mu})^2
\]

Cet estimateur est non biais√©, et l'esp√©rance de
\(\hat{\sigma}^2_{\text{non biais√©}}\) est √©gale √† la vraie variance de
la population :

\[
\mathbb{E}[\hat{\sigma}^2_{\text{non biais√©}}] = \sigma^2
\]

\subsubsection{Estimateur convergent}\label{estimateur-convergent}

Un estimateur est dit convergent s'il converge en probabilit√© vers le
param√®tre √† estimer : \[\hat{\theta}_n \xrightarrow{P} \theta\]

En pratique, tout estimateur sans biais et dont la variance tend vers 0
est convergent.

\subsubsection{Estimateur optimal}\label{estimateur-optimal}

La qualit√© d'un estimateur est mesur√©e √† travers son erreur quadratique
moyenne d√©finie par :
\[EQM(\hat{\theta}_n) = (b_n(\hat{\theta}, \theta))^2 + V(\hat{\theta}_n)\]
Comme nous cherchons tout le temps (presque) des estimateurs sans biais,
il reste √† comparer les variances.

Un estimateur ùúÉÃÇ1 est meilleur que ùúÉÃÇ2 si :
\[V(\hat{\theta}_1) < V(\hat{\theta}_2)\]

\textcolor{green!70!black}{In√©galit√© de Rao-Cramer/ Efficacit√©}

On d√©finit la quantit√© d'information apport√©e par l'estimateur par : \[
I(\hat{\theta}_n) = -\left( \mathbb{E} \left( \frac{\partial L}{\partial \theta} \right) \right)^2
\] O√π ùêø(ùë•, ùúÉ) = ‚àè ùëì(ùë•ùëñ) (nous reviendrons sur sa d√©finition)

L'in√©galit√© de Rao-Cramer postule que la variance d'un estimateur ne
peut pas aller en del√† d'un certain seuil :
\[V(\hat{\theta}_n) \geqslant \frac{1}{I(\hat{\theta}_n)}\] Un
estimateur est optimal (ou efficace) si sa variance v√©rifie le cas
d'√©galit√©.

\newpage

\subsubsection{Construction d'un
estimateur}\label{construction-dun-estimateur}

Un estimateur est une valeur qu'on ne peut pas obtenir en th√©orie donc
on essaye de l'estimer. Par exemple, on ne peut pas calculer l'esp√©rence
d'une s√©rie de donn√©es et donc pour essayer d'obtenir une valeur on
calculer une estimation. On recours √† plusieurs estimateurs tels que le
maximum de vraisemblance ou bien la m√©thode des moments.

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-note-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, opacitybacktitle=0.6]

La m√©thode du maximum de vraisemblance est la plus souvent utilis√© dans
les mod√®les de pr√©diction.

\end{tcolorbox}

La m√©thode du maximum de vraisemblance consiste √† affecter \(ùúÉ\) la
valeur qui maximise la probabilit√© d'observer \((ùë•_1, ùë•_2, ‚Ä¶ , ùë•_ùëõ)\)
lorsque l'al√©a du vecteur \((ùëã_1, ùëã_2, ‚Ä¶ , ùëã_ùëõ)\) tombe. Sans trop
rentrer dans la th√©orie de la vraisemblance, nous allons pr√©senter un
algorithme en cinq √©tapes pour calculer cet estimateur :

\textbf{Etape 1} : Calculer la fonction de vraisemblance

Dans le cas continu : \[L(\mathbf{x}, \theta) = \prod_{i=1}^{n} f(x_i)\]

Dans le cas discret :
\[L(\mathbf{x}, \theta) = \prod_{i=1}^{n} P(X_i = x_i)\]

\textbf{Etape 2} : Calculer le log-vraisemblance Il s'agit de calculer
un maximum, ce qui revient √† d√©river. Il s'agit ici d'un produit de n
facteurs, ce qui rend la d√©rivation assez coriace. La fonction
logarithmique pr√©sente des propri√©t√©s assez sympas pour faciliter cette
t√¢che.

\textbf{Etape 3} : Calculer la d√©riv√©e de la log-vraisemblance

\textbf{Etape 4} : R√©soudre l'√©quation d'inconnue \(ùúΩ\)\}
\[\frac{\partial (\ln(L))}{\partial \theta} = 0 \Rightarrow \theta = \theta_0\]

\textbf{Etape 5}: V√©rifier qu'il s'agit d'un maximum.

En s'assurant que :
\[\frac{\partial^2 (\ln(L))}{\partial \theta^2} < 0\]

\newpage

La m√©thode des moments consiste √† √©galiser les moments th√©oriques
(esp√©rance, variance) √† leurs √©quivalents empiriques et √† en d√©gager une
estimation ponctuelle.

En pratique, il faut r√©soudre l'(les) √©quation(s) :
\[\mathbb{E}(X) = \overline{X} \text{ et } \text{Var}(X) = S_n^2\] avec
: \[\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i \hspace{2cm}
 S_n^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \overline{X})^2\]

Il existe une autre m√©thode d'estimateurs qu'est la m√©thode des moindres
carr√©s ordinaires.

Lorsqu'il s'agit de prendre une mesure ùúÉ avec un appareil dot√© d'une
impr√©cision \(ùúÄ\), alors le probl√®me d'estimation peut s'√©crire :
\(ùëã = ùúÉ + ùúÄ\). La m√©thode des moindres-carr√©s ordinaires consiste √†
trouver le param√®tre \(ùúÉ\) qui minimise la somme des carr√©es des erreurs
:
\[ùúÉ_{ùëÄùê∂ùëÇ} = \arg\min \left( \sum_{i=0}^n \varepsilon_i^2 \right) = \arg\min \left( \sum_{i=0}^n (X_i - \theta)^2 \right)\]

\subsubsection{Intervalles de confiance}\label{intervalles-de-confiance}

Un intervalle de confiance {[}\(A\), \(B\){]} de niveau \(1 - \alpha\)
est un intervalle al√©atoire qui a la probabilit√© \(1 - \alpha\) de
contenir le param√®tre √† estimer \(\theta\). Formellement, on √©crit :
\(P (t_1 (\theta) \leqslant f(X_1, \ldots, X_n) \leqslant t_2 (\theta)) = P(A \leqslant \theta \leqslant B) = 1 - \alpha\)

\newpage

\subsubsection{Test d'hypoth√®ses}\label{test-dhypothuxe8ses}

Dans le cadre d'un test d'hypoth√®se, nous cherchons √† faire valoir une
hypoth√®se en d√©pit d'une autre, qui lui est contradictoire.

On appellera la premi√®re (celle dont le rejet √† tort sera le plus
pr√©judiciable) ¬´ Hypoth√®se nulle ¬ª et la deuxi√®me ¬´ Hypoth√®se
alternative ¬ª.

\begin{center}
\includegraphics[width=0.5\linewidth,height=\textheight,keepaspectratio]{images/test_hypo.png}
\end{center}

Les calculs qui se cachent derri√®re le choix de l'hypoth√®se √† garder
sont compliqu√©s. Mais BONNE NOUVELLE, la machine fera tour √† notre
place. Il suffit juste de suivre correctement la m√©thode :

\textbf{Etape 1} : Choisir judicieusement les hypoth√®ses √† √©valuer et
fixer le risque \(ùõº\)\\
\textbf{Etape 2} : Choisir le test adapt√© √† la proc√©dure\\
\textbf{Etape 3} : Rentrer la commande correspondante sur R et
ex√©cuter\\
\textbf{Etape 4}: Lire dans les sorties la p-value. si elle est
sup√©rieure √† Œ± on \textbf{conserve} l'hypoth√®se nulle H0. Si elle lui
est inf√©rieure, on \textbf{rejette} H0 et on \textbf{accepte}
l'hypoth√®se alternative H1.

\newpage

\subsubsection{Construction d'intervalles de
confiance}\label{construction-dintervalles-de-confiance}

Les intervalles de confiance sont des outils essentiels en statistique
pour estimer des param√®tres inconnus tout en mesurant l'incertitude
associ√©e √† cette estimation. Ci-dessous, vous trouverez un tableau
pr√©sentant la construction des intervalles de confiance pour diff√©rents
param√®tres.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{images/intervalles_conf.png}
\end{figure}

\subsection{Statistiques descriptives
univari√©es}\label{statistiques-descriptives-univariuxe9es}

\begin{itemize}
\item
  La \textbf{moyenne arithm√©tique} d'une s√©rie de valeurs
  \(x_1, x_2, \ldots, x_n\) est donn√©e par :
  \[\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i\]
\item
  La \textbf{m√©diane} est la valeur qui s√©pare la s√©rie en deux parties
  √©gales. Pour une s√©rie ordonn√©e, si \(n\) est impair, la m√©diane est
  la valeur centrale. Si \(n\) est pair, c'est la moyenne des deux
  valeurs centrales.
\item
  La \textbf{variance} est une mesure de la dispersion des valeurs
  autour de la moyenne :
  \[\sigma_x^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2\]
\item
  L'\textbf{√©cart-type} est la racine carr√©e de la variance :
  \[\sigma = \sqrt{\sigma_x^2}\]
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, opacityback=0, toptitle=1mm, bottomtitle=1mm, rightrule=.15mm, colframe=quarto-callout-note-color-frame, leftrule=.75mm, titlerule=0mm, breakable, bottomrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, coltitle=black, arc=.35mm, left=2mm, colback=white, toprule=.15mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, opacitybacktitle=0.6]

Plus l'√©cart-type est grand, plus les donn√©es sont dispers√©es autour de
la moyenne.

\end{tcolorbox}

Les statistiques descriptives univari√©es sont essentielles pour r√©sumer
et comprendre les caract√©ristiques principales d'une seule variable.
Elles sont largement utilis√©es en analyse de donn√©es pour obtenir une
vue d'ensemble rapide et efficace. Elles permettent aussi d'identifier
rapidement des valeurs extr√™mes.

\subsection{Statistiques descriptives
bivari√©es}\label{statistiques-descriptives-bivariuxe9es}

\subsubsection{D√©finitions}\label{duxe9finitions}

\begin{itemize}
\item
  Les nuages de points (ou diagrammes de dispersion) sont une m√©thode
  graphique utilis√©e pour observer la relation entre deux variables
  quantitatives. Chaque point du graphique repr√©sente une paire de
  valeurs \((x,y)\) pour ces deux variables. Ce type de graphique permet
  de visualiser des tendances, des corr√©lations (positives, n√©gatives ou
  nulles), ainsi que la pr√©sence d'√©ventuelles anomalies ou valeurs
  aberrantes. Si les points semblent s'aligner le long d'une ligne
  droite, cela peut indiquer une relation lin√©aire entre les deux
  variables.
\item
  Les boxplots (ou bo√Ætes √† moustaches) sont un autre outil graphique,
  souvent utilis√© pour repr√©senter la distribution d'une variable
  quantitative en fonction d'une variable qualitative. Ils montrent la
  m√©diane, les quartiles, ainsi que les valeurs extr√™mes ou aberrantes
  d'un jeu de donn√©es. Dans un boxplot, la bo√Æte repr√©sente l'intervalle
  interquartile (de Q1 √† Q3), la ligne m√©diane √† l'int√©rieur de la bo√Æte
  repr√©sente la m√©diane de la distribution, et les moustaches s'√©tendent
  jusqu'aux valeurs non aberrantes les plus extr√™mes. Ces graphiques
  sont utiles pour comparer rapidement la dispersion et la sym√©trie des
  distributions entre diff√©rentes cat√©gories d'une variable qualitative.
\end{itemize}

\section{Economie}\label{economie}

\subsection{Concepts de base}\label{concepts-de-base}

\subsubsection{Macro√©conomie}\label{macrouxe9conomie}

\begin{center}
\includegraphics[width=0.76042in,height=\textheight,keepaspectratio]{images/macroeconomics.png}
\end{center}

La macro√©conomie est l'√©tude √©conomique d'un syst√®me ou de ph√©nom√®nes √†
un niveau global de l'√©conomie.

\subsubsection{Micro√©conomie}\label{microuxe9conomie}

La micro√©conomie se concentre sur l'observation et l'analyse des
interactions √† petite √©chelle.

\subsubsection{Bien √©conomique}\label{bien-uxe9conomique}

``Chose utile √† satisfaire un besoin, il faut que le bien soit
disponible et en quantit√© limit√©e.

Un bien non √©conomique est un bien qui s'obtient gratuitement, comme
l'oxyg√®ne, contrairement √† un bien √©conomique qui s'obtient en payant.''

\subsubsection{Agent √©conomique}\label{agent-uxe9conomique}

``Un agent √©conomique est un individu ou un groupe d'individus
constituant un centre de d√©cision √©conomique ind√©pendant.''

\subsubsection{March√©}\label{marchuxe9}

\begin{center}
\includegraphics[width=0.76042in,height=\textheight,keepaspectratio]{images/economie-circulaire.png}
\end{center}

``Le march√© c'est une institution sociale qui permet l'√©change entre
l'offre et la demande.''

\subsubsection{Asym√©trie d'information}\label{asymuxe9trie-dinformation}

``L'asym√©trie d'information concerne les situations o√π les agents d'un
march√© ne poss√®dent pas de la m√™me information sur un produit que ce
soit au sujet de ses qualit√©s ou de ses d√©fauts''

\subsubsection{Externalit√©}\label{externalituxe9}

L'externalit√© d√©signe la cons√©quence (positive ou n√©gative) d'une
activit√© d'un agent √©conomique sur un autre, sans qu'aucun des deux ne
re√ßoive ou ne paye une compensation pour cet effet.

\subsubsection{Concurrence Pure et
Parfaite}\label{concurrence-pure-et-parfaite}

La \textbf{CPP} repose sur cinq fondements :

\begin{itemize}
\tightlist
\item
  L'Atomicit√© du march√©
\end{itemize}

Existence d'un grand nombre d'agent √©conomique sur le march√©, √† tel un
point que ni l'offre ni la demande ne peut exercer une action quelconque
sur la production et les prix ;

\begin{itemize}
\tightlist
\item
  L'Homog√©n√©it√© des produits
\end{itemize}

La pr√©f√©rence d'un produit √† un autre du point de vue de l'acheteur se
fait uniquement selon son prix ;

\begin{itemize}
\tightlist
\item
  Libre entr√©e et sortie sur le march√©
\end{itemize}

Aucune firme ne peut s'opposer √† l'arriv√©e d'un concurrent sur le
march√©, tout le monde est libre de l'int√©grer ;

\begin{itemize}
\tightlist
\item
  Libre circulation des facteurs de production
\end{itemize}

Les facteurs de production (capital et travail) doivent √™tre libre de se
d√©placer librement sans obstacle d'une industrie √† l'autre ;

\begin{itemize}
\tightlist
\item
  La transparence de l'information
\end{itemize}

Offreurs et demandeurs sont parfaitement conscient des caract√©ristiques
et prix des produits.

\subsubsection{Monopole}\label{monopole}

``Le monopole est une situation dans un march√© o√π un vendeur fait face
aux multitudes vendeurs.''

\subsubsection{Segmentation de march√©}\label{segmentation-de-marchuxe9}

``La segmentation de march√© est un d√©coupage du march√© en groupes
homog√®nes selon des crit√®res sp√©cifiques, que ce soit des crit√®res
d√©mographiques ou bien g√©o-graphiques.''

\subsubsection{Discrimination par les
prix}\label{discrimination-par-les-prix}

``La discrimination par les prix est le pouvoir de pratiquer des prix
diff√©rents pour un m√™me produit, peut s'appliquer sur la quantit√© ou
bien selon la segmentation du march√©.''

\subsubsection{Utilit√©}\label{utilituxe9}

``L'utilit√© mesure le bien-√™tre li√©e √† la consommation d'un bien.''

\subsubsection{Actualisation}\label{actualisation}

``L'Actualisation est un calcul permettant de transformer une valeur
future en une valeur pr√©sente.''

Que vaut aujourd'hui les X euros que j'aurais demain ?

\[
V_a = \frac{V_f}{(1+i)^t}
\]

\[
V_a : Valeur\ Actuelle
\]

\[
V_f : Valeur\ future
\] \[
i : Taux\ sans\ risque\\ 
\]

\[
t : Temps
\]

\subsubsection{Probl√®mes
macro√©conomiques}\label{probluxe8mes-macrouxe9conomiques}

Il existe 4 grands probl√®mes macro√©conomiques :

\begin{itemize}
\item
  Crises et r√©cessions Ralentissement et/ou r√©gression de l'activit√©
  √©conomique ;
\item
  Inflations Augmentation g√©n√©rale et durable du niveau des prix
  entra√Ænant une perte du pouvoir d'achat de la monnaie ;
\item
  Ch√¥mage Inactivit√© due au manque de travail ;
\item
  Probl√®me de l'√©quilibre ext√©rieur Quand les importations sont plus
  importantes que les exportations, la balance commerciale est
  d√©s√©quilibr√©e.
\end{itemize}

\subsection{La dissertation en
√©conomie}\label{la-dissertation-en-uxe9conomie}

\emph{``On tient tout d'abord √† remercier l'enseignant chercheur (en
Philosophie √©conomique, Th√©ories √©conomiques de la justice,
Redistribution des revenus, Economie sociale, Economie publique),
monsieur \textbf{Jean-S√©bastien Gharbi} pour cette rubrique d'aide √† la
dissertation.''}

\begin{center}
\includegraphics[width=3.33333in,height=\textheight,keepaspectratio]{images/dissertation.png}
\end{center}

On pense souvent que la dissertation en √©conomie est un exercice
difficile et qui r√©compense mal le travail. C'est totalement faux. La
dissertation est un exercice dans lequel il est facile d'obtenir la
moyenne, et m√™me (avec un peu d'entra√Ænement) d'obtenir syst√©matiquement
de tr√®s bonnes notes. C'est un exercice relativement facile parce que
c'est un exercice en tr√®s grande partie formel~: tout est une question
de m√©thode.

Faire une dissertation, c'est \emph{montrer que vous √™tes capable
d'utiliser et de r√©organiser vos connaissances pour r√©pondre √† une
question de mani√®re argument√©e (c'est-√†-dire sous la forme d'un
raisonnement)}. Autrement dit~:

\begin{itemize}
\tightlist
\item
  \textbf{\emph{Une dissertation n'est pas une question de cours.}}
\end{itemize}

La premi√®re chose √† faire, c'est de diff√©rencier question de cours et
dissertation (qui sont souvent confondues). Une question de cours
demande simplement de r√©citer un cours. Si vous ne faites que r√©citer
votre cours dans un exercice de dissertation, vous aurez une mauvaise
note. Pourquoi~? Parce que \emph{l'exercice de dissertation suppose de
montrer que vous √™tes capable d'utiliser et de r√©organiser vos
connaissances} (dans un temps limit√©) -- pas seulement de r√©citer une
le√ßon apprise plus ou moins par c≈ìur. Comme la question de cours, la
dissertation suppose donc que vous savez des choses sur le sujet, mais
il est important de comprendre que la dissertation porte tout autant sur
votre aptitude √† organiser vos id√©es que sur vos connaissances.

\begin{itemize}
\tightlist
\item
  \textbf{\emph{Dans une dissertation, la r√©ponse donn√©e n'est pas
  importante !}}
\end{itemize}

Une dissertation consiste toujours √† r√©pondre √† une question. Les
√©tudiants pensent parfois qu'il y a une ¬´~bonne~¬ª r√©ponse √† la question
pos√©e -- qu'il s'agirait de trouver. D'ailleurs, cela contribue √† l'id√©e
(fausse) que la dissertation est un exercice al√©atoire~: si vous ne
trouvez pas la bonne r√©ponse, vous avez perdu. Cela aussi est faux~:
\emph{il n'y a (en g√©n√©ral) pas de ¬´~bonne~¬ª r√©ponse √† la question pos√©e
par la dissertation}. L'exercice de dissertation vient de la
philosophie. Pensez-vous s√©rieusement que l'on puisse demander √† un
√©tudiant (ou √† un professeur, d'ailleurs) de r√©gler de fa√ßon d√©finitive
un d√©bat philosophique qui a donn√© lieu √† des controverses pendant des
si√®cles en trois, quatre ou m√™me sept heures~? La r√©ponse √©vidente est
¬´~non~¬ª.

\begin{itemize}
\tightlist
\item
  \textbf{\emph{Dans une dissertation, le plus important c'est
  l'argumentation !}}
\end{itemize}

Si on ne s'int√©resse pas √† la r√©ponse donn√©e. C'est tout simplement,
parce que \emph{ce qui int√©resse votre lecteur, c'est la mani√®re dont
vous r√©pondez} : votre aptitude √† utiliser vos connaissances de mani√®re
argumentative pour d√©fendre une conclusion. Sur le principe, il serait
donc possible de d√©fendre une conclusion choquante ou m√™me offensante
dans une dissertation, pour la bonne raison qu'on n'√©value pas la
r√©ponse que vous donnez, mais la mani√®re dont vous amenez votre r√©ponse.
Votre r√©ponse, √† la limite, on ne s'y int√©resse pas. Une fois cela dit,
il est assez √©vident qu'il est beaucoup plus facile de d√©fendre une
position mod√©r√©e et consensuelle, qu'une position offensante pour de
nombreuses personnes. C'est la raison pour laquelle, il n'est pas du
tout conseill√© de chercher la provocation gratuite dans une
dissertation.

\ul{\textbf{Comment on fait une dissertation ?}}

\begin{center}
\includegraphics[width=1.8125in,height=\textheight,keepaspectratio]{images/question-02.png}
\end{center}

\subsubsection{Analyse du sujet}\label{analyse-du-sujet}

L'analyse du sujet est la premi√®re √©tape de la dissertation et l'une des
plus importantes. Une dissertation se pr√©sente sous la forme d'un sujet.
Il faut isoler la ou les deux notions principales du sujet.

Il y a quatre grands types de sujets~: les sujets ne contenant qu'une
seule notion (ex~: ¬´~Les discriminations en France~¬ª), les couples de
notions (ex~: ¬´~Capitalisme et d√©mocratie~¬ª), les citations (ex~:
¬´~\emph{Le syst√®me de production capitaliste est une d√©mocratie
√©conomique dans laquelle chaque sou donne un droit de vote. Les
consommateurs constituent le peuple souverain}~¬ª, Ludwig von Mises) ou
une question (ex~: ¬´~La croissance √©conomique s'oppose-t-elle √† la
pr√©servation de l'environnement~?~¬ª).

Dans tous les cas, l'objectif est d'arriver √† une question (donc les
sujets les plus simples √† traiter √† ce stade, ce sont les questions~:
ils vous donnent imm√©diatement le probl√®me √† traiter). Mais la premi√®re
chose √† faire (m√™me quand on a d√©j√† la question), c'est de trouver le
couple de notions impliqu√©es dans le sujet. Souvent, c'est absolument
√©vident, mais parfois il faut un peu chercher.

Il faut √©viter √† tout prix de faire un expos√© quand on attend de vous
une dissertation. Un hors-sujet, c'est de ne pas traiter le bon sujet.
Si vous r√©pondez de mani√®re factuelle √† un sujet de dissertation, vous
faites pire~: vous faites un hors-exercice.

\subsubsection{Recherche des id√©es}\label{recherche-des-iduxe9es}

Une fois qu'on a identifi√© un couple de notions, il faut (au brouillon)
essayer de faire la liste des √©l√©ments du cours qui relient les deux
notions. Il est important de ne noter que les √©l√©ments qui relient les
deux notions (pour ne pas risquer de se perdre dans des √©l√©ments qui
concernent seulement une seule des deux notions). Sur chacune des
notions que vous aurez √† traiter en dissertation, on a √©crit des livres
entiers. Il est impossible de tout dire dessus dans une dissertation. On
se limite donc √† ce qui relie les deux notions de notre sujet.
√âvidemment, si un √©l√©ment pertinent vous vient en t√™te et qu'il ne se
trouve pas dans votre cours, n'h√©sitez pas √† le noter. Si cet √©l√©ment
peut √™tre utilis√© dans votre raisonnement, m√™me comme exemple, ce sera
un plus indiscutable.

Dans un premier temps, on note tout ce qui se pr√©sente √† l'esprit. Ce
n'est que dans un deuxi√®me temps, quand on a un certain nombre
d'√©l√©ments que l'on se pose la question~: ¬´~Est-ce qu'il y a une mani√®re
qui saute aux yeux de relier tous ces √©l√©ments en r√©pondant √† la
question (si elle a √©t√© pos√©e de mani√®re directe) ou pour r√©pondre √† une
question comprenant le couple de notions (si la question n'a pas √©t√©
formul√©e dans le sujet)~? ¬ª. Si la r√©ponse est positive, on a trouv√© la
question qui structurera notre devoir. Si ce n'est pas le cas, il faut
essayer de trouver une question qui relie le plus grand nombre des
√©l√©ments que l'on a not√© sur son brouillon~-- et donc laisser de c√¥t√©
les √©l√©ments qui ne servent pas. Il arrive souvent qu'une partie des
√©l√©ments que l'on note sur son brouillon ne soit pas utilis√©e dans le
devoir. Bref, si notre sujet est un couple de notions ou une citation,
il faut que l'on arrive √† une question. √âvidemment, quand notre sujet
est d√©j√† une question, on n'a pas autant de marge de man≈ìuvre, mais en
v√©rit√©, si on vous pose une question pr√©cise, c'est que vous avez les
√©l√©ments pour y r√©pondre dans le cours (donc la diff√©rence n'est pas
tr√®s importante).

\subsubsection{Mise en √©vidence d'un
probl√®me}\label{mise-en-uxe9vidence-dun-probluxe8me}

Puisqu'elle ne doit pas √™tre une question de fait, la question qui relie
le plus d'√©l√©ments possibles parmi ceux qui associent les deux notions
dans votre cours doit √™tre une question conceptuelle. Pour le dire
autrement, cette question doit √™tre un probl√®me (on parle souvent de
¬´~probl√©matique~¬ª pour d√©signer ce probl√®me dans le cadre d'une
dissertation). Qu'est-ce qu'un probl√®me~? C'est une question qui met en
tension deux concepts et qui analyse les diff√©rents aspects de leur
relation (conceptuelle).

Souvent les √©tudiants ont peur de ne pas trouver le ¬´~bon~¬ª probl√®me.
Pourtant, si on suit la m√©thode de dissertation, il n'y a pas de risque
de se tromper. En effet, on ne doit pas choisir un probl√®me d'abord
(sans savoir si on a de quoi le traiter) et le traiter ensuite. Vous
aurez not√© qu'on proc√®de exactement dans le sens inverse~: on voit √†
quelle question on peut r√©pondre avec les √©l√©ments qu'on a sur son
brouillon et on pose pr√©cis√©ment la question √† laquelle on sait qu'on
peut r√©pondre.

\subsubsection{Construction du plan}\label{construction-du-plan}

Pour la m√™me raison qu'au-dessus, la construction du plan ne doit pas
√™tre tr√®s difficile~: il s'agit de rassembler les diff√©rents √©l√©ments
qui permettent de r√©pondre √† la question (au probl√®me que l'on va poser)
de fa√ßon √† y apporter une r√©ponse.

On va apporter la r√©ponse que les √©l√©ments disponibles nous permettent
d'atteindre. Il y a une seule contrainte~: votre plan doit √™tre
suffisamment d√©taill√©. Comme l'objectif de la dissertation, c'est de
montrer que vous √™tes capable d'utiliser et de r√©organiser vos
connaissances. Si vous ne faites que deux parties sans sous-parties √†
l'int√©rieur (il n'y aurait donc qu'une seule articulation logique), on
trouvera que vous n'avez pas assez structur√© votre devoir. Le d√©coupage
minimal, c'est d'avoir quatre √©l√©ments (en g√©n√©ral, on fait deux grandes
parties avec deux sous-parties chacune, donc on a trois articulations).

Vos parties et vos sous-parties doivent correspondre √† des √©tapes de
votre raisonnement (on dit souvent qu'il faut une id√©e par sous-partie),
donc votre plan doit donner la structure du raisonnement gr√¢ce auquel
vous allez r√©pondre √† la question pos√©e. Le plan (qui est annonc√© √† la
fin de l'introduction et qui doit √™tre apparent dans le devoir, nous
reviendrons sur ce point un peu plus loin) doit permettre de comprendre
la structure de votre devoir d'un coup d'≈ìil -- simplement en lisant les
titres.

Un √©l√©ment qui permet de savoir si votre plan est bon, c'est de se
demander si √† la fin de la premi√®re partie, on est arriv√© √† un √©tat de
la r√©flexion diff√©rent de celui de la fin de l'introduction.

Qu'est-ce que la premi√®re partie a permis de comprendre~? Et est-ce que
la seconde partie apporte quelque chose d'autre~? Si chaque partie
repr√©sente une √©tape dans un raisonnement et que votre devoir complet
est donc un raisonnement, votre plan est forc√©ment bon~: vu que c'est
pr√©cis√©ment ce qu'on attend de vous.

Il ne faut jamais faire deux sous-parties dans une partie sous la forme
d'une seule phrase coup√©e par des points de suspension (ex~: ¬´~A)
L'organisation scientifique du travail a permis la croissance des trente
glorieuses\ldots~¬ª, ¬´~B) mais, elle a aussi eu des cons√©quences
n√©gatives, notamment sur le plan social~¬ª). En effet, cela revient √†
pointer du doigt que vous op√©rez une coupure arbitraire (donc que vous
n'articulez pas de mani√®re assez nette les diff√©rentes parties de votre
devoir). Sur le principe, les deux sous-parties sont reli√©es par les
points de suspension et donc ne forment qu'une partie sans coupure.
Pr√©f√©rez toujours les titres qui se succ√®dent sans √™tre grammaticalement
li√©s les uns aux autres. Dans l'exemple ci-dessus, il suffit de faire
deux phrases pour d√©couper les deux id√©es. Si on ne peut pas couper
grammaticalement les deux titres, c'est la preuve que l'articulation
pose probl√®me.

Dans l'id√©al, un plan est √©quilibr√©~: chaque partie comprend le m√™me
nombre de sous-parties que l'autre et elles font √† peu pr√®s la m√™me
longueur. Et si vous faites plus de sous-parties dans une partie que
dans l'autre, il faut que les sous-parties soient un peu plus longues
dans la partie qui contient moins de sous-parties. Remarquez que si vous
faites un plan avec deux parties, deux sous-parties, ce dernier probl√®me
ne se pose pas.

Un point important et souvent totalement n√©glig√© par les √©tudiants~:
m√™me quand c'est tentant, \emph{on ne fait jamais de plan centr√© sur les
auteurs}. Un plan par auteurs conduit tr√®s souvent √† suivre l'ordre
chronologique et √† pr√©senter les positions des auteurs sans les
confronter r√©ellement les unes aux autres . Ce qui doit structurer le
plan, ce sont les concepts (c'est-√†-dire les notions qui nous avaient
permis de construire le probl√®me √† r√©soudre).

En r√©alit√©, il n'est pas rare qu'on suive plus ou moins l'ordre
chronologie, mais il est essentiel de se focaliser sur les concepts, et
pas sur les auteurs. Pourquoi~? Parce que l'encha√Ænement ou l'opposition
de concepts constitue un raisonnement (ce que vous devez faire~!), alors
que l'encha√Ænement ou l'opposition d'auteurs constitue un expos√© (ce que
vous ne devez pas faire~!). En r√©alit√©, c'est assez facile √† faire il
suffit de s'interdire de mentionner le nom des auteurs dans les titres
de partie ou de sous-partie.

Vu que l'objectif du plan, c'est de r√©pondre √† une question qui met les
deux notions du sujet en relation, \emph{les parties (ou les
sous-parties) qui se focalisent sur une seule des deux notions sont √†
√©viter √† tout prix~: elles sont simplement hors-sujet}. Sur un sujet
comme ¬´~capitalisme et d√©mocratie~¬ª, le plan ¬´~premi√®re partie~:
capitalisme~¬ª, ¬´~deuxi√®me partie~: d√©mocratie~¬ª est parmi les pires
possibles.

\textbf{Jusqu'√† pr√©sent, nous n'avons encore rien √©crit sur la copie
elle-m√™me.} Nous n'avons travaill√© que sur le brouillon. Nous avons deux
notions cl√©s, un probl√®me et un plan. Ce sont les √©l√©ments fondamentaux
du devoir. Il faut √† pr√©sent passer √† la r√©daction. Nous allons nous
int√©resser d'abord √† l'introduction.

\subsubsection{La r√©daction}\label{la-ruxe9daction}

\ul{\textbf{(Introduction, Conclusion, D√©veloppement)}}

\textbf{L'introduction} est la partie la plus importante de la
dissertation. Elle permet de savoir pourquoi le probl√®me se pose,
comment il se pose et comment il va √™tre r√©solu. A quoi sert
l'introduction~?

\emph{Le r√¥le de l'introduction, sa raison d'√™tre, c'est de construire
et d'√©noncer le probl√®me (la probl√©matique)} auquel le reste du devoir
va r√©pondre. Il ne suffit donc pas de poser la question (pour cela deux
lignes suffiraient) et de commencer le d√©veloppement. L'introduction,
comme son nom le dit tr√®s bien, va introduire le probl√®me, c'est-√†-dire
qu'elle va nous y amener, rapidement, certes, mais en plusieurs √©tapes
tr√®s codifi√©es.

Une introduction de dissertation comprend obligatoirement (au minimum)
cinq √©l√©ments~: une accroche, une d√©finition des termes du sujets, la
construction du probl√®me, l'√©nonc√© du probl√®me et l'annonce du plan.
Comme une introduction de dissertation fait entre 20 lignes et une page
et demie (grand maximum), il faut √™tre efficace.

\begin{itemize}
\tightlist
\item
  \textbf{\emph{L'accroche}}
\end{itemize}

\textbf{\emph{Une introduction de dissertation suit des r√®gles assez
rigides. Elle commence toujours par une accroche}}.

\emph{Une ¬´~accroche~¬ª, c'est une phrase ou deux qui vont contenir la ou
les deux notion(s) du sujet}. Son r√¥le est d'amener par √©tapes le
lecteur vers la question que vous allez poser. Elle sert donc
d'introduction √† l'introduction. Une accroche peut √™tre une citation (il
y en a toujours dans un cours) ou un fait r√©cent (le ch√¥mage a-t-il
baiss√© r√©cemment~? Un candidat √† l'√©lection pr√©sidentielle a-t-il dit
qu'il fallait juger sa politique en fonction de son impact sur le niveau
de ch√¥mage~?). Si on n'a pas de citation ou de fait relevant de
l'actualit√©, on peut amener le sujet de fa√ßon plus habituelle.

Il est important d'√©viter un certain nombre de formules toutes faites et
souvent utilis√©es comme ¬´~De tous temps\ldots~¬ª, ¬´~De tous temps, les
hommes\ldots~¬ª ou encore les affirmations tr√®s g√©n√©rales (et que vous ne
justifierez pas) comme~: ¬´~Le ch√¥mage est un ph√©nom√®ne √©conomique
important, c'est pourquoi il faut l'√©tudier~¬ª. Le d√©faut de tous ces
d√©buts d'accroche, c'est qu'ils peuvent servir pour n'importe quel sujet
et que cela se voit.

On met une accroche parce que cela permet de mentionner les termes du
sujet sans commencer directement par une d√©finition -- ce qui constitue
l'√©tape suivante.

\begin{itemize}
\tightlist
\item
  \textbf{D√©finition des termes du sujet}
\end{itemize}

L'accroche a introduit les notions, mais sans les d√©finir -- comme si
tout le monde savait pr√©cis√©ment de quoi il s'agit (ce qui n'est pas si
surprenant, on ne passe pas son temps √† d√©finir tous les mots qu'on
utilise). Mais, pour utiliser les deux notions du sujet de fa√ßon un peu
plus pr√©cise, il faut les d√©finir. Les d√©finitions que l'on va donner
dans une introduction n'ont pas pour objectif de d√©finir les notions de
mani√®re exhaustive ou dans l'absolu. Elles doivent permettre de
comprendre le lien (ou l'opposition) entre les deux notions et orienter
l'introduction de fa√ßon √† ce que l'on puisse construire le probl√®me --
avant de l'√©noncer (autrement dit, elles doivent ouvrir la voie aux deux
√©tapes suivantes de l'introduction).

Du coup, les d√©finitions que l'on va donner vont d√©pendre du probl√®me
que l'on souhaite atteindre.

\begin{itemize}
\tightlist
\item
  \textbf{Construction du probl√®me}
\end{itemize}

Comme on sait √† quelle question on doit arriver (que cette question nous
ait √©t√© donn√©e par le sujet ou que ce soit la question √† laquelle on est
le mieux arm√© pour apporter une r√©ponse), il ne va pas √™tre difficile de
passer des d√©finitions au probl√®me. Cela suppose juste de montrer
qu'avec les d√©finitions que l'on vient de donner, il y a une question se
pose avec force.

Encore une fois, cela peut sembler tr√®s artificiel (et √ßa l'est).
Toutefois, l'int√©r√™t de cet aspect artificiel, c'est qu'il nous garantit
que l'on ne va pas se perdre en chemin. Quand on fait une dissertation,
on ne cherche pas son chemin~: on sait o√π on va et on ne fait
qu'expliquer pourquoi on y va. Le sujet que l'on construit ne tombe pas
du ciel, il vient de notre cours. Les d√©finitions ne tombent pas du
ciel, elles donnent les √©l√©ments qui vont nous permettre de poser la
question √† laquelle on sait d√©j√† comment on va r√©pondre. Bref, l'√©tape
de construction du probl√®me est importante parce qu'elle montre que vous
avez des aptitudes pour vous faire comprendre √† l'√©crit (et il ne faut
surtout pas la n√©gliger), mais elle n'est pas une √©tape difficile ou
magique.

Vous pourriez √™tre surpris que l'on construise le sujet, alors qu'il
nous est parfois donn√© sous forme de question (dans les autres cas, on
comprend mieux pourquoi il est n√©cessaire de construire le probl√®me). En
fait, c'est une mani√®re de montrer que vous √™tes capable de vous
approprier le sujet. Vous ne traitez pas le sujet parce qu'on vous l'a
donn√© (m√™me si vous c'est une des raisons pour lesquelles vous faites
une dissertation), mais parce que vous comprenez pourquoi la question se
pose. Et comment mieux montrer qu'on comprend un probl√®me qu'en montrant
en quoi il est probl√©matique ? Autrement dit, m√™me quand votre sujet a
la forme d'une question, vous devez passer par l'√©tape de construction
du sujet dans l'introduction.

\begin{itemize}
\tightlist
\item
  \textbf{Enonc√© du probl√®me}
\end{itemize}

L'√©nonc√© du probl√®me doit prendre la forme d'une question. Il est le
point final de l'√©tape juste pr√©c√©dente. Une fois qu'on a les √©l√©ments
qui permettent de comprendre que le probl√®me se pose, il faut
explicitement exprimer le probl√®me lui-m√™me. \emph{On exprime toujours
le probl√®me sous la forme d'une question (parce que c'est une mani√®re de
montrer qu'il appelle une r√©ponse) et d'une question unique}. Poser
deux, trois ou quatre questions ce serait soit redire plusieurs fois la
m√™me chose (et si votre premi√®re question est claire, c'est inutile),
soit poser (volontairement ou pas) plusieurs questions diff√©rentes. Or,
vous ne pourrez pas r√©pondre convenablement et dans les r√®gles de la
dissertation √† plusieurs questions en un seul devoir. Vous devrez donc
choisir entre ne pas traiter certaines des questions que vous avez
explicitement pos√©es (et dans ce cas pourquoi les poser explicitement)
ou essayer de les traiter toutes (ce qui vous conduira √† un devoir dont
la ligne directrice sera au mieux difficile √† suivre, au pire
inexistante). Si on se rappelle du c√¥t√© formel et rh√©torique d'une
dissertation, on comprend qu'il ne faut poser qu'une seule question~:
celle √† laquelle vous apportez une r√©ponse.

Lorsque le sujet est une question, faut-il r√©p√©ter mot pour mot le sujet
comme √©nonc√© du probl√®me~? Il y a deux √©coles~: la premi√®re dit qu'il
faut reformuler la question pour montrer que vous la comprenez. Ainsi un
sujet comme ¬´~Les d√©penses publiques permettent-elles de r√©duire le
ch√¥mage~?~¬ª, on pourrait proposer une probl√©matique comme ¬´~les d√©penses
publiques sont-elles efficaces √† court et √† long terme pour lutter
contre le ch√¥mage~?~¬ª.

Si vous faites correctement votre travail de d√©finition des termes et de
construction du sujet (dans les deux √©tapes pr√©c√©dentes), je pense
qu'aucun correcteur ne vous reprochera de reprendre le sujet mot pour
mot dans votre √©nonc√© du probl√®me. Ce qui pose probl√®me pour les
partisans de la premi√®re fa√ßon de faire, c'est quand on peut se demander
si l'√©tudiant comprend que la question qu'il pose est un probl√®me
conceptuel, c'est-√†-dire qui vient d'une tension entre deux notions.
Dans une introduction qui remplit correctement son r√¥le de construction
du probl√®me, le fait de r√©p√©ter le sujet mot pour mot n'est pas un
souci.

\begin{itemize}
\tightlist
\item
  \textbf{Annonce du plan}
\end{itemize}

Une introduction doit toujours se terminer par une annonce du plan (ce
n'est pas une option, c'est une obligation). L'annonce de plan dit √†
votre lecteur comment vous allez r√©pondre au probl√®me que vous venez de
poser. Dans une dissertation, on ne joue pas sur le suspens. On ne
cherche pas √† surprendre son correcteur. Il faut donc annoncer le plan
de mani√®re √† ce qu'il comprenne que vous allez r√©pondre au probl√®me pos√©
par un raisonnement et qu'il comprenne aussi quels vont √™tre les
principales √©tapes de votre raisonnement (c'est-√†-dire de votre devoir).

Vous allez donc annoncer vos (deux ou trois) grandes parties. Il est
conseill√© fortement d'utiliser les formules (un peu lourdes en termes de
style, mais tr√®s claires) ¬´~dans une premi√®re partie, nous montrerons
que\ldots~¬ª, puis ¬´~dans une deuxi√®me partie, nous verrons que \ldots~¬ª.
Quand vous ne le faites pas, il arrive trop souvent que votre lecteur ne
sache pas si vous allez faire formellement deux ou trois parties -- pour
peu que vous utilisiez des mots comme ¬´~et~¬ª, ¬´~puis~¬ª ou ¬´~ensuite~¬ª,
qui peuvent aussi bien marquer des √©tapes √† l'int√©rieur d'une grande
partie que le passage d'une partie √† une autre.

\textbf{La conclusion}

\textbf{Vous pourriez √™tre surpris de voir la conclusion arriver aussi
t√¥t dans le devoir.} La raison, c'est qu'il est inconcevable de ne pas
r√©pondre √† la question pos√©e en introduction -- si vous ne r√©pondez pas
le devoir n'aura, litt√©ralement, servi √† rien. Or, il est √©vident qu'en
partiel, on est souvent pris par le temps. On r√©dige donc la conclusion
juste apr√®s avoir r√©dig√© l'introduction au brouillon (on la r√©dige aussi
au brouillon, d'ailleurs). Comme √ßa si on est pris par le temps, on
pourra recopier la conclusion d√©j√† pr√™te avant de rendre le devoir. S'il
faut couper quelque chose en raison du temps limit√© de l'√©preuve, il
vaut mieux couper un bout du d√©veloppement que rendre une dissertation
sans conclusion.

La premi√®re phrase de votre conclusion doit apporter la r√©ponse √† la
question que vous avez pos√©e en introduction. Elle doit le faire de
fa√ßon absolument claire et donc il est conseill√© de reprendre exactement
la question en la tournant en une phrase affirmative ou en une phrase
n√©gative selon votre r√©ponse. \emph{Le r√¥le de la conclusion, c'est de
r√©pondre √† la question}. Il ne faut pas qu'on relise la conclusion en se
demandant quelle √©tait la r√©ponse -- et m√™me en se demandant si une
r√©ponse a √©t√© donn√©e. Cela ne vous emp√™che pas de donner une r√©ponse
nuanc√©e, mais il faut une r√©ponse claire.

Une conclusion de dissertation ne r√©sume pas le devoir (on vient de le
lire, c'est tout √† fait inutile). Une conclusion n'introduit jamais un
√©l√©ment qui n'a pas √©t√© abord√© dans le devoir, mais qui aurait pu y √™tre
discut√©. Si jamais votre correcteur n'a pas vu que vous avez oubli√© de
parler de quelque chose d'important, vous n'allez tout de m√™me pas lui
dire qu'il manque quelque chose dans votre devoir (chacun son boulot).
La dissertation est un exercice de rh√©torique, votre objectif, c'est de
convaincre votre lecteur~: ce n'est pas √† vous de dire qu'il manque
quelque chose, m√™me si vous le savez.

On conseille parfois de finir sa dissertation sur une ouverture. Une
ouverture est un nouveau probl√®me qui se pose une fois que vous avez
r√©pondu au probl√®me de votre devoir. Cela revient √† sugg√©rer une autre
dissertation possible une fois qu'on consid√®re votre r√©ponse comme
accept√©e. Trop souvent, les √©tudiants finissent leurs devoirs de mani√®re
particuli√®rement maladroite parce qu'ils ne comprennent pas ce qu'est
une ouverture. Mon conseil est d'√©viter de faire une ouverture, au moins
au d√©but~: ce n'est pas une obligation et cela peut donner une tr√®s
mauvaise impression finale.

\textbf{La r√©daction du devoir}

Une fois tout cela fait, on prend sa copie (totalement vierge √† ce
moment) et on commence √† √©crire dessus~: on recopie l'introduction, on
r√©dige le d√©veloppement directement sur la copie (on ne r√©dige jamais
son d√©veloppement sur le brouillon, cela prend beaucoup trop de temps √†
recopier). \emph{Le d√©veloppement du devoir doit contenir des titres
apparents pour les parties et les sous-parties}. Cela signifie que le
titre de votre grande partie est marqu√© dans votre copie (pr√©c√©d√© d'un
¬´~I)~¬ª) et qu'il est isol√© du texte et soulign√©. Bref, on doit pouvoir
voir appara√Ætre d'un coup d'≈ìil votre plan en survolant votre copie du
regard.

Comme dit juste au-dessus, si on manque de temps, on coupe une partie du
d√©veloppement et on recopie la conclusion qui se trouve sur le
brouillon. Attention~: si vous ne r√©digez pas tout le d√©veloppement,
mettez tout de m√™me le plan apparent pour les parties et sous-parties
non d√©velopp√©es. C'est pr√©cis√©ment parce qu'on a une id√©e de ce que vous
auriez √©crit qu'il est possible (en cas de gros manque de temps) de ne
pas r√©diger tout le d√©veloppement. Si vous ne d√©taillez pas votre plan,
c'est la trame de votre raisonnement qui manque et c'est beaucoup plus
ennuyeux. Si vous ne pouvez pas r√©diger tout le d√©veloppement, je vous
conseille de mettre des √©l√©ments que vous auriez utilis√© sous forme de
liste de tirets (en plus des titres apparents qui sont obligatoires).




\end{document}
