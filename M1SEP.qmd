---
title: "DATA Camp M1"
editor: visual
--- 

# Alg√®bre Lin√©aire : niveau √©l√©mentaire

## Matrices

Une matrice est un tableau de nombres dispos√©s en $m$ lignes et $n$
colonnes. Soit $A$ de taille $(m, n)$ : $$
A = (a_{ij})_{i=1,\ldots,m \atop j=1,\ldots,n} =
\begin{bmatrix}
a_{11} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{m1} & \cdots & a_{mn}
\end{bmatrix}
$$

Le terme $a_{ij}$ est situ√© √† la $i$-√®me ligne de la $j$-√®me colonne de
la matrice $A$.

\textcolor{green!70!black!70!black}{Exemples :}

$$
A =
\begin{bmatrix}
-2 & 1 \\
8 & -3 \\
1 & 3
\end{bmatrix}
;\quad
B =
\begin{bmatrix}
-2 \\
-3 \\
5
\end{bmatrix}
;\quad
C =
\begin{bmatrix}
3 & -1 & 6
\end{bmatrix}
;\quad
D =
\begin{bmatrix}
3 & -1 \\
4 & -3
\end{bmatrix}
$$

$A$ est une matrice de taille $(3, 2)$, $B$ est une matrice de taille
$(3, 1)$, $C$ est une matrice de taille $(1, 3)$, $D$ est une matrice de
taille $(2, 2)$.

Une matrice $(m, 1)$ est dite matrice colonne. Une matrice $(1, n)$ est
dite une matrice ligne. Une matrice $(n, n)$ est dite une matrice carr√©e
d'ordre $n$.

On appelle transpos√©e de $A$ (et on note $A^t$ ou $A'$), la matrice dont
les lignes sont les colonnes de $A$, et dont les colonnes sont les
lignes de $A$.

\textcolor{green!70!black}{Exemple :} $$
A =
\begin{bmatrix}
-2 & 1 \\
8 & -3 \\
1 & 3
\end{bmatrix}
\Rightarrow
A^t =
\begin{bmatrix}
-2 & 8 & 1 \\
1 & -3 & 3
\end{bmatrix}
$$

\textcolor{green!70!black}{Propri√©t√©s :} $$
(A + B)^t = A^t + B^t
$$ $$
(AB)^t = B^t A
$$

## Matrices usuelles

Une matrice carr√©e d'ordre $n$ est dite diagonale lorsque, pour tout
$i \neq j$, on a $a_{ij} = 0$ : $$
A =
\begin{bmatrix}
-2 & 0 & 0 \\
0 & -3 & 0 \\
0 & 0 & 5
\end{bmatrix}
$$

La matrice unit√© $I_n$ est la matrice diagonale telle que
$\forall i = 1, \ldots, n$, $a_{ii} = 1$ : $$
I_3 =
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$

## Op√©rations de base

Soient $A$ et $B$ deux matrices de m√™me taille $(m, n)$ de termes
g√©n√©raux respectifs $a_{ij}$ et $b_{ij}$, et $\lambda$ un nombre r√©el.

$A = B$ si et seulement si $a_{ij} = b_{ij}$ pour tous $i,j$.

La somme de $A$ et $B$ est la matrice de terme g√©n√©ral $a_{ij} + b_{ij}$
: $$
A + B =
\begin{bmatrix}
5 + (-4) & 2 + 1 \\
6 + 1 & 1 + (-3)
\end{bmatrix}
=
\begin{bmatrix}
1 & 3 \\
7 & -2
\end{bmatrix}
$$

Le produit de $A$ par $\lambda$ est la matrice de terme g√©n√©ral
$\lambda a_{ij}$ : $$
\lambda A =
3 \times
\begin{bmatrix}
5 & 2 \\
6 & 1
\end{bmatrix}
=
\begin{bmatrix}
15 & 6 \\
18 & 3
\end{bmatrix}
$$

\textcolor{green!70!black}{Exemples :} $$
A =
\begin{bmatrix}
5 & 2 \\
6 & 1
\end{bmatrix}
;\quad
B =
\begin{bmatrix}
-4 & 1 \\
1 & -3
\end{bmatrix}
;\quad
\lambda = 3
$$ $$
A + B =
\begin{bmatrix}
1 & 3 \\
7 & -2 \\
\end{bmatrix}
\hspace{2cm}
\lambda A =
\begin{bmatrix}
15 & 6 \\
18 & -2 \\
\end{bmatrix}
$$

## Multiplication matricielle

Le produit de matrices A et B (not√© $AB$) n'est d√©fini que si le nombre
de colonnes de $A$ est √©gal au nombre de lignes de $B$. C'est-√†-dire $A$
doit √™tre de taille $(m, p)$ et $B$ de taille $(p, n)$. Alors $AB$ est
de taille $(m, n)$. De plus, soient $a_{ij}$ et $b_{ij}$ les termes
g√©n√©raux respectifs de $A$ et $B$, alors le terme g√©n√©ral de $C$ = $AB$
est $c_{ij}$ d√©fini par : $$
c_{ij} = \sum_{k=1}^{p} a_{ik} b_{kj}
$$ \textcolor{green!70!black}{Exemple : } $$A =
\begin{bmatrix}
2 & -2 & 1 \\
-3 & 6 & 8 \\
5 & 2 & 1
\end{bmatrix}
\hspace{2cm}
B = \begin{bmatrix}
-1 & 5 \\
1 & 2 \\
3 & 4
\end{bmatrix}$$ Alors, la matrice $C = AB$ est donn√©e par :
$$C = \begin{bmatrix}
-1 & 10 \\
33 & 29 \\
0 & 33
\end{bmatrix}$$

En effet, l'√©l√©ment qui se trouve au croisement de la i-√®me ligne et la
j-√®me colonne est : $$c_{ij} = \sum_{k=1}^{p} a_{ik} b_{kj}$$

Par exemple,
$$c_{2,1} = (-3) \times (-1) + 6 \times 1 + 8 \times 3 = 33$$

\textbf{\textcolor{red}{Le produit matriciel n‚Äôest pas commutatif.}}

\newpage

## Propri√©t√©s

Le produit est distributif par rapport √† l'addition. C'est-√†-dire : $$
A (B + C) = AB + AC \quad \text{et} \quad (B + C)A = BA + CA
$$

Le produit est associatif, c'est-√†-dire : $$
ABC = A(BC) = (AB)C
$$

Si A est une matrice carr√©e d'ordre n, alors $$A I_n = I_n A = A$$

Le produit de deux matrices peut √™tre nul sans que l'une des deux
matrices ne soit la matrice nulle, par exemple : $$
\begin{bmatrix}
1 & 2 \\
2 & 4
\end{bmatrix} \times
\begin{bmatrix}
-2 & 10 \\
1 & -5
\end{bmatrix}
$$

## Inverse

Une matrice carr√©e $A$ d'ordre $n$ est dite inversible lorsqu'il existe
une matrice $B$ telle que : $$ A B = B A = I_n $$ $B$ est alors not√©e
$A^{-1}$, l'inverse de $A$.

\newpage

## Syst√®mes lin√©aires

Gr√¢ce au produit matriciel, on peut repr√©senter un syst√®me lin√©aire par
une √©quation matricielle. Soit le syst√®me lin√©aire de $n$ √©quations et
$p$ inconnues :

$$
\begin{cases}
a_{11} x_1 + a_{12} x_2 + \ldots + a_{1p} x_p = b_1 \\
a_{21} x_1 + a_{22} x_2 + \ldots + a_{2p} x_p = b_2 \\
a_{n1} x_1 + a_{n2} x_2 + \ldots + a_{np} x_p = b_n
\end{cases}
$$

On peut le repr√©senter par $AX = B$ o√π :

$$A = \begin{bmatrix}
a_{11} & \ldots & a_{1p} \\
\vdots & \ddots & \vdots \\
a_{n1} & \ldots & a_{np}
\end{bmatrix} ; 
\hspace{2cm}
X = \begin{bmatrix}
x_1 \\
\vdots \\
x_p
\end{bmatrix} ; 
\hspace{2cm}
B = \begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}$$

\newpage

# Alg√®bre lin√©aire : niveau basique

## D√©terminant

Soit $A = (a_{ij})$ une matrice carr√©e d'ordre 2. Le d√©terminant de $A$
est le r√©el not√© $\text{det}(A)$ tel que : $$
\text{det}(A) = \begin{vmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{vmatrix} = a_{11}a_{22} - a_{12}a_{21}
$$

Soient $A = (a_{ij})$ et $B = (b_{ij})$ deux matrices carr√©es d'ordre
$n$ et $\lambda \in \mathbb{R}$. On a les propri√©t√©s suivantes :

-   $\text{det}(AB) = \text{det}(A) \cdot \text{det}(B) = \text{det}(BA)$
-   $\text{det}(A^T) = \text{det}(A)$
-   $\text{det}(\lambda A) = \lambda^n \cdot \text{det}(A)$
-   Si $A$ est diagonale, alors
    $\text{det}(A) = a_{11}a_{22}\ldots a_{nn}$
-   $\text{det}(I_n) = 1$
-   $A$ est inversible si et seulement si $\text{det}(A) \neq 0$
-   Si $\text{det}(A) \neq 0$, alors
    $\text{det}(A^{-1}) = \frac{1}{\text{det}(A)}$

## Diagonalisation

\textcolor{green!70!black}{Valeur propre / Vecteur propre}

Une valeur propre de $A$ est un scalaire $\lambda$ tel qu'il existe un
vecteur colonne non nul $V$ v√©rifiant : $AV = \lambda V$. $V$ est alors
appel√© vecteur propre de $A$ associ√© √† $\lambda$.

\textcolor{green!70!black}{Diagonalisation}

Une matrice carr√©e $A$ d'ordre $n$ est diagonalisable lorsqu'il existe
une matrice diagonale $D$ et une matrice inversible $P$ telles que :
$A = PDP^{-1}$. $D$ est constitu√©e des valeurs propres de $A$. $P$ est
obtenue par la concat√©nation des vecteurs propres de $A$. Si les valeurs
propres de $A$ sont distinctes, alors $A$ est diagonalisable (r√©ciproque
fausse).

## Matrice sym√©trique

Une matrice carr√©e $A$ d'ordre $n$ est sym√©trique lorsque $A^T = A$. Si
$A$ est sym√©trique, alors :

-   $A$ a des valeurs propres r√©elles.
-   $A$ est diagonalisable.
-   Il existe une matrice $P$ telle que $P^{-1} = P^T$ et
    $A = PDP^{-1}$.

## Produit scalaire

Soit $x$, $y$, $z$ trois vecteurs de $\mathbb{R}^n$ et $\lambda$ un
scalaire. On d√©finit par produit scalaire (qu'on note
$\langle \cdot, \cdot \rangle$) toute application qui v√©rifie les
propri√©t√©s suivantes :

-   $\langle x + \lambda y, z \rangle = \langle x, z \rangle + \lambda \langle y, z \rangle$
-   $\langle x, y + \lambda z \rangle = \langle x, z \rangle + \lambda \langle x, z \rangle$
-   $\langle x, y \rangle = \langle y, x \rangle$
-   $\langle x, x \rangle \geq 0$
-   $\langle x, x \rangle = 0 \Rightarrow x = 0$

Le produit scalaire canonique et usuel est d√©fini comme : $$
\langle x, y \rangle = \sum_{i=1}^{n} x_i \cdot y_i
$$

## Norme

On appelle norme associ√©e √† un produit scalaire le r√©el
$\|x\| = \sqrt{\langle x, x \rangle}$. Elle v√©rifie les propri√©t√©s
suivantes :

-   $|\langle x, y \rangle| \leq \|x\| \cdot \|y\|$ (In√©galit√© de
    Cauchy-Schwartz)
-   $\|x + y\| \leq \|x\| + \|y\|$ (In√©galit√© triangulaire)
-   $\|x\| \geq 0$ avec √©galit√© si $x = 0$
-   $\|\lambda x\| = |\lambda| \cdot \|x\|$
-   $\|x + y\|^2 = \|x\|^2 + \|y\|^2 + 2\langle x, y \rangle$

Un vecteur est dit unitaire ou norm√© si $\|x\| = 1$

## Orthogonalit√©

Deux vecteurs $x$ et $y$ sont dits orthogonaux si
$\langle x, y \rangle = 0$. On note $x \perp y$.

Une famille de vecteurs $\{x_i\}$ est dite orthogonale si tous ses
vecteurs sont deux √† deux orthogonaux. Toute famille orthogonale
$\{x_i\}_{i=1}^p$ v√©rifie le th√©or√®me de Pythagore : $$
\left\|\sum_{i=1}^n x_i\right\|^2 = \sum_{i=1}^n \|x_i\|^2
$$

Soit $E$ un espace muni d'un produit scalaire et $X$ une partie de $E$.
On appelle orthogonal de $X$ et on note $X^\perp$ l'ensemble :
$X^\perp = \{y \in E \,|\, \forall x \in X, \langle x, y \rangle = 0\}$.

On dit que $\{e_i\}_{i=1}^p$ est une base orthonorm√©e de $E$ si et
seulement si : - Si $a_1e_1 + a_2e_2 + \ldots + a_ne_n = 0$, alors
$a_i = 0$ pour tout $i \in \{1, \ldots, n\}$.\
- Pour tout $x \in E$, il existe $a_1, a_2, \ldots, a_n \in \mathbb{R}$
tels que $x = a_1e_1 + a_2e_2 + \ldots + a_ne_n$.\
- $e_i$ est orthogonal √† $e_j$ pour tout $i \neq j$.\
- Pour tout $i \in \{1, \ldots, n\}$, $\|e_i\| = 1$.

## Projection orthogonale

Soit $x$ un vecteur d'un espace muni d'un produit scalaire $E$. Soit $F$
un sous-espace vectoriel de $E$, $x$ s'√©crit de fa√ßon unique sous la
forme : $x = f + f^\perp$ o√π $f \in F$ et $f^\perp \in F^\perp$. On dit
que $f$ est le projet√© orthogonal de $x$ sur $F$ et on note
$f = P_F(x)$.

Pour $x$ et $y$ de $E$, on a
$\langle P_F(x),y\rangle = \langle x, P_F(y)\>$.

Si $(e_1, e_2, \ldots, e_n)$ est une base orthonorm√©e, alors :
$P_F(x) = \sum_{i=1}^n \langle x, e_i \rangle e_i$

Notons que : $\|x - P_F(x)\| = \inf_{f \in F} \|x - f\|$

## Matrice orthogonale

Soit $M$ une matrice carr√©e d'ordre $n$. On dit que $M$ est une matrice
orthogonale si elle v√©rifie : $$M \cdot M^T = M^T \cdot M = I_n$$

Le d√©terminant d'une matrice orthogonale est √©gal √† $\pm 1$. L'ensemble
des valeurs propres de $M$ est inclus dans l'ensemble $\{0, 1\}$.

\newpage

# Fondements de probabilit√© : niveau √©l√©mentaire

## Quelques d√©finitions

-   On appelle √©preuve $E$ toute exp√©rience probabiliste.
-   On appelle univers de $E$ l'ensemble, g√©n√©ralement not√© $\Omega$, de
    tous les r√©sultats possibles de l'√©preuve $E$ (appel√©s "√©v√©nements
    √©l√©mentaires").

Lancer une paire de d√©s √©quilibr√©s et en retenir la somme est une
√©preuve. $\Omega = \{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$ \hspace{1cm}
![](images/deux_des.png){width="5%" fig-align="center"}

## Ev√©nements

Un √©v√©nement est un sous-ensemble de $\Omega$.

-   L'intersection de $A$ et $B$, not√©e $A \cap B$, est un √©v√©nement. Il
    est r√©alis√© uniquement si $A$ et $B$ se produisent.
-   La r√©union de $A$ et $B$, not√©e $A \cup B$, est un √©v√©nement. Il est
    r√©alis√© si $A$ ou $B$ se produit. Deux √©v√©nements remarquables sont
    √† retenir :
    -   L'√©v√©nement certain $\Omega$ ;
    -   L'√©v√©nement impossible $\emptyset$ ;
-   Tous les √©l√©ments qui n'appartiennent pas √† $A$ appartiennent √† un
    √©v√©nement que l'on appelle le compl√©mentaire de $A$. On le note
    $\overline{A}$ ou $A^C$.
-   On dit que deux √©v√©nements $A$ et $B$ sont incompatibles s'ils ne
    peuvent pas √™tre r√©alis√©s en m√™me temps.

Si $A$, $B$ et $C$ sont des √©v√©nements de $\Omega$, les propri√©t√©s
suivantes sont toujours v√©rifi√©es :

-   $A \cup \overline{A} = \Omega$ et $A \cap \overline{A} = \emptyset$
-   $\overline{\overline{A} \cap \overline{B}} = \overline{A} \cup \overline{B}$
    et
    $\overline{\overline{A} \cup \overline{B}} = \overline{A} \cap \overline{B}$
    (lois de De Morgan)
-   $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
-   $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$

## Partitions

La famille d'√©v√©nements forme une partition de $\Omega$ si : $$
\bigcup_{i \in I} A_i = \Omega \quad \text{et} \quad A_i \cap A_j = \emptyset \text{ pour tout } i \neq j.
$$ Une partition remarquable est la famille qui contient l'√©v√©nement $A$
et son compl√©mentaire.

## Tribus et bor√©liens

![](images/venn_diagrams.jpg){width="50%" fig-align="center"}
![](images/AnBnC.png){width="50%" fig-align="center"}

\textcolor{green!70!black}{Comment pouvons-nous qualifier l'ensemble des √©v√©nements ?}

Une tribu est une famille $T$ de parties de l'ensemble $\Omega$ qui
v√©rifie les propri√©t√©s suivantes : - $\Omega \in T$\
- Si $(A_n)$ est une suite d√©nombrable d'√©l√©ments de $T$, alors
$\bigcup A_n \in T$\
--- Si $A$ est un √©l√©ment de $T$, alors son compl√©mentaire l'est aussi.

De plus, si $T$ est une tribu, alors : - $\emptyset \in T$\
- Si $(A_n)$ est une suite d'√©l√©ments de $T$, alors $\bigcap A_n \in T$.

\textcolor{green!70!black}{Exemples de tribus :}

Pour le cas discret, on consid√®re l'exp√©rience "Lancer une pi√®ce de
monnaie √©quilibr√©e".\
On notera : $P$ pour "PILE appara√Æt" et $F$ pour "FACE appara√Æt".\
Dans ce cas, l'univers est l'ensemble $\{P, F\}$ et
$T = \{\Omega, \emptyset, P, F\}$ est une tribu.\
En g√©n√©ral, l'ensemble des parties est une tribu classique.

Pour le cas continu, les intervalles du type $[a, +\infty[$,
$]a, +\infty[$, $]-\infty, a[$, $]-\infty, a]$ sont des tribus. Nous les
appelons DES BOR√âLIENS.

\textcolor{green!70!black}{Propri√©t√©s :}

Soient $A$ et $B$ deux √©v√©nements. Les propri√©t√©s suivantes sont
toujours vraies :

1.  $P(A^C) = 1 - P(A)$\
2.  $P(B) = P(A \cap B) + P(A^C \cap B)$\
3.  Si $A \subset B$, alors $P(A) \leq P(B)$\
4.  $0 \leq P(A) \leq 1$\
5.  $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

De plus, en consid√©rant une suite $(A_k)$ d'√©v√©nements, on a les
relations suivantes : $$
\begin{aligned}
P\left(\bigcup A_k\right) & = \lim_{n \to +\infty} P\left(\bigcup_{k=1}^n A_k\right) \\
P\left(\bigcap A_k\right) & = \lim_{n \to +\infty} P\left(\bigcap_{k=1}^n A_k\right) \\
P\left(\bigcup A_k\right) & \leq \sum_{k=1}^{+\infty} P(A_k)
\end{aligned}
$$

Et si $\bigcup A_k = \Omega$, alors : $$
P(B) = \sum_{k=1}^{+\infty} P(B \cap A_k)
$$

## Mesure

Soit $E$ un ensemble muni d'une tribu $T$. On appelle mesure toute
application $m : T \rightarrow \mathbb{R}^+$ telle que : -
$m(\emptyset) = 0$ - Si $(A_n)$ est une suite d'√©l√©ments de $T$ deux √†
deux disjoints alors : $$m\left(\bigcup_n A_n\right) = \sum_n m(A_n).$$

## Probabilit√©s

Soit $E$ un ensemble muni d'une tribu $T$. On appelle probabilit√© toute
application $P : T \rightarrow \mathbb{R}^+$ telle que : -
$P(\emptyset) = 0$ - Si $(A_n)$ est une suite d'√©l√©ments de $T$ deux √†
deux disjoints alors : $$P\left(\bigcup_n A_n\right) = \sum_n P(A_n).$$

## Probabilit√©s conditionnelles

En th√©orie des probabilit√©s, nous nous int√©ressons souvent au
comportement d'un al√©a, sachant qu'un autre √©v√©nement est d√©j√† pass√©.
C'est ce que nous appelons Les Probabilit√©s Conditionnelles.

Consid√©rant deux √©v√©nements de probabilit√© non nulle, $A$ et $B$, la
probabilit√© conditionnelle de $A$ sachant que $B$ est r√©alis√©
(couramment dit $A$ sachant $B$) est donn√©e par : $$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$

Par commutativit√© de l'intersection, nous avons : $$
P(A \cap B) = P(B \cap A)
$$

En utilisant la formule ci-dessus, nous pouvons √©galement exprimer la
probabilit√© conditionnelle de $B$ sachant $A$ : $$
P(B|A) = \frac{P(A|B) \cdot P(B)}{P(A)}
$$

C'est ce que nous appelons \textcolor{red}{LA FORMULE DE BAYES}.

## Ind√©pendance

Deux √©v√©nements $A$ et $B$ sont dits ind√©pendants si et seulement si :
$$P(A \cap B) = P(A) \cdot P(B)$$ En termes courants, deux √©v√©nements
sont ind√©pendants si le r√©sultat de l'un n'influence aucunement
l'aboutissement de l'autre. Sous condition d'ind√©pendance de $A$ et $B$,
la notion de la probabilit√© conditionnelle tombe √† l'eau, car les
√©v√©nements √©voluent l'un sans se soucier de l'autre. Ceci se traduit par
: $$P(A|B) = P(A)$$ $$P(B|A) = P(B)$$

Notons que si $A$ est ind√©pendant de $B$, il le sera par rapport √† son
compl√©mentaire √©galement, et vice versa. En g√©n√©ral, pour une suite
$(A_n)$ d'√©v√©nements ind√©pendants, on a :
$$P\left(\bigcap A_i\right) = \prod P(A_i) = P(A_1) \cdot \ldots \cdot P(A_n)$$
Cette formule est largement utilis√©e en statistique.

\textcolor{red}{NE PAS CONFONDRE IND√âPENDANCE ET INCOMPATIBILIT√â DES √âV√âNEMENTS}

## Variable al√©atoire

Une variable al√©atoire est un nombre qui d√©pend du r√©sultat d'une
exp√©rience al√©atoire. Chaque ex√©cution de l'exp√©rience g√©n√®re une
r√©alisation de la variable al√©atoire.

Math√©matiquement, on d√©finit une variable al√©atoire X comme une fonction
$X : T \rightarrow \mathbb{R}$ qui associe √† chaque √©v√©nement s, un r√©el
$X(s)$.

Par exemple, dans une queue pour la caisse d'un magasin, le nombre de
clients est une variable al√©atoire. La dur√©e de traitement de chaque
requ√™te aussi. Remarquons que la premi√®re est un nombre entier. On dit
qu'elle est √† support discret. Alors que la deuxi√®me est une dur√©e (un
nombre r√©el). On dit qu'elle est √† support continu.

\textcolor{green!70!black}{Qu‚Äôest- ce qui caract√©rise une variable al√©atoire ?}

## Fonction de r√©partition

Une variable al√©atoire traduit le r√©sultat d'une exp√©rience al√©atoire en
nombre r√©el. La fonction de r√©partition transporte le calcul des
probabilit√©s concernant les r√©alisations de la variable al√©atoire. C'est
la fonction d√©finie par : $$F_X(x) = P(X \leq x)$$
\textcolor{green!70!black}{Propri√©t√©s :}

Pour tout $x$, $0 \leq F_X(x) \leq 1$ $F_X$ est une fonction croissante.
$\lim_{x \to -\infty} F_X(x) = 0$ et $\lim_{x \to \infty} F_X(x) = 1$

![](images/fonction_repartition.png){width="50%" fig-align="center"}

## Probabilit√© ponctuelle / Densit√©

\textcolor{green!70!black}{CAS DISCRET : Probabilit√© ponctuelle}

La probabilit√© ponctuelle est la fonction qui d√©crit les sauts de la
fonction de r√©partition :
$$P(X = k) = P(X \leq k) - P(X \leq k - 1) = p_k$$ $$\sum p_i = 1$$

\textcolor{green!70!black}{CAS CONTINU : densit√© de probabilit√©}

La densit√© est la fonction qui d√©crit les variations de la fonction de
r√©partition : $$f(x) = \frac{dF_X}{dx}(x)$$ $$\int f(x) dx = 1$$

\newpage

# Fondements de probabilit√©s : niveau basique

## Moments

\textcolor{green!70!black}{ESP√âRANCE}

L'esp√©rance d'une variable al√©atoire est sa valeur attendue. C'est une
mesure de localisation de la distribution.

Dans le cas discret : $$E(X) = \sum k \cdot P(X = k)$$
$$k \in X(\Omega)$$ Alors que dans le cas continu :
$$E(X) = \int x \cdot f_X(x) \, dx$$ $$x \in X(\Omega)$$

\textcolor{green!70!black}{TH√âOR√àME DE TRANSFERT}
$$E(g(X)) = \sum g(k) \cdot P(X = k)$$ $$\forall k \in X(\Omega)$$
$$E(g(X)) = \int g(x) \cdot f_X(x) \, dx$$ $$\forall x \in X(\Omega)$$
\textcolor{green!70!black}{VARIANCE}

La variance d'une variable al√©atoire d√©crit la dispersion de la variable
al√©atoire autour de sa valeur moyenne (son esp√©rance).

Elle est d√©finie par : $$Var(X) = E(X^2) - (E(X))^2 = E((x - E(X))^2)$$
Sa racine carr√©e est appel√©e √©cart-type et not√©e g√©n√©ralement :
$$\sigma(X) = \sqrt{Var(X)}$$

\newpage

\textcolor{green!70!black}{CENTRAGE ET R√âDUCTION}

Le centrage consiste √† localiser la distribution autour de l'origine et
la r√©duction consiste √† normaliser la dispersion. La technique est
simple : $$Y = \frac{X - E(X)}{\sigma(X)}$$

\textcolor{green!70!black}{MOMENTS D‚ÄôORDRE r}

Le moment d'ordre r est d√©fini par : $$\mu_r = E(X^r)$$ Le moment centr√©
d'ordre r est d√©fini ainsi : $$\muÃÉ_r = E((X - E(X))^r)$$

## Couples al√©atoires

La fonction conjointe $$F_{X, Y}(x, y) = P(X \leq x \cap Y \leq y)$$ est
appel√©e la distribution conjointe de X et Y.

Dans le cas continu, la fonction d√©finie par :
$$f_{X, Y}(x, y) = \frac{\partial^2 F_{X, Y}(x, y)}{\partial x \partial y}$$
est la densit√© conjointe du couple (X, Y). On a donc :
$$F_{X, Y}(x, y) = \int \int f_{X, Y}(t, u) \, dt \, du, \text{ o√π } -\infty < x, y < +\infty,$$

Dans le cas discret, on d√©finit la fonction de probabilit√© conjointe :
$$P(X = x_i, Y = y_j) = p_{ij}$$ On a donc :
$$F_{X, Y}(x, y) = \sum \sum p_{ij}, \text{ o√π } x_i \leq x \text{ et } y_j \leq y$$

\textcolor{green!70!black}{LOI MARGINALE}

La loi marginale de X est d√©finie comme suit :
$$f_X(x) = \int f_{X, Y}(x, y) \, dy, \text{ o√π } -\infty < x < \infty,$$
dans le cas continu, ou encore :
$$f_X(x_i) = \sum p_{ij}, \text{ o√π } j \text{ tel que } y_j \leq y$$

Si X et Y sont ind√©pendants, alors :
$$f_{X, Y}(x, y) = f_X(x) \cdot f_Y(y)$$

\textcolor{green!70!black}{COVARIANCE}

La covariance mesure l'intensit√© de la relation lin√©aire entre deux
variables al√©atoires X et Y. Elle est d√©finie comme suit :
$$Cov(X, Y) = E(XY) - E(X) \cdot E(Y)$$

Si X et Y sont ind√©pendants, alors : $$Cov(X, Y) = 0$$

\textcolor{red}{Il est important de noter que la r√©ciproque n'est pas vraie : la covariance n'implique pas n√©cessairement l'ind√©pendance entre X et Y.}

\newpage

## Propri√©t√©s

\textcolor{green!70!black}{ESP√âRANCE} $$
\mathbb{E}(aX + bY) = a\mathbb{E}(X) + b\mathbb{E}(Y)
$$ $$
\mathbb{E}(a) = a
$$

\textcolor{green!70!black}{VARIANCE} $$
\text{Var}(aX) = a^2\text{Var}(X)
$$ $$
\text{Var}(a) = 0
$$ $$
\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2\text{Cov}(X,Y)
$$ $$
\text{Var}(X - Y) = \text{Var}(X) + \text{Var}(Y) - 2\text{Cov}(X,Y)
$$

\textcolor{green!70!black}{COVARIANCE} $$
\text{Cov}(X, Y) = \text{Cov}(Y, X)
$$ $$
\text{Cov}(aX + b, cY + d) = ac\text{Cov}(X, Y)
$$ $$
\text{Cov}(aX + bY, U) = a\text{Cov}(X, U) + b\text{Cov}(Y, U)
$$ $$
\text{Cov}(X, cU + dV) = c\text{Cov}(X, U) + d\text{Cov}(X, V)
$$ $$
\text{Cov}(aX + bY, cU + dV) = ac\text{Cov}(X, U) + ad\text{Cov}(X, V) + bc\text{Cov}(Y, U) + bd\text{Cov}(Y, V)
$$

\newpage

## Vecteurs al√©atoires

Pour un vecteur al√©atoire $$(X_1, X_2, \ldots, X_n)$$, l'esp√©rance est
toujours lin√©aire. Pour une suite $$(a_i)_{i \in \{1, \ldots, n\}}$$ de
r√©els, on a : $$
\mathbb{E}(a_1X_1 + a_2X_2 + \ldots + a_nX_n) = a_1\mathbb{E}(X_1) + a_2\mathbb{E}(X_2) + \ldots + a_n\mathbb{E}(X_n)
$$

Si les variables al√©atoires $$X_1, X_2, \ldots, X_n$$ sont
ind√©pendantes, alors la variance de leur somme est √©gale √† la somme de
leurs variances individuelles : $$
\text{Var}(X_1 + X_2 + \ldots + X_n) = \text{Var}(X_1) + \ldots + \text{Var}(X_n)
$$

## Lois usuelles

Ces tableaux r√©capitulent les lois usuelles que vous pourrez rencontrer
dans diff√©rents cours du master.

```{=tex}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nom & Notation & $X(\Omega)$ & $P(X = k)$ & $E[X]$ & $V(X)$ \\
\hline
Uniforme & $X \sim U(\{1, 2, \ldots, n\})$ & $\{1, 2, \ldots, n\}$ & $\frac{1}{n}$ & $\frac{n+1}{2}$ & $\frac{n^2-1}{12}$ \\
\hline
Bernouilli & $X \sim B(p), 0 < p < 1$ & $\{0, 1\}$ & $P(X = 1) = p$ & $p$ & $p(1-p)$ \\
& & & $P(X = 0) = 1 - p$ & & \\
\hline
Binomiale & $X \sim B(n, p), 0 < p < 1$ & $\{1, 2, \ldots, n\}$ & $C_k^n p^k (1 - p)^{n-k}$ & $np$ & $np(1-p)$ \\
\hline
G√©om√©trique & $X \sim G(p), 0 < p < 1$ & $\mathbb{N}$ & $p(1-p)^{k}$ & $\frac{1-p}{p}$ & $\frac{1-p}{p^2}$ \\
\hline
Poisson & $X \sim P(\lambda), \lambda > 0$ & $\mathbb{N}$ & $\frac{\lambda^k}{k!}e^{-\lambda}$ & $\lambda$ & $\lambda$ \\
\hline
\end{tabular}
```
```{=tex}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Nom & Notation & $X(\Omega)$ & $f_X(x)$ & $E[X]$ & $V(X)$ \\
\hline
Uniforme & $X \sim U([a, b]), a < b$ & $[a, b]$ & $\frac{1}{b - a}1_{[a, b]}(x)$ & $\frac{a + b}{2}$ & $\frac{(a - b)^2}{12}$ \\
\hline
Exponentielle & $X \sim \mathcal{E}(\lambda), \lambda > 0$ & $\mathbb{R}^+$ & $\lambda e^{-\lambda x}1_{\mathbb{R}^+}(x)$ & $\frac{1}{\lambda}$ & $\frac{1}{\lambda^2}$ \\
& $\mathcal{E}(Œª) = Œ≥(1, Œª)$ & & & & \\
\hline
Normale ou Gaussienne & $X \sim N(m, \sigma^2), \sigma > 0$ & $\mathbb{R}$ & $\frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{(x - m)^2}{2\sigma^2}\right)$ & $m$ & $\sigma^2$ \\
\hline
Gamma & $X \sim \gamma(\alpha, \theta), \alpha > 0, \theta > 0$ & $\mathbb{R}^+$ & $\frac{\theta^\alpha}{\Gamma(\alpha)}x^{\alpha - 1}e^{-\theta x}1_{\mathbb{R}^+}(x)$ & $\frac{\alpha}{\theta}$ & $\frac{\alpha}{\theta^2}$ \\
& $\Gamma(\alpha) = \int_0^\infty e^{-x}x^{\alpha-1} \, dx$ & & & & \\
\hline
Khi-2 & $X \sim \chi^2(n), n \in \mathbb{N}^+$ & $\mathbb{R}^+$ & $\gamma\left(\frac{n}{2}, \frac{1}{2}\right)$ & $n$ & $2n$ \\
& $Y_1, Y_2, \ldots, Y_n \text{ ind√©pendantes},$ & & & & \\
& $Y_i \sim \mathcal{N}(0, 1), \quad X = \sum_{i=1}^{n} Y_i^2$ & & & & \\
\hline
B√™ta & $X \sim B(\alpha, \theta), \alpha > 0, \theta > 0$ & $[0, 1]$ & $\frac{x^{\alpha-1}(1-x)^{\theta-1}}{B(\alpha, \theta)}1_{[0, 1]}(x)$ & $\frac{\alpha}{\alpha+\theta}$ & $\frac{\alpha\theta}{(\alpha+\theta)^2(\alpha+\theta+1)}$ \\
& $B(\alpha, \theta) = \int_0^1 x^{\alpha-1}(1-x)^{\theta-1} \, dx$ & & & & \\
& $B(\alpha, \theta) = \int_0^1 x^{\alpha-1}(1-x)^{\theta-1} \, dx$ & & & & \\
& $X = \frac{Z}{1 + Z}, \quad Z \sim B'(\alpha, \theta)$ & & & & \\
\hline
B√™ta (prime) & $Z ‚àº B'(Œ±, Œ∏), Œ± > 0, Œ∏ > 0$ & $\mathbb{R}^+$ & $\frac{z^{Œ±-1}}{B(Œ±,Œ∏) \cdot (1+z)^{Œ±+Œ∏}} \cdot 1_{\mathbb{R}^+}(z)$ & $ \frac{Œ±}{Œ∏ - 1}$ & $\frac{Œ±(Œ±+Œ∏-1)}{(Œ∏-1)^2(Œ∏-2)}$ \\
& $X \sim \gamma(\alpha, 1), Y \sim \gamma(\theta, 1), X \perp\!\!\!\perp Y$ & & & & \\
& $Z = \frac{X}{Y}$ & & & $Œ∏ > 1$ & $Œ∏ > 2$ \\
& $B(Œ±, Œ∏) = \int_{0}^{\infty} \frac{x^{\alpha-1}}{(1+x)^{\alpha+\theta}} \, dx$ & & & & \\
\hline
Student T & $T \sim T(n), n \in \mathbb{N}^*$ & $\mathbb{R}$ & $\frac{\left(1 + \frac{t^2}{n}\right)^{-(n+\frac{1}{2})}}{\sqrt{n}\cdot B(\frac{1}2,\frac{n}2)}$ & $0$ & $\frac{n}{n - 2}$ \\
& $X \sim \mathcal{N}(0, 1), Y \sim \chi^2(n), X \perp\!\!\!\perp Y$ & & & & \\
& $T = \frac{X}{\sqrt{Y/n}} $ & & & & $n > 2$ \\
& $T^2/n \sim B'(1/2, n/2)$ & & & & \\
\hline
Fisher & $X \sim F(n, m)$ & $\mathbb{R}^+$ & $\frac{Kx^{n/2-1}}{(m+nx)^{(n+m)/2}}1_{\mathbb{R}^+}(x)$ & $\frac{m}{m-2}$ & $\frac{2m^2(n+m-2)}{n(m-2)^2(m-4)}$ \\
& $N \sim \chi^2(n), n \in \mathbb{N}^*$ & & $K = \frac{n^{\frac{n}{2}} \cdot m^{\frac{m}{2}}}{B\left(\frac{n}{2}, \frac{m}{2}\right)}$ & & \\
& $M \sim \chi^2(m), \quad m \in \mathbb{N}^*$ & & & $m > 2$ & $m > 4$ \\
& $N \perp\!\!\!\perp M, \quad X = \frac{N}{n} / \frac{M}{m}$ & & & & \\
& $\frac{n}{m}X \sim B' \left(\frac{n}{2}, \frac{m}{2}\right)$ & & & & \\
\hline
\end{tabular}
```
\newpage

$$\Gamma(x) = \int_0^{\infty} t^{x-1}e^{-t} \, dt \text{ : d√©signe la fonction Gamma d'Euler}$$

$$B(x, y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)} \text{ : d√©signe la fonction B√™ta}$$

Nous allons souvent rencontrer les lois gris√©es dans les Tests
statistiques. L√† encore, conna√Ætre les densit√©s ne servirait pas √† grand
chose, mais ceci nous √©vitera de parler de lois dont nous ne connaissons
pas la t√™te.

\newpage

# Fondements de probabilit√©s

## Vecteurs al√©atoires

\textcolor{green!70!black}{INDEPENDANCE DEUX √Ä DEUX}

Les variables $X_1, \ldots, X_n$ sont deux √† deux ind√©pendantes si et
seulement si : $\forall i \neq j, X_i$ et $X_j$ sont ind√©pendantes.

\textcolor{green!70!black}{INDEPENDANCE MUTUELLE}

Les variables $X_1, \ldots, X_n$ sont mutuellement ind√©pendantes si et
seulement si :
$$P(X_1 = x_1, \ldots, X_n = x_n) = P(X_1 = x_1) \times \ldots \times P(X_n = x_n)$$

\textcolor{red}{L'IND√âPENDANCE MUTUELLE IMPLIQUE L'IND√âPENDANCE DEUX √Ä DEUX. LA R√âCIROQUE EST FAUSSE.}

Si $X_1, \ldots, X_n$ sont mutuellement ind√©pendantes, alors pour toute
famille de fonctions r√©elles $f_i$, on a :
$(f_1(X_1), \ldots, f_n(X_n))$ sont ind√©pendantes.

\textbf{ESP√âRANCE ET VARIANCE-COVARIANCE}

Soit $X = (X_1, \ldots, X_n)^T$ un vecteur al√©atoire. Dans le cas
multidimensionnel, l'esp√©rance scalaire est remplac√©e par un vecteur
esp√©rance. $$E(X) = (E(X_1), \ldots, E(X_n))^T$$

La variance unidimensionnelle est remplac√©e par la matrice sym√©trique de
variance-covariance. Elle contient les variances en diagonale et les
covariances ailleurs. On la note g√©n√©ralement $\Sigma_X$.
$$\Sigma_X = \begin{bmatrix}
V(X_1) & \ldots & \text{Cov}(X_1, X_n) \\
\vdots & \ddots & \vdots \\
\text{Cov}(X_n, X_1) & \ldots & V(X_n)
\end{bmatrix}$$

## Notions de convergence

Si l'on pense √† des donn√©es, vues comme r√©alisation de variables
al√©atoires $X_1, \ldots, X_n$, il serait int√©ressant de se poser la
question de savoir comment √©volue cette suite lorsque $n$ tend vers
l'infini.

\textcolor{green!70!black}{Convergence presque s√ªre}

On dit que $(X_n)$ converge presque s√ªrement vers $X$ et on note
$X_n \xrightarrow{\text{p.s.}} X$ si et seulement si :
$P\left(\lim_{{n\to+\infty}} X_n = X\right) = 1$

\textcolor{green!70!black}{Convergence en probabilit√©}

On dit que $(X_n)$ converge en probabilit√© vers $X$ et on note
$X_n \xrightarrow{\text{p}} X$ si et seulement si :
$\forall \varepsilon > 0, \quad P(|X_n - X| > \varepsilon) \rightarrow 0$

\textcolor{green!70!black}{Convergence en Loi}

On dit que $(X_n)$ converge en loi vers $X$ et on note
$X_n \xrightarrow{\mathcal{L}} X$ si et seulement si :
$F_{X_n} \xrightarrow{n \to +\infty} F_X$ O√π $F_X$ d√©note la fonction de
r√©partition de $X$.

\textcolor{green!70!black}{Convergence en Moyenne quadratique}

On dit que $(X_n)$ converge en moyenne quadratique vers $X$ et on note
$X_n \xrightarrow{m.q.} X$ si et seulement si :
$\mathbb{E}((X_n - X)^2) \rightarrow 0$ Cette d√©finition peut se
g√©n√©raliser jusqu'√† l'ordre $n$, mais nous n'en aurons pas besoin.

![](images/convergence.png){width="30%" fig-align="center"}

## Loi faible des grands nombres

Soit $X_1, \ldots, X_n$ une suite de variables al√©atoires ind√©pendantes
et de m√™me loi telles que : $\mathbb{E}(X_i) = \mu$ et
$\text{Var}(X_i) = \sigma^2$ alors :\
$$\frac{1}{n} \sum_{i=1}^{n} X_i \xrightarrow{p} \mu $$

## Loi forte des grands nombres

Soit $X_1, \ldots, X_n$ une suite de variables al√©atoires ind√©pendantes
et de m√™me loi telles que : $\mathbb{E}(X_i) = \mu$ et
$\text{Var}(X_i) = \sigma^2$, alors :\
$$\frac{1}{n} \sum_{i=1}^{n} X_i \xrightarrow{p.s.} \mu$$

## Th√©or√®me Central Limite

Soit $X_1, \ldots, X_n$ une suite de variables al√©atoires ind√©pendantes
et de m√™me loi telles que : $\mathbb{E}(X_i) = \mu$ et
$\text{Var}(X_i) = \sigma^2$, alors :
$$\sqrt{n}\frac{\overline{X}_n - \mu}{\sigma} \xrightarrow{\mathcal{Loi}} \mathcal{N}(0, 1)$$

\newpage

# Statistique inf√©rentielle : niveau basique

## Echantillon / Estimateur

Le point de d√©part est un vecteur (ou un tableau dans le cas
multidimensionnel) de donn√©es. Ces donn√©es peuvent √™tre vues comme les
r√©alisations $(x_1, x_2, \ldots, x_n)$ d'une variable al√©atoire $X$ qui
d√©pend d'un certain param√®tre $\theta$ que nous allons chercher √†
estimer. Pour ce faire, nous allons construire un √©chantillon de cette
variable. Un √©chantillon $(X_1, X_2, \ldots, X_n)$ est un n-uplet de
variables al√©atoires ind√©pendantes qui suivent toutes la m√™me loi (celle
de $X$). Un estimateur de $\theta$ est une fonction
$\hat{\theta} = f(X_1, X_2, \ldots, X_n)$ de notre √©chantillon, qui
poss√®de une loi de probabilit√©. Lorsque l'al√©a est r√©alis√©,
$\hat{\theta}(\omega) = f(x_1, x_2, \ldots, x_n)$ est une estimation de
$\theta$. Le but de ce cours est de construire le meilleur estimateur
possible de $\theta$.

## Estimateur sans biais

Pour que l'estimation soit bonne, il faut que $\hat{\theta}$ soit proche
de $\theta$. Comme $\hat{\theta} = f(X_1, X_2, \ldots, X_n)$ est une
variable al√©atoire, on ne peut imposer de condition qu'√† sa valeur
moyenne.

On d√©finit ainsi le biais :
$$b_n(\hat{\theta}, \theta) = \mathbb{E}(\hat{\theta}_n) - \theta$$

Un estimateur est dit sans biais si $b_n(\hat{\theta}, \theta) = 0$,
c'est-√†-dire : $$\mathbb{E}(\hat{\theta}_n) = \theta$$

## Estimateur convergent

Un estimateur est dit convergent s'il converge en probabilit√© vers le
param√®tre √† estimer : $$\hat{\theta}_n \xrightarrow{P} \theta$$

En pratique, tout estimateur sans biais et dont la variance tend vers 0
est convergent.

## Estimateur optimal

\textcolor{green!70!black}{Qualit√© d‚Äôun estimateur}

La qualit√© d'un estimateur est mesur√©e √† travers son erreur quadratique
moyenne d√©finie par :
$$EQM(\hat{\theta}_n) = (b_n(\hat{\theta}, \theta))^2 + V(\hat{\theta}_n)$$
Comme nous cherchons tout le temps (presque) des estimateurs sans biais,
il reste √† comparer les variances.

Un estimateur ùúÉÃÇ1 est meilleur que ùúÉÃÇ2 si :
$$V(\hat{\theta}_1) < V(\hat{\theta}_2)$$

\textcolor{green!70!black}{In√©galit√© de Rao-Cramer/ Efficacit√©}

On d√©finit la quantit√© d'information apport√©e par l'estimateur par : $$
I(\hat{\theta}_n) = -\left( \mathbb{E} \left( \frac{\partial L}{\partial \theta} \right) \right)^2
$$ O√π ùêø(ùë•, ùúÉ) = ‚àè ùëì(ùë•ùëñ) (nous reviendrons sur sa d√©finition)

L'in√©galit√© de Rao-Cramer postule que la variance d'un estimateur ne
peut pas aller en del√† d'un certain seuil :
$$V(\hat{\theta}_n) \geq \frac{1}{I(\hat{\theta}_n)}$$ Un estimateur est
optimal (ou efficace) si sa variance v√©rifie le cas d'√©galit√©.

\newpage

## Construction d'un estimateur

\textcolor{green!70!black}{M√©thode du maximum de vraisemblance}

La m√©thode du maximum de vraisemblance consiste √† affecter $ùúÉ$ la valeur
qui maximise la probabilit√© d'observer $(ùë•_1, ùë•_2, ‚Ä¶ , ùë•_ùëõ)$ lorsque
l'al√©a du vecteur $(ùëã_1, ùëã_2, ‚Ä¶ , ùëã_ùëõ)$ tombe. Sans trop rentrer dans la
th√©orie de la vraisemblance, nous allons pr√©senter un algorithme en cinq
√©tapes pour calculer cet estimateur (qui pr√©sente des propri√©t√©s assez
s√©duisantes) :

\textcolor{blue}{Etape 1 : Calculer la fonction de vraisemblance}

Dans le cas continu : $$L(\mathbf{x}, \theta) = \prod_{i=1}^{n} f(x_i)$$

Dans le cas discret :
$$L(\mathbf{x}, \theta) = \prod_{i=1}^{n} P(X_i = x_i)$$
\textcolor{blue}{Etape 2 : Calculer le log-vraisemblance}

Il s'agit de calculer un maximum, ce qui revient √† d√©river. Il s'agit
ici d'un produit de n facteurs, ce qui rend la d√©rivation assez coriace.
La fonction logarithmique pr√©sente des propri√©t√©s assez sympas pour
faciliter cette t√¢che.

\textcolor{blue}{Etape 3 : Calculer la d√©riv√©e de la log-vraisemblance}

\textcolor{blue}{Etape 4 : R√©soudre l'√©quation d'inconnue $ùúΩ$}
$$\frac{\partial (\ln(L))}{\partial \theta} = 0 \Rightarrow \theta = \theta_0$$

\textcolor{blue}{Etape 5 : V√©rifier qu'il s'agit d'un maximum.}

En s'assurant que :
$$\frac{\partial^2 (\ln(L))}{\partial \theta^2} < 0$$

\newpage

\textcolor{green!70!black}{M√©thode des moments}

Comme le param√®tre √† estimer intervient dans la densit√© de probabilit√©,
les moments th√©oriques sont souvent en fonction de ce param√®tre. Ainsi,
la m√©thode des moments consiste √† √©galiser les moments th√©oriques
(esp√©rance, variance) √† leurs √©quivalents empiriques et √† en d√©gager une
estimation ponctuelle.

En pratique, il faut r√©soudre l'(les) √©quation(s) :
$$\mathbb{E}(X) = \overline{X} \text{ et } \text{Var}(X) = S_n^2$$ avec
: $$\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i \hspace{2cm}
 S_n^2 = \frac{1}{n} \sum_{i=1}^{n} (X_i - \overline{X})^2$$

\textcolor{green!70!black}{M√©thode des moindres carr√©s ordinaires}

Lorsqu'il s'agit de prendre une mesure ùúÉ avec un appareil dot√© d'une
impr√©cision $ùúÄ$, alors le probl√®me d'estimation peut s'√©crire :
$ùëã = ùúÉ + ùúÄ$. La m√©thode des moindres-carr√©s ordinaires consiste √†
trouver le param√®tre $ùúÉ$ qui minimise la somme des carr√©es des erreurs :
$$ùúÉ_{ùëÄùê∂ùëÇ} = \arg\min \left( \sum_{i=0}^n \varepsilon_i^2 \right) = \arg\min \left( \sum_{i=0}^n (X_i - \theta)^2 \right)$$

## Intervalles de confiance

Un intervalle de confiance \[$A$, $B$\] de niveau $1 - \alpha$ est un
intervalle al√©atoire qui a la probabilit√© $1 - \alpha$ de contenir le
param√®tre √† estimer $\theta$. Formellement, on √©crit :
$P (t_1 (\theta) \leq f(X_1, \ldots, X_n) \leq t_2 (\theta)) = P(A \leq \theta \leq B) = 1 - \alpha$

\newpage

## Test d'hypoth√®ses

Dans le cadre d'un test d'hypoth√®se, nous cherchons √† faire valoir une
hypoth√®se en d√©pit d'une autre, qui lui est contradictoire.

On appellera la premi√®re (celle dont le rejet √† tort sera le plus
pr√©judiciable) ¬´ Hypoth√®se nulle ¬ª et la deuxi√®me ¬´ Hypoth√®se
alternative ¬ª.

![](images/test_hypo.png){width="50%" fig-align="center"}

Les calculs qui se cachent derri√®re le choix de l'hypoth√®se √† garder
sont compliqu√©s. Mais BONNE NOUVELLE, la machine fera tour √† notre
place. Il suffit juste de suivre correctement la m√©thode :

\textcolor{blue}{Etape 1 : Choisir judicieusement les hypoth√®ses √† √©valuer et fixer le risque $ùõº$}\
\textcolor{blue}{Etape 2 : Choisir le test adapt√© √† la proc√©dure}\
\textcolor{blue}{Etape 3 : Rentrer la commande correspondante sur R et ex√©cuter}\
\textcolor{blue}{Etape 4 : Lire dans les sorties la p-value. si elle est sup√©rieure √† Œ± on accepte H0. Si elle lui est inf√©rieure, on rejette H0}

\newpage

## Construction d'intervalles de confiance

Les intervalles de confiance sont des outils essentiels en statistique
pour estimer des param√®tres inconnus tout en mesurant l'incertitude
associ√©e √† cette estimation. Ci-dessous, vous trouverez un tableau
pr√©sentant la construction des intervalles de confiance pour diff√©rents
param√®tres.

```{=tex}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{images/intervalles_conf.png}
\end{figure}
```

# Economie 

## D√©finitions

### Macro√©conomie

![](images/macroeconomics.png){fig-align="center" width="73"}

La macro√©conomie est l'√©tude √©conomique d'un syst√®me ou de ph√©nom√®nes √† un niveau global de l'√©conomie.

### Micro√©conomie

La micro√©conomie se concentre sur l'observation et l'analyse des interactions √† petite √©chelle.

### Bien √©conomique

"Chose utile √† satisfaire un besoin, il faut que le bien soit disponible et en quantit√© limit√©e.

Un bien non √©conomique est un bien qui s'obtient gratuitement, comme l'oxyg√®ne, contrairement √† un bien √©conomique qui s'obtient en payant."

### Agent √©conomique

"Un agent √©conomique est un individu ou un groupe d'individus constituant un centre de d√©cision √©conomique ind√©pendant."

### March√©

![](images/economie-circulaire.png){fig-align="center" width="73"}

"Le march√© c'est une institution sociale qui permet l'√©change entre l'offre et la demande."

### Asym√©trie d'information

"L'asym√©trie d'information concerne les situations o√π les agents d'un march√© ne poss√®dent pas de la m√™me information sur un produit que ce soit au sujet de ses qualit√©s ou de ses d√©fauts"

### Concurrence Pure et Parfaite

La **CPP** repose sur cinq fondements :

-   L'Atomicit√© du march√©

Existence d'un grand nombre d'agent √©conomique sur le march√©, √† tel un point que ni l'offre ni la demande ne peut exercer une action quelconque sur la production et les prix ;

-   L'Homog√©n√©it√© des produits

La pr√©f√©rence d'un produit √† un autre du point de vue de l'acheteur se fait uniquement selon son prix ;

-   Libre entr√©e et sortie sur le march√©

Aucune firme ne peut s'opposer √† l'arriv√©e d'un concurrent sur le march√©, tout le monde est libre de l'int√©grer ;

-   Libre circulation des facteurs de production

Les facteurs de production (capital et travail) doivent √™tre libre de se d√©placer librement sans obstacle d'une industrie √† l'autre ;

-   La transparence de l'information

Offreurs et demandeurs sont parfaitement conscient des caract√©ristiques et prix des produits.

### Monopole

"Le monopole est une situation dans un march√© o√π un vendeur fait face aux multitudes vendeurs."

### Segmentation de march√©

"La segmentation de march√© est un d√©coupage du march√© en groupes homog√®nes selon des crit√®res sp√©cifiques, que ce soit des crit√®res d√©mographiques ou bien g√©o-graphiques."

### Discrimination par les prix

"La discrimination par les prix est le pouvoir de pratiquer des prix diff√©rents pour un m√™me produit, peut s'appliquer sur la quantit√© ou bien selon la segmentation du march√©."

### Utilit√©

"L'utilit√© mesure le bien-√™tre li√©e √† la consommation d'un bien."

### Actualisation

"L'Actualisation est un calcul permettant de transformer une valeur future en une valeur pr√©sente."

Que vaut aujourd'hui les X euros que j'aurais demain ?

$$
V_a = \frac{V_f}{(1+i)^t}
$$

$$
V_a : Valeur\ Actuelle
$$

$$
V_f : Valeur\ future
$$ $$
i : Taux\ sans\ risque\\ 
$$

$$
t : Temps
$$

### Probl√®mes macro√©conomiques

Il existe 4 grands probl√®mes macro√©conomiques :

-   Crises et r√©cessions Ralentissement et/ou r√©gression de l'activit√© √©conomique ;

-   Inflations Augmentation g√©n√©rale et durable du niveau des prix entra√Ænant une perte du pouvoir d'achat de la monnaie ;

-   Ch√¥mage Inactivit√© due au manque de travail ;

-   Probl√®me de l'√©quilibre ext√©rieur Quand les importations sont plus importantes que les exportations, la balance commerciale est d√©s√©quilibr√©e.

## La dissertation en √©conomie

*"On tient tout d'abord √† remercier l'enseignant chercheur (en Philosophie √©conomique, Th√©ories √©conomiques de la justice, Redistribution des revenus, Economie sociale, Economie publique), monsieur **Jean-S√©bastien Gharbi** pour cette rubrique d'aide √† la dissertation."*

![](images/dissertation.png){fig-align="center" width="320"}

On pense souvent que la dissertation en √©conomie est un exercice difficile et qui r√©compense mal le travail. C'est totalement faux. La dissertation est un exercice dans lequel il est facile d'obtenir la moyenne, et m√™me (avec un peu d'entra√Ænement) d'obtenir syst√©matiquement de tr√®s bonnes notes. C'est un exercice relativement facile parce que c'est un exercice en tr√®s grande partie formel¬†: tout est une question de m√©thode.

Faire une dissertation, c'est *montrer que vous √™tes capable d'utiliser et de r√©organiser vos connaissances pour r√©pondre √† une question de mani√®re argument√©e (c'est-√†-dire sous la forme d'un raisonnement)*. Autrement dit¬†:

-   ***Une dissertation n'est pas une question de cours.***

La premi√®re chose √† faire, c'est de diff√©rencier question de cours et dissertation (qui sont souvent confondues). Une question de cours demande simplement de r√©citer un cours. Si vous ne faites que r√©citer votre cours dans un exercice de dissertation, vous aurez une mauvaise note. Pourquoi¬†? Parce que *l'exercice de dissertation suppose de montrer que vous √™tes capable d'utiliser et de r√©organiser vos connaissances* (dans un temps limit√©) -- pas seulement de r√©citer une le√ßon apprise plus ou moins par c≈ìur. Comme la question de cours, la dissertation suppose donc que vous savez des choses sur le sujet, mais il est important de comprendre que la dissertation porte tout autant sur votre aptitude √† organiser vos id√©es que sur vos connaissances.

-   ***Dans une dissertation, la r√©ponse donn√©e n'est pas importante !***

Une dissertation consiste toujours √† r√©pondre √† une question. Les √©tudiants pensent parfois qu'il y a une ¬´¬†bonne¬†¬ª r√©ponse √† la question pos√©e -- qu'il s'agirait de trouver. D'ailleurs, cela contribue √† l'id√©e (fausse) que la dissertation est un exercice al√©atoire¬†: si vous ne trouvez pas la bonne r√©ponse, vous avez perdu. Cela aussi est faux¬†: *il n'y a (en g√©n√©ral) pas de ¬´¬†bonne¬†¬ª r√©ponse √† la question pos√©e par la dissertation*. L'exercice de dissertation vient de la philosophie. Pensez-vous s√©rieusement que l'on puisse demander √† un √©tudiant (ou √† un professeur, d'ailleurs) de r√©gler de fa√ßon d√©finitive un d√©bat philosophique qui a donn√© lieu √† des controverses pendant des si√®cles en trois, quatre ou m√™me sept heures¬†? La r√©ponse √©vidente est ¬´¬†non¬†¬ª.

-   ***Dans une dissertation, le plus important c'est l'argumentation !***

Si on ne s'int√©resse pas √† la r√©ponse donn√©e. C'est tout simplement, parce que *ce qui int√©resse votre lecteur, c'est la mani√®re dont vous r√©pondez* : votre aptitude √† utiliser vos connaissances de mani√®re argumentative pour d√©fendre une conclusion. Sur le principe, il serait donc possible de d√©fendre une conclusion choquante ou m√™me offensante dans une dissertation, pour la bonne raison qu'on n'√©value pas la r√©ponse que vous donnez, mais la mani√®re dont vous amenez votre r√©ponse. Votre r√©ponse, √† la limite, on ne s'y int√©resse pas. Une fois cela dit, il est assez √©vident qu'il est beaucoup plus facile de d√©fendre une position mod√©r√©e et consensuelle, qu'une position offensante pour de nombreuses personnes. C'est la raison pour laquelle, il n'est pas du tout conseill√© de chercher la provocation gratuite dans une dissertation.

[**Comment on fait une dissertation ?**]{.underline}

![](images/question-02.png){fig-align="center" width="174"}

### **Analyse du sujet**

L'analyse du sujet est la premi√®re √©tape de la dissertation et l'une des plus importantes. Une dissertation se pr√©sente sous la forme d'un sujet. Il faut isoler la ou les deux notions principales du sujet.

Il y a quatre grands types de sujets¬†: les sujets ne contenant qu'une seule notion (ex¬†: ¬´¬†Les discriminations en France¬†¬ª), les couples de notions (ex¬†: ¬´¬†Capitalisme et d√©mocratie¬†¬ª), les citations (ex¬†: ¬´¬†*Le syst√®me de production capitaliste est une d√©mocratie √©conomique dans laquelle chaque sou donne un droit de vote. Les consommateurs constituent le peuple souverain*¬†¬ª, Ludwig von Mises) ou une question (ex¬†: ¬´¬†La croissance √©conomique s'oppose-t-elle √† la pr√©servation de l'environnement¬†?¬†¬ª).

Dans tous les cas, l'objectif est d'arriver √† une question (donc les sujets les plus simples √† traiter √† ce stade, ce sont les questions¬†: ils vous donnent imm√©diatement le probl√®me √† traiter). Mais la premi√®re chose √† faire (m√™me quand on a d√©j√† la question), c'est de trouver le couple de notions impliqu√©es dans le sujet. Souvent, c'est absolument √©vident, mais parfois il faut un peu chercher.

Il faut √©viter √† tout prix de faire un expos√© quand on attend de vous une dissertation. Un hors-sujet, c'est de ne pas traiter le bon sujet. Si vous r√©pondez de mani√®re factuelle √† un sujet de dissertation, vous faites pire¬†: vous faites un hors-exercice.

### **Recherche des id√©es**

Une fois qu'on a identifi√© un couple de notions, il faut (au brouillon) essayer de faire la liste des √©l√©ments du cours qui relient les deux notions. Il est important de ne noter que les √©l√©ments qui relient les deux notions (pour ne pas risquer de se perdre dans des √©l√©ments qui concernent seulement une seule des deux notions). Sur chacune des notions que vous aurez √† traiter en dissertation, on a √©crit des livres entiers. Il est impossible de tout dire dessus dans une dissertation. On se limite donc √† ce qui relie les deux notions de notre sujet. √âvidemment, si un √©l√©ment pertinent vous vient en t√™te et qu'il ne se trouve pas dans votre cours, n'h√©sitez pas √† le noter. Si cet √©l√©ment peut √™tre utilis√© dans votre raisonnement, m√™me comme exemple, ce sera un plus indiscutable.

Dans un premier temps, on note tout ce qui se pr√©sente √† l'esprit. Ce n'est que dans un deuxi√®me temps, quand on a un certain nombre d'√©l√©ments que l'on se pose la question¬†: ¬´¬†Est-ce qu'il y a une mani√®re qui saute aux yeux de relier tous ces √©l√©ments en r√©pondant √† la question (si elle a √©t√© pos√©e de mani√®re directe) ou pour r√©pondre √† une question comprenant le couple de notions (si la question n'a pas √©t√© formul√©e dans le sujet)¬†? ¬ª. Si la r√©ponse est positive, on a trouv√© la question qui structurera notre devoir. Si ce n'est pas le cas, il faut essayer de trouver une question qui relie le plus grand nombre des √©l√©ments que l'on a not√© sur son brouillon¬†-- et donc laisser de c√¥t√© les √©l√©ments qui ne servent pas. Il arrive souvent qu'une partie des √©l√©ments que l'on note sur son brouillon ne soit pas utilis√©e dans le devoir. Bref, si notre sujet est un couple de notions ou une citation, il faut que l'on arrive √† une question. √âvidemment, quand notre sujet est d√©j√† une question, on n'a pas autant de marge de man≈ìuvre, mais en v√©rit√©, si on vous pose une question pr√©cise, c'est que vous avez les √©l√©ments pour y r√©pondre dans le cours (donc la diff√©rence n'est pas tr√®s importante).

### **Mise en √©vidence d'un probl√®me**

Puisqu'elle ne doit pas √™tre une question de fait, la question qui relie le plus d'√©l√©ments possibles parmi ceux qui associent les deux notions dans votre cours doit √™tre une question conceptuelle. Pour le dire autrement, cette question doit √™tre un probl√®me (on parle souvent de ¬´¬†probl√©matique¬†¬ª pour d√©signer ce probl√®me dans le cadre d'une dissertation). Qu'est-ce qu'un probl√®me¬†? C'est une question qui met en tension deux concepts et qui analyse les diff√©rents aspects de leur relation (conceptuelle).

Souvent les √©tudiants ont peur de ne pas trouver le ¬´¬†bon¬†¬ª probl√®me. Pourtant, si on suit la m√©thode de dissertation, il n'y a pas de risque de se tromper. En effet, on ne doit pas choisir un probl√®me d'abord (sans savoir si on a de quoi le traiter) et le traiter ensuite. Vous aurez not√© qu'on proc√®de exactement dans le sens inverse¬†: on voit √† quelle question on peut r√©pondre avec les √©l√©ments qu'on a sur son brouillon et on pose pr√©cis√©ment la question √† laquelle on sait qu'on peut r√©pondre.

### **Construction du plan**

Pour la m√™me raison qu'au-dessus, la construction du plan ne doit pas √™tre tr√®s difficile¬†: il s'agit de rassembler les diff√©rents √©l√©ments qui permettent de r√©pondre √† la question (au probl√®me que l'on va poser) de fa√ßon √† y apporter une r√©ponse.

On va apporter la r√©ponse que les √©l√©ments disponibles nous permettent d'atteindre. Il y a une seule contrainte¬†: votre plan doit √™tre suffisamment d√©taill√©. Comme l'objectif de la dissertation, c'est de montrer que vous √™tes capable d'utiliser et de r√©organiser vos connaissances. Si vous ne faites que deux parties sans sous-parties √† l'int√©rieur (il n'y aurait donc qu'une seule articulation logique), on trouvera que vous n'avez pas assez structur√© votre devoir. Le d√©coupage minimal, c'est d'avoir quatre √©l√©ments (en g√©n√©ral, on fait deux grandes parties avec deux sous-parties chacune, donc on a trois articulations).

Vos parties et vos sous-parties doivent correspondre √† des √©tapes de votre raisonnement (on dit souvent qu'il faut une id√©e par sous-partie), donc votre plan doit donner la structure du raisonnement gr√¢ce auquel vous allez r√©pondre √† la question pos√©e. Le plan (qui est annonc√© √† la fin de l'introduction et qui doit √™tre apparent dans le devoir, nous reviendrons sur ce point un peu plus loin) doit permettre de comprendre la structure de votre devoir d'un coup d'≈ìil -- simplement en lisant les titres.

Un √©l√©ment qui permet de savoir si votre plan est bon, c'est de se demander si √† la fin de la premi√®re partie, on est arriv√© √† un √©tat de la r√©flexion diff√©rent de celui de la fin de l'introduction.

Qu'est-ce que la premi√®re partie a permis de comprendre¬†? Et est-ce que la seconde partie apporte quelque chose d'autre¬†? Si chaque partie repr√©sente une √©tape dans un raisonnement et que votre devoir complet est donc un raisonnement, votre plan est forc√©ment bon¬†: vu que c'est pr√©cis√©ment ce qu'on attend de vous.

Il ne faut jamais faire deux sous-parties dans une partie sous la forme d'une seule phrase coup√©e par des points de suspension (ex¬†: ¬´¬†A) L'organisation scientifique du travail a permis la croissance des trente glorieuses...¬†¬ª, ¬´¬†B) mais, elle a aussi eu des cons√©quences n√©gatives, notamment sur le plan social¬†¬ª). En effet, cela revient √† pointer du doigt que vous op√©rez une coupure arbitraire (donc que vous n'articulez pas de mani√®re assez nette les diff√©rentes parties de votre devoir). Sur le principe, les deux sous-parties sont reli√©es par les points de suspension et donc ne forment qu'une partie sans coupure. Pr√©f√©rez toujours les titres qui se succ√®dent sans √™tre grammaticalement li√©s les uns aux autres. Dans l'exemple ci-dessus, il suffit de faire deux phrases pour d√©couper les deux id√©es. Si on ne peut pas couper grammaticalement les deux titres, c'est la preuve que l'articulation pose probl√®me.

Dans l'id√©al, un plan est √©quilibr√©¬†: chaque partie comprend le m√™me nombre de sous-parties que l'autre et elles font √† peu pr√®s la m√™me longueur. Et si vous faites plus de sous-parties dans une partie que dans l'autre, il faut que les sous-parties soient un peu plus longues dans la partie qui contient moins de sous-parties. Remarquez que si vous faites un plan avec deux parties, deux sous-parties, ce dernier probl√®me ne se pose pas.

Un point important et souvent totalement n√©glig√© par les √©tudiants¬†: m√™me quand c'est tentant, *on ne fait jamais de plan centr√© sur les auteurs*. Un plan par auteurs conduit tr√®s souvent √† suivre l'ordre chronologique et √† pr√©senter les positions des auteurs sans les confronter r√©ellement les unes aux autres . Ce qui doit structurer le plan, ce sont les concepts (c'est-√†-dire les notions qui nous avaient permis de construire le probl√®me √† r√©soudre).

En r√©alit√©, il n'est pas rare qu'on suive plus ou moins l'ordre chronologie, mais il est essentiel de se focaliser sur les concepts, et pas sur les auteurs. Pourquoi¬†? Parce que l'encha√Ænement ou l'opposition de concepts constitue un raisonnement (ce que vous devez faire¬†!), alors que l'encha√Ænement ou l'opposition d'auteurs constitue un expos√© (ce que vous ne devez pas faire¬†!). En r√©alit√©, c'est assez facile √† faire il suffit de s'interdire de mentionner le nom des auteurs dans les titres de partie ou de sous-partie.

Vu que l'objectif du plan, c'est de r√©pondre √† une question qui met les deux notions du sujet en relation, *les parties (ou les sous-parties) qui se focalisent sur une seule des deux notions sont √† √©viter √† tout prix¬†: elles sont simplement hors-sujet*. Sur un sujet comme ¬´¬†capitalisme et d√©mocratie¬†¬ª, le plan ¬´¬†premi√®re partie¬†: capitalisme¬†¬ª, ¬´¬†deuxi√®me partie¬†: d√©mocratie¬†¬ª est parmi les pires possibles.

**Jusqu'√† pr√©sent, nous n'avons encore rien √©crit sur la copie elle-m√™me.** Nous n'avons travaill√© que sur le brouillon. Nous avons deux notions cl√©s, un probl√®me et un plan. Ce sont les √©l√©ments fondamentaux du devoir. Il faut √† pr√©sent passer √† la r√©daction. Nous allons nous int√©resser d'abord √† l'introduction.

### **La r√©daction**

[**(Introduction, Conclusion, D√©veloppement)**]{.underline}

**L'introduction** est la partie la plus importante de la dissertation. Elle permet de savoir pourquoi le probl√®me se pose, comment il se pose et comment il va √™tre r√©solu. A quoi sert l'introduction¬†?

*Le r√¥le de l'introduction, sa raison d'√™tre, c'est de construire et d'√©noncer le probl√®me (la probl√©matique)* auquel le reste du devoir va r√©pondre. Il ne suffit donc pas de poser la question (pour cela deux lignes suffiraient) et de commencer le d√©veloppement. L'introduction, comme son nom le dit tr√®s bien, va introduire le probl√®me, c'est-√†-dire qu'elle va nous y amener, rapidement, certes, mais en plusieurs √©tapes tr√®s codifi√©es.

Une introduction de dissertation comprend obligatoirement (au minimum) cinq √©l√©ments¬†: une accroche, une d√©finition des termes du sujets, la construction du probl√®me, l'√©nonc√© du probl√®me et l'annonce du plan. Comme une introduction de dissertation fait entre 20 lignes et une page et demie (grand maximum), il faut √™tre efficace.

-   ***L'accroche***

***Une introduction de dissertation suit des r√®gles assez rigides. Elle commence toujours par une accroche***.

*Une ¬´¬†accroche¬†¬ª, c'est une phrase ou deux qui vont contenir la ou les deux notion(s) du sujet*. Son r√¥le est d'amener par √©tapes le lecteur vers la question que vous allez poser. Elle sert donc d'introduction √† l'introduction. Une accroche peut √™tre une citation (il y en a toujours dans un cours) ou un fait r√©cent (le ch√¥mage a-t-il baiss√© r√©cemment¬†? Un candidat √† l'√©lection pr√©sidentielle a-t-il dit qu'il fallait juger sa politique en fonction de son impact sur le niveau de ch√¥mage¬†?). Si on n'a pas de citation ou de fait relevant de l'actualit√©, on peut amener le sujet de fa√ßon plus habituelle.

Il est important d'√©viter un certain nombre de formules toutes faites et souvent utilis√©es comme ¬´¬†De tous temps\...¬†¬ª, ¬´¬†De tous temps, les hommes\...¬†¬ª ou encore les affirmations tr√®s g√©n√©rales (et que vous ne justifierez pas) comme¬†: ¬´¬†Le ch√¥mage est un ph√©nom√®ne √©conomique important, c'est pourquoi il faut l'√©tudier¬†¬ª. Le d√©faut de tous ces d√©buts d'accroche, c'est qu'ils peuvent servir pour n'importe quel sujet et que cela se voit.

On met une accroche parce que cela permet de mentionner les termes du sujet sans commencer directement par une d√©finition -- ce qui constitue l'√©tape suivante.

-   **D√©finition des termes du sujet**

L'accroche a introduit les notions, mais sans les d√©finir -- comme si tout le monde savait pr√©cis√©ment de quoi il s'agit (ce qui n'est pas si surprenant, on ne passe pas son temps √† d√©finir tous les mots qu'on utilise). Mais, pour utiliser les deux notions du sujet de fa√ßon un peu plus pr√©cise, il faut les d√©finir. Les d√©finitions que l'on va donner dans une introduction n'ont pas pour objectif de d√©finir les notions de mani√®re exhaustive ou dans l'absolu. Elles doivent permettre de comprendre le lien (ou l'opposition) entre les deux notions et orienter l'introduction de fa√ßon √† ce que l'on puisse construire le probl√®me -- avant de l'√©noncer (autrement dit, elles doivent ouvrir la voie aux deux √©tapes suivantes de l'introduction).

Du coup, les d√©finitions que l'on va donner vont d√©pendre du probl√®me que l'on souhaite atteindre.

-   **Construction du probl√®me**

Comme on sait √† quelle question on doit arriver (que cette question nous ait √©t√© donn√©e par le sujet ou que ce soit la question √† laquelle on est le mieux arm√© pour apporter une r√©ponse), il ne va pas √™tre difficile de passer des d√©finitions au probl√®me. Cela suppose juste de montrer qu'avec les d√©finitions que l'on vient de donner, il y a une question se pose avec force.

Encore une fois, cela peut sembler tr√®s artificiel (et √ßa l'est). Toutefois, l'int√©r√™t de cet aspect artificiel, c'est qu'il nous garantit que l'on ne va pas se perdre en chemin. Quand on fait une dissertation, on ne cherche pas son chemin¬†: on sait o√π on va et on ne fait qu'expliquer pourquoi on y va. Le sujet que l'on construit ne tombe pas du ciel, il vient de notre cours. Les d√©finitions ne tombent pas du ciel, elles donnent les √©l√©ments qui vont nous permettre de poser la question √† laquelle on sait d√©j√† comment on va r√©pondre. Bref, l'√©tape de construction du probl√®me est importante parce qu'elle montre que vous avez des aptitudes pour vous faire comprendre √† l'√©crit (et il ne faut surtout pas la n√©gliger), mais elle n'est pas une √©tape difficile ou magique.

Vous pourriez √™tre surpris que l'on construise le sujet, alors qu'il nous est parfois donn√© sous forme de question (dans les autres cas, on comprend mieux pourquoi il est n√©cessaire de construire le probl√®me). En fait, c'est une mani√®re de montrer que vous √™tes capable de vous approprier le sujet. Vous ne traitez pas le sujet parce qu'on vous l'a donn√© (m√™me si vous c'est une des raisons pour lesquelles vous faites une dissertation), mais parce que vous comprenez pourquoi la question se pose. Et comment mieux montrer qu'on comprend un probl√®me qu'en montrant en quoi il est probl√©matique ? Autrement dit, m√™me quand votre sujet a la forme d'une question, vous devez passer par l'√©tape de construction du sujet dans l'introduction.

-   **Enonc√© du probl√®me**

L'√©nonc√© du probl√®me doit prendre la forme d'une question. Il est le point final de l'√©tape juste pr√©c√©dente. Une fois qu'on a les √©l√©ments qui permettent de comprendre que le probl√®me se pose, il faut explicitement exprimer le probl√®me lui-m√™me. *On exprime toujours le probl√®me sous la forme d'une question (parce que c'est une mani√®re de montrer qu'il appelle une r√©ponse) et d'une question unique*. Poser deux, trois ou quatre questions ce serait soit redire plusieurs fois la m√™me chose (et si votre premi√®re question est claire, c'est inutile), soit poser (volontairement ou pas) plusieurs questions diff√©rentes. Or, vous ne pourrez pas r√©pondre convenablement et dans les r√®gles de la dissertation √† plusieurs questions en un seul devoir. Vous devrez donc choisir entre ne pas traiter certaines des questions que vous avez explicitement pos√©es (et dans ce cas pourquoi les poser explicitement) ou essayer de les traiter toutes (ce qui vous conduira √† un devoir dont la ligne directrice sera au mieux difficile √† suivre, au pire inexistante). Si on se rappelle du c√¥t√© formel et rh√©torique d'une dissertation, on comprend qu'il ne faut poser qu'une seule question¬†: celle √† laquelle vous apportez une r√©ponse.

Lorsque le sujet est une question, faut-il r√©p√©ter mot pour mot le sujet comme √©nonc√© du probl√®me¬†? Il y a deux √©coles¬†: la premi√®re dit qu'il faut reformuler la question pour montrer que vous la comprenez. Ainsi un sujet comme ¬´¬†Les d√©penses publiques permettent-elles de r√©duire le ch√¥mage¬†?¬†¬ª, on pourrait proposer une probl√©matique comme ¬´¬†les d√©penses publiques sont-elles efficaces √† court et √† long terme pour lutter contre le ch√¥mage¬†?¬†¬ª.

Si vous faites correctement votre travail de d√©finition des termes et de construction du sujet (dans les deux √©tapes pr√©c√©dentes), je pense qu'aucun correcteur ne vous reprochera de reprendre le sujet mot pour mot dans votre √©nonc√© du probl√®me. Ce qui pose probl√®me pour les partisans de la premi√®re fa√ßon de faire, c'est quand on peut se demander si l'√©tudiant comprend que la question qu'il pose est un probl√®me conceptuel, c'est-√†-dire qui vient d'une tension entre deux notions. Dans une introduction qui remplit correctement son r√¥le de construction du probl√®me, le fait de r√©p√©ter le sujet mot pour mot n'est pas un souci.

-   **Annonce du plan**

Une introduction doit toujours se terminer par une annonce du plan (ce n'est pas une option, c'est une obligation). L'annonce de plan dit √† votre lecteur comment vous allez r√©pondre au probl√®me que vous venez de poser. Dans une dissertation, on ne joue pas sur le suspens. On ne cherche pas √† surprendre son correcteur. Il faut donc annoncer le plan de mani√®re √† ce qu'il comprenne que vous allez r√©pondre au probl√®me pos√© par un raisonnement et qu'il comprenne aussi quels vont √™tre les principales √©tapes de votre raisonnement (c'est-√†-dire de votre devoir).

Vous allez donc annoncer vos (deux ou trois) grandes parties. Il est conseill√© fortement d'utiliser les formules (un peu lourdes en termes de style, mais tr√®s claires) ¬´¬†dans une premi√®re partie, nous montrerons que\...¬†¬ª, puis ¬´¬†dans une deuxi√®me partie, nous verrons que \...¬†¬ª. Quand vous ne le faites pas, il arrive trop souvent que votre lecteur ne sache pas si vous allez faire formellement deux ou trois parties -- pour peu que vous utilisiez des mots comme ¬´¬†et¬†¬ª, ¬´¬†puis¬†¬ª ou ¬´¬†ensuite¬†¬ª, qui peuvent aussi bien marquer des √©tapes √† l'int√©rieur d'une grande partie que le passage d'une partie √† une autre.

**La conclusion**

**Vous pourriez √™tre surpris de voir la conclusion arriver aussi t√¥t dans le devoir.** La raison, c'est qu'il est inconcevable de ne pas r√©pondre √† la question pos√©e en introduction -- si vous ne r√©pondez pas le devoir n'aura, litt√©ralement, servi √† rien. Or, il est √©vident qu'en partiel, on est souvent pris par le temps. On r√©dige donc la conclusion juste apr√®s avoir r√©dig√© l'introduction au brouillon (on la r√©dige aussi au brouillon, d'ailleurs). Comme √ßa si on est pris par le temps, on pourra recopier la conclusion d√©j√† pr√™te avant de rendre le devoir. S'il faut couper quelque chose en raison du temps limit√© de l'√©preuve, il vaut mieux couper un bout du d√©veloppement que rendre une dissertation sans conclusion.

La premi√®re phrase de votre conclusion doit apporter la r√©ponse √† la question que vous avez pos√©e en introduction. Elle doit le faire de fa√ßon absolument claire et donc il est conseill√© de reprendre exactement la question en la tournant en une phrase affirmative ou en une phrase n√©gative selon votre r√©ponse. *Le r√¥le de la conclusion, c'est de r√©pondre √† la question*. Il ne faut pas qu'on relise la conclusion en se demandant quelle √©tait la r√©ponse -- et m√™me en se demandant si une r√©ponse a √©t√© donn√©e. Cela ne vous emp√™che pas de donner une r√©ponse nuanc√©e, mais il faut une r√©ponse claire.

Une conclusion de dissertation ne r√©sume pas le devoir (on vient de le lire, c'est tout √† fait inutile). Une conclusion n'introduit jamais un √©l√©ment qui n'a pas √©t√© abord√© dans le devoir, mais qui aurait pu y √™tre discut√©. Si jamais votre correcteur n'a pas vu que vous avez oubli√© de parler de quelque chose d'important, vous n'allez tout de m√™me pas lui dire qu'il manque quelque chose dans votre devoir (chacun son boulot). La dissertation est un exercice de rh√©torique, votre objectif, c'est de convaincre votre lecteur¬†: ce n'est pas √† vous de dire qu'il manque quelque chose, m√™me si vous le savez.

On conseille parfois de finir sa dissertation sur une ouverture. Une ouverture est un nouveau probl√®me qui se pose une fois que vous avez r√©pondu au probl√®me de votre devoir. Cela revient √† sugg√©rer une autre dissertation possible une fois qu'on consid√®re votre r√©ponse comme accept√©e. Trop souvent, les √©tudiants finissent leurs devoirs de mani√®re particuli√®rement maladroite parce qu'ils ne comprennent pas ce qu'est une ouverture. Mon conseil est d'√©viter de faire une ouverture, au moins au d√©but¬†: ce n'est pas une obligation et cela peut donner une tr√®s mauvaise impression finale.

**La r√©daction du devoir**

Une fois tout cela fait, on prend sa copie (totalement vierge √† ce moment) et on commence √† √©crire dessus¬†: on recopie l'introduction, on r√©dige le d√©veloppement directement sur la copie (on ne r√©dige jamais son d√©veloppement sur le brouillon, cela prend beaucoup trop de temps √† recopier). *Le d√©veloppement du devoir doit contenir des titres apparents pour les parties et les sous-parties*. Cela signifie que le titre de votre grande partie est marqu√© dans votre copie (pr√©c√©d√© d'un ¬´¬†I)¬†¬ª) et qu'il est isol√© du texte et soulign√©. Bref, on doit pouvoir voir appara√Ætre d'un coup d'≈ìil votre plan en survolant votre copie du regard.

Comme dit juste au-dessus, si on manque de temps, on coupe une partie du d√©veloppement et on recopie la conclusion qui se trouve sur le brouillon. Attention¬†: si vous ne r√©digez pas tout le d√©veloppement, mettez tout de m√™me le plan apparent pour les parties et sous-parties non d√©velopp√©es. C'est pr√©cis√©ment parce qu'on a une id√©e de ce que vous auriez √©crit qu'il est possible (en cas de gros manque de temps) de ne pas r√©diger tout le d√©veloppement. Si vous ne d√©taillez pas votre plan, c'est la trame de votre raisonnement qui manque et c'est beaucoup plus ennuyeux. Si vous ne pouvez pas r√©diger tout le d√©veloppement, je vous conseille de mettre des √©l√©ments que vous auriez utilis√© sous forme de liste de tirets (en plus des titres apparents qui sont obligatoires).

