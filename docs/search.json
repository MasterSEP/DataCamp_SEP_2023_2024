[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SEP Guide",
    "section": "",
    "text": "Le module d’Implication dans la Vie Universitaire, fil rouge de la formation M2 Statistiques pour l’Évaluation et la Prévision, a pour but de montrer comment les étudiants peuvent s’investir dans la vie universitaire ou dans le monde associatif. Il a pour objectif la réalisation d’une mission d’utilité publique, qui va au-delà d’un module de cours classique en matière d’investissement dans un projet collectif et de prise d’initiative.\nLe SEP Guide est un projet réalisé par les étudiants pour les futurs candidats aux master SEP."
  },
  {
    "objectID": "index.html#pourquoi-un-tel-document",
    "href": "index.html#pourquoi-un-tel-document",
    "title": "SEP Guide",
    "section": "Pourquoi un tel document ?",
    "text": "Pourquoi un tel document ?\nLe Master SEP à la particularité de réunir des étudiants d’origines universitaires diverses car il regroupe des personnes particulièrement formées aux mathématiques avec d’autres qui ont suivi un parcours en économie. À noter également le recrutement ouvert à l’international qui fait que les programmes suivis par les étudiants dépendent également de leur pays de provenance.\nLe document sur lequel nous avons travaillé est donc particulièrement utile dans le but de préciser à tout nouvel étudiant en SEP les prérequis de la formation, la base commune de connaissances indispensable au bon suivi du Master."
  },
  {
    "objectID": "Economie.html",
    "href": "Economie.html",
    "title": "Prérequis d’Économie",
    "section": "",
    "text": "La macroéconomie est l’étude économique d’un système ou de phénomènes à un niveau global de l’économie.\n\n\n\nLa microéconomie se concentre sur l’observation et l’analyse des interactions à petite échelle.\n\n\n\n“Chose utile à satisfaire un besoin, il faut que le bien soit disponible et en quantité limitée.\nUn bien non économique est un bien qui s’obtient gratuitement, comme l’oxygène, contrairement à un bien économique qui s’obtient en payant.”\n\n\n\n“Un agent économique est un individu ou un groupe d’individus constituant un centre de décision économique indépendant.”\n\n\n\n\n\n\n\n\n“Le marché c’est une institution sociale qui permet l’échange entre l’offre et la demande.”\n\n\n\n“L’asymétrie d’information concerne les situations où les agents d’un marché ne possèdent pas de la même information sur un produit que ce soit au sujet de ses qualités ou de ses défauts”\n\n\n\nLa CPP repose sur cinq fondements :\n\nL’Atomicité du marché\n\nExistence d’un grand nombre d’agent économique sur le marché, à tel un point que ni l’offre ni la demande ne peut exercer une action quelconque sur la production et les prix ;\n\nL’Homogénéité des produits\n\nLa préférence d’un produit à un autre du point de vue de l’acheteur se fait uniquement selon son prix ;\n\nLibre entrée et sortie sur le marché\n\nAucune firme ne peut s’opposer à l’arrivée d’un concurrent sur le marché, tout le monde est libre de l’intégrer ;\n\nLibre circulation des facteurs de production\n\nLes facteurs de production (capital et travail) doivent être libre de se déplacer librement sans obstacle d’une industrie à l’autre ;\n\nLa transparence de l’information\n\nOffreurs et demandeurs sont parfaitement conscient des caractéristiques et prix des produits.\n\n\n\n“Le monopole est une situation dans un marché où un vendeur fait face aux multitudes vendeurs.”\n\n\n\n“La segmentation de marché est un découpage du marché en groupes homogènes selon des critères spécifiques, que ce soit des critères démographiques ou bien géo-graphiques.”\n\n\n\n“La discrimination par les prix est le pouvoir de pratiquer des prix différents pour un même produit, peut s’appliquer sur la quantité ou bien selon la segmentation du marché.”\n\n\n\n“L’utilité mesure le bien-être liée à la consommation d’un bien.”\n\n\n\n“L’Actualisation est un calcul permettant de transformer une valeur future en une valeur présente.”\nQue vaut aujourd’hui les X euros que j’aurais demain ?\n\\[\nV_a = \\frac{V_f}{(1+i)^t}\n\\]\n\\[\nV_a : Valeur\\ Actuelle\n\\]\n\\[\nV_f : Valeur\\ future\n\\] \\[\ni : Taux\\ sans\\ risque\\\\\n\\]\n\\[\nt : Temps\n\\]\n\n\n\nIl existe 4 grands problèmes macroéconomiques :\n\nCrises et récessions Ralentissement et/ou régression de l’activité économique ;\nInflations Augmentation générale et durable du niveau des prix entraînant une perte du pouvoir d’achat de la monnaie ;\nChômage Inactivité due au manque de travail ;\nProblème de l’équilibre extérieur Quand les importations sont plus importantes que les exportations, la balance commerciale est déséquilibrée."
  },
  {
    "objectID": "Economie.html#la-dissertation-en-économie",
    "href": "Economie.html#la-dissertation-en-économie",
    "title": "Prérequis d’Économie",
    "section": "La dissertation en économie",
    "text": "La dissertation en économie\n“On tient tout d’abord à remercier l’enseignant chercheur (en Philosophie économique, Théories économiques de la justice, Redistribution des revenus, Economie sociale, Economie publique), monsieur Jean-Sébastien Gharbi pour cette rubrique d’aide à la dissertation.”\n\n\n\n\n\nOn pense souvent que la dissertation en économie est un exercice difficile et qui récompense mal le travail. C’est totalement faux. La dissertation est un exercice dans lequel il est facile d’obtenir la moyenne, et même (avec un peu d’entraînement) d’obtenir systématiquement de très bonnes notes. C’est un exercice relativement facile parce que c’est un exercice en très grande partie formel : tout est une question de méthode.\nFaire une dissertation, c’est montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances pour répondre à une question de manière argumentée (c’est-à-dire sous la forme d’un raisonnement). Autrement dit :\n\nUne dissertation n’est pas une question de cours.\n\nLa première chose à faire, c’est de différencier question de cours et dissertation (qui sont souvent confondues). Une question de cours demande simplement de réciter un cours. Si vous ne faites que réciter votre cours dans un exercice de dissertation, vous aurez une mauvaise note. Pourquoi ? Parce que l’exercice de dissertation suppose de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances (dans un temps limité) – pas seulement de réciter une leçon apprise plus ou moins par cœur. Comme la question de cours, la dissertation suppose donc que vous savez des choses sur le sujet, mais il est important de comprendre que la dissertation porte tout autant sur votre aptitude à organiser vos idées que sur vos connaissances.\n\nDans une dissertation, la réponse donnée n’est pas importante !\n\nUne dissertation consiste toujours à répondre à une question. Les étudiants pensent parfois qu’il y a une « bonne » réponse à la question posée – qu’il s’agirait de trouver. D’ailleurs, cela contribue à l’idée (fausse) que la dissertation est un exercice aléatoire : si vous ne trouvez pas la bonne réponse, vous avez perdu. Cela aussi est faux : il n’y a (en général) pas de « bonne » réponse à la question posée par la dissertation. L’exercice de dissertation vient de la philosophie. Pensez-vous sérieusement que l’on puisse demander à un étudiant (ou à un professeur, d’ailleurs) de régler de façon définitive un débat philosophique qui a donné lieu à des controverses pendant des siècles en trois, quatre ou même sept heures ? La réponse évidente est « non ».\n\nDans une dissertation, le plus important c’est l’argumentation !\n\nSi on ne s’intéresse pas à la réponse donnée. C’est tout simplement, parce que ce qui intéresse votre lecteur, c’est la manière dont vous répondez : votre aptitude à utiliser vos connaissances de manière argumentative pour défendre une conclusion. Sur le principe, il serait donc possible de défendre une conclusion choquante ou même offensante dans une dissertation, pour la bonne raison qu’on n’évalue pas la réponse que vous donnez, mais la manière dont vous amenez votre réponse. Votre réponse, à la limite, on ne s’y intéresse pas. Une fois cela dit, il est assez évident qu’il est beaucoup plus facile de défendre une position modérée et consensuelle, qu’une position offensante pour de nombreuses personnes. C’est la raison pour laquelle, il n’est pas du tout conseillé de chercher la provocation gratuite dans une dissertation.\nComment on fait une dissertation ?\n\n\n\n\n\n\nAnalyse du sujet\nL’analyse du sujet est la première étape de la dissertation et l’une des plus importantes. Une dissertation se présente sous la forme d’un sujet. Il faut isoler la ou les deux notions principales du sujet.\nIl y a quatre grands types de sujets : les sujets ne contenant qu’une seule notion (ex : « Les discriminations en France »), les couples de notions (ex : « Capitalisme et démocratie »), les citations (ex : « Le système de production capitaliste est une démocratie économique dans laquelle chaque sou donne un droit de vote. Les consommateurs constituent le peuple souverain », Ludwig von Mises) ou une question (ex : « La croissance économique s’oppose-t-elle à la préservation de l’environnement ? »).\nDans tous les cas, l’objectif est d’arriver à une question (donc les sujets les plus simples à traiter à ce stade, ce sont les questions : ils vous donnent immédiatement le problème à traiter). Mais la première chose à faire (même quand on a déjà la question), c’est de trouver le couple de notions impliquées dans le sujet. Souvent, c’est absolument évident, mais parfois il faut un peu chercher.\nIl faut éviter à tout prix de faire un exposé quand on attend de vous une dissertation. Un hors-sujet, c’est de ne pas traiter le bon sujet. Si vous répondez de manière factuelle à un sujet de dissertation, vous faites pire : vous faites un hors-exercice.\n\n\nRecherche des idées\nUne fois qu’on a identifié un couple de notions, il faut (au brouillon) essayer de faire la liste des éléments du cours qui relient les deux notions. Il est important de ne noter que les éléments qui relient les deux notions (pour ne pas risquer de se perdre dans des éléments qui concernent seulement une seule des deux notions). Sur chacune des notions que vous aurez à traiter en dissertation, on a écrit des livres entiers. Il est impossible de tout dire dessus dans une dissertation. On se limite donc à ce qui relie les deux notions de notre sujet. Évidemment, si un élément pertinent vous vient en tête et qu’il ne se trouve pas dans votre cours, n’hésitez pas à le noter. Si cet élément peut être utilisé dans votre raisonnement, même comme exemple, ce sera un plus indiscutable.\nDans un premier temps, on note tout ce qui se présente à l’esprit. Ce n’est que dans un deuxième temps, quand on a un certain nombre d’éléments que l’on se pose la question : « Est-ce qu’il y a une manière qui saute aux yeux de relier tous ces éléments en répondant à la question (si elle a été posée de manière directe) ou pour répondre à une question comprenant le couple de notions (si la question n’a pas été formulée dans le sujet) ? ». Si la réponse est positive, on a trouvé la question qui structurera notre devoir. Si ce n’est pas le cas, il faut essayer de trouver une question qui relie le plus grand nombre des éléments que l’on a noté sur son brouillon – et donc laisser de côté les éléments qui ne servent pas. Il arrive souvent qu’une partie des éléments que l’on note sur son brouillon ne soit pas utilisée dans le devoir. Bref, si notre sujet est un couple de notions ou une citation, il faut que l’on arrive à une question. Évidemment, quand notre sujet est déjà une question, on n’a pas autant de marge de manœuvre, mais en vérité, si on vous pose une question précise, c’est que vous avez les éléments pour y répondre dans le cours (donc la différence n’est pas très importante).\n\n\nMise en évidence d’un problème\nPuisqu’elle ne doit pas être une question de fait, la question qui relie le plus d’éléments possibles parmi ceux qui associent les deux notions dans votre cours doit être une question conceptuelle. Pour le dire autrement, cette question doit être un problème (on parle souvent de « problématique » pour désigner ce problème dans le cadre d’une dissertation). Qu’est-ce qu’un problème ? C’est une question qui met en tension deux concepts et qui analyse les différents aspects de leur relation (conceptuelle).\nSouvent les étudiants ont peur de ne pas trouver le « bon » problème. Pourtant, si on suit la méthode de dissertation, il n’y a pas de risque de se tromper. En effet, on ne doit pas choisir un problème d’abord (sans savoir si on a de quoi le traiter) et le traiter ensuite. Vous aurez noté qu’on procède exactement dans le sens inverse : on voit à quelle question on peut répondre avec les éléments qu’on a sur son brouillon et on pose précisément la question à laquelle on sait qu’on peut répondre.\n\n\nConstruction du plan\nPour la même raison qu’au-dessus, la construction du plan ne doit pas être très difficile : il s’agit de rassembler les différents éléments qui permettent de répondre à la question (au problème que l’on va poser) de façon à y apporter une réponse.\nOn va apporter la réponse que les éléments disponibles nous permettent d’atteindre. Il y a une seule contrainte : votre plan doit être suffisamment détaillé. Comme l’objectif de la dissertation, c’est de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances. Si vous ne faites que deux parties sans sous-parties à l’intérieur (il n’y aurait donc qu’une seule articulation logique), on trouvera que vous n’avez pas assez structuré votre devoir. Le découpage minimal, c’est d’avoir quatre éléments (en général, on fait deux grandes parties avec deux sous-parties chacune, donc on a trois articulations).\nVos parties et vos sous-parties doivent correspondre à des étapes de votre raisonnement (on dit souvent qu’il faut une idée par sous-partie), donc votre plan doit donner la structure du raisonnement grâce auquel vous allez répondre à la question posée. Le plan (qui est annoncé à la fin de l’introduction et qui doit être apparent dans le devoir, nous reviendrons sur ce point un peu plus loin) doit permettre de comprendre la structure de votre devoir d’un coup d’œil – simplement en lisant les titres.\nUn élément qui permet de savoir si votre plan est bon, c’est de se demander si à la fin de la première partie, on est arrivé à un état de la réflexion différent de celui de la fin de l’introduction.\nQu’est-ce que la première partie a permis de comprendre ? Et est-ce que la seconde partie apporte quelque chose d’autre ? Si chaque partie représente une étape dans un raisonnement et que votre devoir complet est donc un raisonnement, votre plan est forcément bon : vu que c’est précisément ce qu’on attend de vous.\nIl ne faut jamais faire deux sous-parties dans une partie sous la forme d’une seule phrase coupée par des points de suspension (ex : « A) L’organisation scientifique du travail a permis la croissance des trente glorieuses… », « B) mais, elle a aussi eu des conséquences négatives, notamment sur le plan social »). En effet, cela revient à pointer du doigt que vous opérez une coupure arbitraire (donc que vous n’articulez pas de manière assez nette les différentes parties de votre devoir). Sur le principe, les deux sous-parties sont reliées par les points de suspension et donc ne forment qu’une partie sans coupure. Préférez toujours les titres qui se succèdent sans être grammaticalement liés les uns aux autres. Dans l’exemple ci-dessus, il suffit de faire deux phrases pour découper les deux idées. Si on ne peut pas couper grammaticalement les deux titres, c’est la preuve que l’articulation pose problème.\nDans l’idéal, un plan est équilibré : chaque partie comprend le même nombre de sous-parties que l’autre et elles font à peu près la même longueur. Et si vous faites plus de sous-parties dans une partie que dans l’autre, il faut que les sous-parties soient un peu plus longues dans la partie qui contient moins de sous-parties. Remarquez que si vous faites un plan avec deux parties, deux sous-parties, ce dernier problème ne se pose pas.\nUn point important et souvent totalement négligé par les étudiants : même quand c’est tentant, on ne fait jamais de plan centré sur les auteurs. Un plan par auteurs conduit très souvent à suivre l’ordre chronologique et à présenter les positions des auteurs sans les confronter réellement les unes aux autres . Ce qui doit structurer le plan, ce sont les concepts (c’est-à-dire les notions qui nous avaient permis de construire le problème à résoudre).\nEn réalité, il n’est pas rare qu’on suive plus ou moins l’ordre chronologie, mais il est essentiel de se focaliser sur les concepts, et pas sur les auteurs. Pourquoi ? Parce que l’enchaînement ou l’opposition de concepts constitue un raisonnement (ce que vous devez faire !), alors que l’enchaînement ou l’opposition d’auteurs constitue un exposé (ce que vous ne devez pas faire !). En réalité, c’est assez facile à faire il suffit de s’interdire de mentionner le nom des auteurs dans les titres de partie ou de sous-partie.\nVu que l’objectif du plan, c’est de répondre à une question qui met les deux notions du sujet en relation, les parties (ou les sous-parties) qui se focalisent sur une seule des deux notions sont à éviter à tout prix : elles sont simplement hors-sujet. Sur un sujet comme « capitalisme et démocratie », le plan « première partie : capitalisme », « deuxième partie : démocratie » est parmi les pires possibles.\nJusqu’à présent, nous n’avons encore rien écrit sur la copie elle-même. Nous n’avons travaillé que sur le brouillon. Nous avons deux notions clés, un problème et un plan. Ce sont les éléments fondamentaux du devoir. Il faut à présent passer à la rédaction. Nous allons nous intéresser d’abord à l’introduction.\n\n\nLa rédaction\n(Introduction, Conclusion, Développement)\nL’introduction est la partie la plus importante de la dissertation. Elle permet de savoir pourquoi le problème se pose, comment il se pose et comment il va être résolu. A quoi sert l’introduction ?\nLe rôle de l’introduction, sa raison d’être, c’est de construire et d’énoncer le problème (la problématique) auquel le reste du devoir va répondre. Il ne suffit donc pas de poser la question (pour cela deux lignes suffiraient) et de commencer le développement. L’introduction, comme son nom le dit très bien, va introduire le problème, c’est-à-dire qu’elle va nous y amener, rapidement, certes, mais en plusieurs étapes très codifiées.\nUne introduction de dissertation comprend obligatoirement (au minimum) cinq éléments : une accroche, une définition des termes du sujets, la construction du problème, l’énoncé du problème et l’annonce du plan. Comme une introduction de dissertation fait entre 20 lignes et une page et demie (grand maximum), il faut être efficace.\n\nL’accroche\n\nUne introduction de dissertation suit des règles assez rigides. Elle commence toujours par une accroche.\nUne « accroche », c’est une phrase ou deux qui vont contenir la ou les deux notion(s) du sujet. Son rôle est d’amener par étapes le lecteur vers la question que vous allez poser. Elle sert donc d’introduction à l’introduction. Une accroche peut être une citation (il y en a toujours dans un cours) ou un fait récent (le chômage a-t-il baissé récemment ? Un candidat à l’élection présidentielle a-t-il dit qu’il fallait juger sa politique en fonction de son impact sur le niveau de chômage ?). Si on n’a pas de citation ou de fait relevant de l’actualité, on peut amener le sujet de façon plus habituelle.\nIl est important d’éviter un certain nombre de formules toutes faites et souvent utilisées comme « De tous temps... », « De tous temps, les hommes... » ou encore les affirmations très générales (et que vous ne justifierez pas) comme : « Le chômage est un phénomène économique important, c’est pourquoi il faut l’étudier ». Le défaut de tous ces débuts d’accroche, c’est qu’ils peuvent servir pour n’importe quel sujet et que cela se voit.\nOn met une accroche parce que cela permet de mentionner les termes du sujet sans commencer directement par une définition – ce qui constitue l’étape suivante.\n\nDéfinition des termes du sujet\n\nL’accroche a introduit les notions, mais sans les définir – comme si tout le monde savait précisément de quoi il s’agit (ce qui n’est pas si surprenant, on ne passe pas son temps à définir tous les mots qu’on utilise). Mais, pour utiliser les deux notions du sujet de façon un peu plus précise, il faut les définir. Les définitions que l’on va donner dans une introduction n’ont pas pour objectif de définir les notions de manière exhaustive ou dans l’absolu. Elles doivent permettre de comprendre le lien (ou l’opposition) entre les deux notions et orienter l’introduction de façon à ce que l’on puisse construire le problème – avant de l’énoncer (autrement dit, elles doivent ouvrir la voie aux deux étapes suivantes de l’introduction).\nDu coup, les définitions que l’on va donner vont dépendre du problème que l’on souhaite atteindre.\n\nConstruction du problème\n\nComme on sait à quelle question on doit arriver (que cette question nous ait été donnée par le sujet ou que ce soit la question à laquelle on est le mieux armé pour apporter une réponse), il ne va pas être difficile de passer des définitions au problème. Cela suppose juste de montrer qu’avec les définitions que l’on vient de donner, il y a une question se pose avec force.\nEncore une fois, cela peut sembler très artificiel (et ça l’est). Toutefois, l’intérêt de cet aspect artificiel, c’est qu’il nous garantit que l’on ne va pas se perdre en chemin. Quand on fait une dissertation, on ne cherche pas son chemin : on sait où on va et on ne fait qu’expliquer pourquoi on y va. Le sujet que l’on construit ne tombe pas du ciel, il vient de notre cours. Les définitions ne tombent pas du ciel, elles donnent les éléments qui vont nous permettre de poser la question à laquelle on sait déjà comment on va répondre. Bref, l’étape de construction du problème est importante parce qu’elle montre que vous avez des aptitudes pour vous faire comprendre à l’écrit (et il ne faut surtout pas la négliger), mais elle n’est pas une étape difficile ou magique.\nVous pourriez être surpris que l’on construise le sujet, alors qu’il nous est parfois donné sous forme de question (dans les autres cas, on comprend mieux pourquoi il est nécessaire de construire le problème). En fait, c’est une manière de montrer que vous êtes capable de vous approprier le sujet. Vous ne traitez pas le sujet parce qu’on vous l’a donné (même si vous c’est une des raisons pour lesquelles vous faites une dissertation), mais parce que vous comprenez pourquoi la question se pose. Et comment mieux montrer qu’on comprend un problème qu’en montrant en quoi il est problématique ? Autrement dit, même quand votre sujet a la forme d’une question, vous devez passer par l’étape de construction du sujet dans l’introduction.\n\nEnoncé du problème\n\nL’énoncé du problème doit prendre la forme d’une question. Il est le point final de l’étape juste précédente. Une fois qu’on a les éléments qui permettent de comprendre que le problème se pose, il faut explicitement exprimer le problème lui-même. On exprime toujours le problème sous la forme d’une question (parce que c’est une manière de montrer qu’il appelle une réponse) et d’une question unique. Poser deux, trois ou quatre questions ce serait soit redire plusieurs fois la même chose (et si votre première question est claire, c’est inutile), soit poser (volontairement ou pas) plusieurs questions différentes. Or, vous ne pourrez pas répondre convenablement et dans les règles de la dissertation à plusieurs questions en un seul devoir. Vous devrez donc choisir entre ne pas traiter certaines des questions que vous avez explicitement posées (et dans ce cas pourquoi les poser explicitement) ou essayer de les traiter toutes (ce qui vous conduira à un devoir dont la ligne directrice sera au mieux difficile à suivre, au pire inexistante). Si on se rappelle du côté formel et rhétorique d’une dissertation, on comprend qu’il ne faut poser qu’une seule question : celle à laquelle vous apportez une réponse.\nLorsque le sujet est une question, faut-il répéter mot pour mot le sujet comme énoncé du problème ? Il y a deux écoles : la première dit qu’il faut reformuler la question pour montrer que vous la comprenez. Ainsi un sujet comme « Les dépenses publiques permettent-elles de réduire le chômage ? », on pourrait proposer une problématique comme « les dépenses publiques sont-elles efficaces à court et à long terme pour lutter contre le chômage ? ».\nSi vous faites correctement votre travail de définition des termes et de construction du sujet (dans les deux étapes précédentes), je pense qu’aucun correcteur ne vous reprochera de reprendre le sujet mot pour mot dans votre énoncé du problème. Ce qui pose problème pour les partisans de la première façon de faire, c’est quand on peut se demander si l’étudiant comprend que la question qu’il pose est un problème conceptuel, c’est-à-dire qui vient d’une tension entre deux notions. Dans une introduction qui remplit correctement son rôle de construction du problème, le fait de répéter le sujet mot pour mot n’est pas un souci.\n\nAnnonce du plan\n\nUne introduction doit toujours se terminer par une annonce du plan (ce n’est pas une option, c’est une obligation). L’annonce de plan dit à votre lecteur comment vous allez répondre au problème que vous venez de poser. Dans une dissertation, on ne joue pas sur le suspens. On ne cherche pas à surprendre son correcteur. Il faut donc annoncer le plan de manière à ce qu’il comprenne que vous allez répondre au problème posé par un raisonnement et qu’il comprenne aussi quels vont être les principales étapes de votre raisonnement (c’est-à-dire de votre devoir).\nVous allez donc annoncer vos (deux ou trois) grandes parties. Il est conseillé fortement d’utiliser les formules (un peu lourdes en termes de style, mais très claires) « dans une première partie, nous montrerons que... », puis « dans une deuxième partie, nous verrons que ... ». Quand vous ne le faites pas, il arrive trop souvent que votre lecteur ne sache pas si vous allez faire formellement deux ou trois parties – pour peu que vous utilisiez des mots comme « et », « puis » ou « ensuite », qui peuvent aussi bien marquer des étapes à l’intérieur d’une grande partie que le passage d’une partie à une autre.\nLa conclusion\nVous pourriez être surpris de voir la conclusion arriver aussi tôt dans le devoir. La raison, c’est qu’il est inconcevable de ne pas répondre à la question posée en introduction – si vous ne répondez pas le devoir n’aura, littéralement, servi à rien. Or, il est évident qu’en partiel, on est souvent pris par le temps. On rédige donc la conclusion juste après avoir rédigé l’introduction au brouillon (on la rédige aussi au brouillon, d’ailleurs). Comme ça si on est pris par le temps, on pourra recopier la conclusion déjà prête avant de rendre le devoir. S’il faut couper quelque chose en raison du temps limité de l’épreuve, il vaut mieux couper un bout du développement que rendre une dissertation sans conclusion.\nLa première phrase de votre conclusion doit apporter la réponse à la question que vous avez posée en introduction. Elle doit le faire de façon absolument claire et donc il est conseillé de reprendre exactement la question en la tournant en une phrase affirmative ou en une phrase négative selon votre réponse. Le rôle de la conclusion, c’est de répondre à la question. Il ne faut pas qu’on relise la conclusion en se demandant quelle était la réponse – et même en se demandant si une réponse a été donnée. Cela ne vous empêche pas de donner une réponse nuancée, mais il faut une réponse claire.\nUne conclusion de dissertation ne résume pas le devoir (on vient de le lire, c’est tout à fait inutile). Une conclusion n’introduit jamais un élément qui n’a pas été abordé dans le devoir, mais qui aurait pu y être discuté. Si jamais votre correcteur n’a pas vu que vous avez oublié de parler de quelque chose d’important, vous n’allez tout de même pas lui dire qu’il manque quelque chose dans votre devoir (chacun son boulot). La dissertation est un exercice de rhétorique, votre objectif, c’est de convaincre votre lecteur : ce n’est pas à vous de dire qu’il manque quelque chose, même si vous le savez.\nOn conseille parfois de finir sa dissertation sur une ouverture. Une ouverture est un nouveau problème qui se pose une fois que vous avez répondu au problème de votre devoir. Cela revient à suggérer une autre dissertation possible une fois qu’on considère votre réponse comme acceptée. Trop souvent, les étudiants finissent leurs devoirs de manière particulièrement maladroite parce qu’ils ne comprennent pas ce qu’est une ouverture. Mon conseil est d’éviter de faire une ouverture, au moins au début : ce n’est pas une obligation et cela peut donner une très mauvaise impression finale.\nLa rédaction du devoir\nUne fois tout cela fait, on prend sa copie (totalement vierge à ce moment) et on commence à écrire dessus : on recopie l’introduction, on rédige le développement directement sur la copie (on ne rédige jamais son développement sur le brouillon, cela prend beaucoup trop de temps à recopier). Le développement du devoir doit contenir des titres apparents pour les parties et les sous-parties. Cela signifie que le titre de votre grande partie est marqué dans votre copie (précédé d’un « I) ») et qu’il est isolé du texte et souligné. Bref, on doit pouvoir voir apparaître d’un coup d’œil votre plan en survolant votre copie du regard.\nComme dit juste au-dessus, si on manque de temps, on coupe une partie du développement et on recopie la conclusion qui se trouve sur le brouillon. Attention : si vous ne rédigez pas tout le développement, mettez tout de même le plan apparent pour les parties et sous-parties non développées. C’est précisément parce qu’on a une idée de ce que vous auriez écrit qu’il est possible (en cas de gros manque de temps) de ne pas rédiger tout le développement. Si vous ne détaillez pas votre plan, c’est la trame de votre raisonnement qui manque et c’est beaucoup plus ennuyeux. Si vous ne pouvez pas rédiger tout le développement, je vous conseille de mettre des éléments que vous auriez utilisé sous forme de liste de tirets (en plus des titres apparents qui sont obligatoires)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction au Data Camp",
    "section": "",
    "text": "Le module d’Implication dans la Vie Universitaire, fil rouge de la formation M2 Statistiques pour l’Évaluation et la Prévision, a pour but de montrer comment les étudiants peuvent s’investir dans la vie universitaire ou dans le monde associatif. Il a pour objectif la réalisation d’une mission d’utilité publique, qui va au-delà d’un module de cours classique en matière d’investissement dans un projet collectif et de prise d’initiative."
  },
  {
    "objectID": "intro.html#pourquoi-un-tel-document",
    "href": "intro.html#pourquoi-un-tel-document",
    "title": "Introduction au Data Camp",
    "section": "Pourquoi un tel document ?",
    "text": "Pourquoi un tel document ?\nLe Master SEP à la particularité de réunir des étudiants d’origines universitaires diverses car il regroupe des personnes particulièrement formées aux mathématiques avec d’autres qui ont suivi un parcours en économie. À noter également le recrutement ouvert à l’international qui fait que les programmes suivis par les étudiants dépendent également de leur pays de provenance.\nLe document sur lequel nous avons travaillé est donc particulièrement utile dans le but de préciser à tout nouvel étudiant en SEP les prérequis de la formation, la base commune de connaissances indispensable au bon suivi du Master."
  },
  {
    "objectID": "Mathématiques.html",
    "href": "Mathématiques.html",
    "title": "Prérequis des mathématiques",
    "section": "",
    "text": "Ici, sera listé les pré-requis nécessaires pour le master SEP.\nNous allons commencer par les bases des probabilités, de l’algèbre linéaire et des statisitques."
  },
  {
    "objectID": "Mathématiques.html#statistique-inférentielle",
    "href": "Mathématiques.html#statistique-inférentielle",
    "title": "Prérequis des mathématiques",
    "section": "Statistique inférentielle",
    "text": "Statistique inférentielle\n\nL’échantillonnage\nSoit X une v.a. sur \\(\\Omega\\) . Un échantillon de X de taille n est un n-uplet \\((X_i , …, X_n)\\) de v.a. iid.\nUne réalisation de cet échantillon est un n-uplet de réels \\((x_1, …, x_n)\\) où \\(X_i(\\omega) = x_i\\).\n\n\nEstimateur\nUn estimateur de \\(\\theta\\) est une statistique \\(\\widehat{\\theta}\\) (donc une fonction de \\((X_1, …, X_n)\\)) qui ne dépend pas de \\(\\theta\\) et dont la réalisation est envisagée comme une “bonne valeur” du paramètre \\(\\theta\\).\n\n\nRisque quadratique\nLa qualité d’un estimateur est mesurée à travers son risque quadratique définie par :\n\\[\nR_{\\widehat{\\theta}}(\\theta) = V(\\widehat{\\theta}) + b_{\\widehat{\\theta}}^2(\\theta)\n\\]\n\n\nBiais\nOn appelle biais d’un estimateur \\(\\widehat{\\theta}\\) pour \\(\\theta\\) la valeur :\n\\[\nb_{\\widehat{\\theta}}(\\theta) = E(\\widehat{\\theta}) - \\theta\n\\]\nUn estimateur T est dit sans biais si :\n\\[\nE(\\widehat{\\theta}) = \\theta\n\\]\n\n\nStatistique\nOn appelle statistique sur un n-échantillon une fonction mesurable de \\((X_1, …, X_n)\\) ne dépendant pas de \\(\\theta\\).\n\n\nConsistance\nUn estimateur \\(\\widehat{\\theta}\\) est dit fortement consistant s’il converge en presque-sûrement vers \\(\\theta\\) lorsque \\(n\\rightarrow +\\infty\\).\n\n\nMoyenne empirique\nOn appelle moyenne de l’échantillon ou moyenne empirique, la statistique notée \\(\\bar{X}\\) définie par :\n\\[\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n\\]\n\n\nVariance empirique\nOn appelle variance empirique non biaisée, la statistique notée \\(S_n^2\\) définie par :\n\\[\nS_n^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i\\ -\\ \\bar{X})\n\\]\n\n\nEstimation par la méthode du maximum de vraisemblance\nOn appelle fonction de vraisemblance de \\(\\theta\\) d’un n-échantillon, la fonction suivante :\n\\[\nV_{x_1, ..., x_n}(\\theta) = f_{x_1, ..., x_n}(x_1, ..., x_n) = \\prod_{i=1}^nf_{x_1,\\theta}(x_i)\n\\]\navec\n\\[\nf_{x_1,\\theta}(x_i) = \\left\\{\n    \\begin{array}{ll}\n       f_{X,\\theta}(x)\\ lorsque\\ X\\ est\\ une\\ v.a.\\ continue\\ de \\ densité\\ f_{X,\\theta}\\\\\n       P_{X,\\theta}(x)\\ lorsque\\ X\\ est\\ une\\ v.a.\\ discrète\\ de\\ probabilité\\ ponctuelle\\ P_{X,\\theta}\n    \\end{array}\n\\right.\n\\]\nLa méthode consistant à estimer \\(\\theta\\) par la valeur qui maximise V (vraisemblance) s’appelle méthode du maximum de vraisemblance.\nLes étapes à suivre sont les suivantes :\n\nCalculer la fonction de vraisemblance ci-dessus;\nCalculer le log de la fonction de vraisemblance noté L;\nCalculer la dérivée de la log-vraisemblance obtenue par rapport à \\(\\theta\\);\nTrouver la valeur \\(\\widehat{\\theta}\\) qui annule la dérivée;\nVérifier que la dérivée seconde par rapport à \\(\\theta\\) est négative en \\(\\widehat{\\theta}\\).\n\nEn résumé, si la dérivée première s’annulle en \\(\\theta = \\widehat{\\theta}\\) et que la dérivée seconde est négative en \\(\\theta = \\widehat{\\theta}\\), alors \\(\\widehat{\\theta}\\) est un maximum local de \\(V_{x_1, …, x_n}(\\theta\\)).\n\n\nIntervalle de confiance\nUn intervalle de confiance permet d’avoir une idée de la marge d’erreur de l’échantillon représentatif sélectionné. En estimant cette marge d’erreur, on est donc en mesure de faire une estimation assez précise de ce qu’aurait été le résultat réel.\n\n\n\n\n\n\n\nTest d’hypothèses\nUn test d’hypothèses sert à répondre à une question donnant 2 résultats alternatives complémentaires. Il faut alors définir :\n\nLa question (des hypothèses);\nUne façon d’y répondre (une règle de décision).\n\n\n\nHypothèse\nUne hypothèse est un ensemble de valeurs des paramètres inconnus de la population.\nDans une question, on distingue en général deux hypothèses étant :\n\nUne hypothèse nulle, notée \\(H_o\\) :\n\\[\nH_o : \\theta\\ \\in\\ \\theta_o\n\\]\nUne hypothèse alternative, notée \\(H_1\\):\n\\[\nH_1 : \\theta\\ \\notin\\ \\theta_0\n\\]\n\nAvec \\(\\theta_o\\) une valeur spécifiée pour un paramètre \\(\\theta\\) de la population.\n\n\nTest et test paramétrique\nUn test est la donnée d’un jeu d’hypothèse et d’une règle de décision.\nUn test peut être unilatéral si l’hypothèse \\(H_1\\) s’exprime sous forme d’inégalités strictes ou bilatéral si \\(H_1\\) s’exprime sous forme de différences (\\(\\neq\\)).\nUn test paramétrique est un test pour lequel des hypothèses sur la distribution des populations sont requises.\n\n\nErreurs et risques\nLorsqu’on prend l’hypothèse nulle, la valeur estimée \\(\\theta_o\\) pour un paramètre \\(\\theta\\) de la population peut conduire à des erreurs. Ces erreurs sont habituellement classés en 2 catégories :\n\nL’erreur de première espèce;\nL’erreur de seconde espèce\n\nChaque erreur entraine un risque qui lui correspond :\n\nLe risque de première espèce, notée \\(\\alpha\\), est le risque de rejeter l’hypothèse \\(H_o\\) alors qu’en réalité cette hypothèse est vraie;\nLe risque de seconde espèce, notée \\(\\gamma\\), est le risque d’accepter l’hypothèse \\(H_o\\) alors qu’en réalité cette hypothèse est fausse\n\nLe tableau suivant résume l’ensemble des couples (décisions/réalités) possibles :\n\n\n\n\n\nLa quantité \\(\\beta\\) est une probabilité de bonne décision appelée puissance du test.\nLien utile : Récapitulatif des tests statistiques"
  },
  {
    "objectID": "Mathématiques.html#econométrie",
    "href": "Mathématiques.html#econométrie",
    "title": "Prérequis des mathématiques",
    "section": "Econométrie",
    "text": "Econométrie\n\nModèle linéaire\nOn cherche à expliquer / prédire une variable \\(Y_i\\) à l’aide de p variables aléatoires \\(X_i^{(1)}, …, X_i^{(p)}\\).\nOn considère le modèle :\n\\[\nY_i = X_i^{(1)}\\beta_1\\ +\\ ...\\ +\\ X_i^{(p)}\\beta_p\\ +\\ \\epsilon_i,\\ \\forall i\\ \\in\\ [1;n].\n\\]\nPour déterminer les paramètres à estimer du modèle, il est plus simple d’écrire le modèle sous forme matricielle :\n\\[\nY = X\\beta\\ +\\ \\epsilon\n\\]\n\\(Y \\in R^n\\) est appelée variable endogène, c’est à dire la variable à expliquer ou prédire.\n\\(X \\in M_{n,p}(R)\\) et contient les \\(X_i^{(1)}, …, X_i^{(p)}\\) qui sont appelées variables exogènes, c’est à dire les variables explicatives.\n\\(\\beta \\in R^p\\) contient les paramètres à estimer du modèle.\n\\(\\epsilon \\in R^p\\) contient le terme d’erreur du modèle non observable.\n\n\nHypothèses sur les erreurs\n4 hypothèses sur les erreurs sont à vérifier dans le cadre d’un modèle linéaire OLS :\n\n\\(\\forall i \\in [1;n];\\ E(\\epsilon_i) = 0\\) : les erreurs sont centrées;\n\\(\\forall i \\in [1;n];\\ V(\\epsilon_i) = \\sigma^2\\) : les erreurs sont homoscédastiques;\n\\(\\forall i\\neq j \\in [1; n]; E(\\epsilon_i,\\epsilon_j) = 0\\) : les erreurs ne sont pas auto-corrélées;\n\\(\\forall i \\in [1;n]; \\epsilon_i\\ ∼ N(0,\\sigma^2)\\) : les erreurs sont normalement distribuées.\n\n\n\nHypothèses structurelle\nDans le cadre d’un modèle linéaire OLS, on doit retrouver 3 hypothèses structurelles :\n\nLes variables \\(X_1, …, X_p\\) sont orthogonales à \\(\\epsilon\\);\nLes variables \\(X_1, …, X_p\\) forment une base de \\(R^{p+1}\\);\nn &gt; p+1.\n\n\n\nDécomposition de la variance\n\n\n\n\n\nL’équation d’analyse de la variance est : SCT = SCE + SCR, cela veut dire que la somme des carrées totale = somme des carrées expliquée + la somme des carrées résiduelle.\n\n\nCoefficient de détérmination\nLe coefficient de détérmination noté \\(R^2\\) est défini par :\n\\[\nR^2 = \\frac{SCE}{SCR}.\n\\]"
  },
  {
    "objectID": "Programmation.html",
    "href": "Programmation.html",
    "title": "Liens utiles pour la programmation",
    "section": "",
    "text": "Dans cette partie vous devrez apprendre de manière autonome, mais ne vous inquiétez pas, vous serez tout de même guidés par des cheatsheets et des cours en ligne de qualité."
  },
  {
    "objectID": "Programmation.html#installation",
    "href": "Programmation.html#installation",
    "title": "Liens utiles pour la programmation",
    "section": "Installation",
    "text": "Installation\n\nPython\nPython est l’un des langages de programmation les plus utilisés. Apprendre à coder avec Python est une compétence très recherchée dans le monde de la Data science !\n\n\n\n\n\nInstallation de Python\nInstallation d’Anaconda\n\n\nR et R studio\nDans le domaine de l'analyse statistique, R est un des langages de programmation les plus utilisés et en même temps l'un des langages les plus simples à apprendre ! Il est particulièrement puissant pour l'analyse et la visualisation des données.\n\n\n\n\n\nInstallation de R\nInstallation de R studio\n\n\nSAS\n\n\n\n\n\nCréer un compte chez SAS, en utilisant votre adresse e-mail universitaire.\nIl est possible d’installer la version virtuelle SAS gratuite universitaire. Cette version est compatible avec tous les OS y compris Mac.\nSuivez les instructions pour Installer SAS University pour l’utiliser sur une machine virtuelle. Toutes les étapes y sont bien expliquées.\nUne autre alternative est d’utiliser SAS Studio. Suivez les instructions pour l’inscription à SAS ON DEMAND FOR ACADEMICS afin d’obtenir un accés à SAS Studio.\n30 à 50 minutes plus tard, vous recevrez sur votre boite mail un identifiant et un lien pour vous connecter au serveur de SAS Studio. Le mot de passe est celui de votre SAS."
  },
  {
    "objectID": "Programmation.html#liens-utiles",
    "href": "Programmation.html#liens-utiles",
    "title": "Programmation",
    "section": "Liens utiles",
    "text": "Liens utiles\n\nPython\nIntroduction à Python\nLibrairies appliquées à la data science\nExploration et nettoyage d’un jeu de données\n\n\nR\nTutoriels pour apprendre R\nPour se familiariser avec des commandes de base\nCheatsheet proposé directement par R Studio\n\n\nSQL\nPour se familiariser avec SQL\nCours SQL\n\n\nSAS\nPour ceux n’ayant pas encore d’adresse e-mail universitaire, vous pouvez vous entrainez avec les supports gratuits d’E-learning SAS, pour une prise en main du logiciel, choisissez pour débuter le e-learning SAS programming 1.\nPour ceux ayant une adresse e-mail universitaire, vous pouvez en plus vous préparer aux certifications SAS.\nPour passer ces certifications gratuitement, il faut obligatoirement vous inscrire dans le programme SCYP-SAS Software Certified Young Professionals."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "Rédaction.html",
    "href": "Rédaction.html",
    "title": "Rédaction et projets universitaires",
    "section": "",
    "text": "La virgule permet de marquer une pause dans la phrase. Elle est seulement suivie d’un espace.\n\nJ’aime les films, surtout lorsqu’il y a du suspense.\n\n\n\n\nle point-virgule permet de marquer une pause importante dans la phrase. Quand une phrase a un lien étroit avec celle qui précède, elle en est séparée par un point-virgule et non par un point.\nOn ne met pas de majuscule au mot qui suit le point-virgule, sauf s’il s’agit d’un nom propre.\n\nIl s’était caché ; il pouvait ainsi les observer très attentivement.\n\n\n\n\nles tirets permettent de segmenter une phrase. Ils sont encadrés d’espaces.\n\nInterstellar - réalisé par christopher Nolan - est un film de science-fiction.\n\n\n\n\nLes deux-points servent à annoncer une énumération ou une citation encadrée par des guillemets. Ils servent également à marquer un lien logique entre deux propositions (cause, conséquence …).\n\nLes pays voisins de la France sont : la Belgique, le Luxembourg, l’Allemagne, la Suisse, l’Italie et l’Espagne.\nSérie : oeuvre télévisuelle se déroulant en plusieurs parties.\n\n\n\n\nLes trois points de suspension permettent d’exprimer un doute ou un silence. Ils ne sont jamais précédés d’une virgule ou d’un point-virgule mais sont suivis d’un espace.\nEntre crochet, ils indiquent une coupure dans une citation.\n\nJe ne sais pas qui dire… Ce film film est un chef d’oeuvre.\n\n\n\n\nLe point d’interrogation termine toute interrogation directe. Il est encadré d’espaces.\n\nAs-tu déjà regardé la série Friends ? C’est une série culte.\n\n\n\n\nLe point d’exclamation permet d’exprimer la surprise, l’exaspération ou un ordre. Il est encadré d’espaces.\n\nJe ne m’attendais pas à une fin pareil ! Ouah.\n\n\n\n\nLes guillemets permettent de faire une citation. Ils sont séparés d’un espace autour de la citation.\n\nIl lui demanda : “Qu’as-tu pensé de ce court-métrage ?”"
  },
  {
    "objectID": "Rédaction.html#mise-en-forme-dun-projet",
    "href": "Rédaction.html#mise-en-forme-dun-projet",
    "title": "Rédaction et projets universitaires",
    "section": "Mise en forme d’un projet",
    "text": "Mise en forme d’un projet\n\nEn général\nCes étapes doivent impérativement être validées lorsque vous écrivez un projet :\n\nVérifier les fautes d’orthographes ;\nFaire attention à la grammaire ;\nUtiliser une bonne typologie (police, taille de la police, couleur…) ;\nMettre tous ses paragraphes en justifié.\n\n\n\nStructure type\nUn projet doit respecter une structure bien définies afin que le lecteur puisse se repérer sans problème. Il faut :\n\nUne page de garde avec un titre parlant ;\nUn résumé expliquant le but et la conclusion du projet, si possible en français puis en anglais ;\nUne table des matières pour les parties,suivi d’une autre table des matières pour les figures et les tableaux ;\nLe corps du projet avec les différentes parties ;\nUne partie annexe ;\nUne bibliographie.\n\n\n\nCe qu’il faut éviter\nLes parties de votre projet doivent avoir un titre parlant, qui résume de quoi vous allez traiter ou qui donnent directement le résultat de votre partie.\nIl ne faut donc plus utiliser les titres « introduction » et « conclusion » qui sont beaucoup trop scolaires et qui ne renseignent pas sur les propos que vous voulez mettre en avant,\nExemple :\nUn titre trop vague : La relation entre les appréciations et les types de film. Un titre parlant : Les films d’actions plus appréciés par le grand public.\nUne autre chose à proscrire est l’utilisation des « on constate » ou « on remarque ». Le projet n’est pas un rapport où vous expliquez seulement ce que vous trouvez, mais il doit « raconter une histoire » sans que vous ne parliez de vous.\nExemple :\nA proscrire : On remarque que 65% des personnes interrogées regardent des séries fréquemment. Meilleure formulation : Parmi les personnes interrogées, 65% affirment regarder des séries fréquemment.\n\n\nFigures\nVous serez amenés à insérer plusieurs figures dans votre projet. Plusieurs règles doivent alors être respectées :\n\nFaire en sorte que la taille de la figure soit correcte et bien lisible ;\nDonner un titre précis permettant de comprendre la figure même sortie de son contexte ;\nMettre une grille de lecture expliquant comment lire votre figure ;\nIndiquer la source de votre figure (si elle vient de vous, mettre « réalisée par les auteurs »).\nNuméroter toutes vos figures afin de créer une table des matières qui leur est dédiée.\n\n\n\nAnnexes\nLes annexes sont très importantes et ne doivent pas être négligées. En effet il faut :\n\nRanger les annexes dans l’ordre chronologique d’apparition dans le projet;\nMettre un titre parlant pour chaque annexe ;\nElles se doivent d’être commentées convenablement ;\nNe mettre un document en annexe que s’il est cité dans le corps du projet ;\nNe pas mettre en annexe les sorties brutes (R, python…)."
  },
  {
    "objectID": "Rédaction.html#commenter-un-graphique",
    "href": "Rédaction.html#commenter-un-graphique",
    "title": "Rédaction et projets universitaires",
    "section": "Commenter un graphique",
    "text": "Commenter un graphique\n\nExemple\nConsidérer le graphique créé à l’aide de R. La figure représente la répartition de l’habitude de consommation d’alcool chez des élèves selon leur genre.\nUn graphique se doit d’être lisible et agréable à l’œil. Les couleurs épurées et les axes bien définis permettent une meilleure lecture.\n\n\n\n\n\n\n\nRemarque\nDans votre futur professionnel, vous serez amené à travailler avec des collègues d’autres professions à qui vous devrez présenter vos études/analyses de données, Or, eux, n’auront pas les même connaissances que vous aurez. Il est donc important de bien expliquer comment se lit le graphique et de surtout ne pas mettre hors annexe des graphiques trop compliqués à la compréhension.\nEssayer de garder le même format de graphique tout le long d’une même analyse.\nIl faut penser à numéroter les graphiques afin de pouvoir faire une table de matière.\nN’oubliez d’indiquer la source du graphique !"
  },
  {
    "objectID": "Rédaction.html#support-de-présentation",
    "href": "Rédaction.html#support-de-présentation",
    "title": "Rédaction et projets universitaires",
    "section": "Support de présentation",
    "text": "Support de présentation\n\nEn général\nCes étapes doivent impérativement être validées lorsque vous élaborez votre support de présentation :\n\nVérifier l’orthographe ;\nUtiliser une bonne typologie (police, taille de la police, couleur…) ;\nNe pas surcharger les slides ;\nêtre clair, concis sur les idées ;\nPrivilégier les images ou schémas aux phrases ;\nBonus : Mettre des animations.\n\n\n\nPrésentation\nUne fois le support terminé, il faut s’entraîner et répéter pour sa présentation orale.\nD’autres points sont à respecter si vous voulez faire une bonne présentation :\n\nNe jamais lire ses slides ;\nRegarder le public ;\nEtre dynamique et non statique ;\nEssayer de sourire, au moins de paraître sympathique ;\nPrendre son temps ;"
  },
  {
    "objectID": "Rédaction.html#mail-professionnel",
    "href": "Rédaction.html#mail-professionnel",
    "title": "Rédaction et projets universitaires",
    "section": "Mail professionnel",
    "text": "Mail professionnel\n\nEn général\nLors de ce master, mais aussi dans votre vie professionnelle, vous serez amenés à rédiger des mails professionnels. En effet, ils permettent d’échanger simplement et rapidement dans le milieu professionnel, tout en étant moins formel qu’une lettre.\nIl faudra cependant suivre certaines règles :\n\nÉviter les fautes d’orthographes ;\nAvoir un vocabulaire soutenu ;\nÊtre bref et ne pas hésiter à aller à la ligne !\n\n\n\nStructure type\nUn mail professionnel doit respecter des règles de rédaction qu’il faut impérativement respecter :\n\nObjet du mail : clair ;\nFormule d’appel : Bonjour Madame/ Monsieur, ;\nCorps du mail : phrasescourtes et langage courant et professionnel;\nFormule de courtoisie : Salutations respectueuses/Cordialement;\nSignature : Prénom et NOM."
  },
  {
    "objectID": "index.html#implication-dans-la-vie-universitaire",
    "href": "index.html#implication-dans-la-vie-universitaire",
    "title": "SEP Guide",
    "section": "",
    "text": "Le module d’Implication dans la Vie Universitaire, fil rouge de la formation M2 Statistiques pour l’Évaluation et la Prévision, a pour but de montrer comment les étudiants peuvent s’investir dans la vie universitaire ou dans le monde associatif. Il a pour objectif la réalisation d’une mission d’utilité publique, qui va au-delà d’un module de cours classique en matière d’investissement dans un projet collectif et de prise d’initiative.\nLe SEP Guide est un projet réalisé par les étudiants pour les futurs candidats aux master SEP."
  },
  {
    "objectID": "Programmation.html#autoformation-et-cheatsheets",
    "href": "Programmation.html#autoformation-et-cheatsheets",
    "title": "Liens utiles pour la programmation",
    "section": "Autoformation et cheatsheets",
    "text": "Autoformation et cheatsheets\n\nPython\nIntroduction à Python\nLibrairies appliquées à la data science\nExploration et nettoyage d’un jeu de données\n\n\nR\nTutoriels pour apprendre R\nPour se familiariser avec des commandes de base\nCheatsheet proposé directement par R Studio\n\n\nSQL\n\n\n\n\n\nPour se familiariser avec SQL\nCours SQL\n\n\nSAS\nPour ceux n’ayant pas encore d’adresse e-mail universitaire, vous pouvez vous entrainez avec les supports gratuits d’E-learning SAS, pour une prise en main du logiciel, choisissez pour débuter le e-learning SAS programming 1.\nPour ceux ayant une adresse e-mail universitaire, vous pouvez en plus vous préparer aux certifications SAS.\nPour passer ces certifications gratuitement, il faut obligatoirement vous inscrire dans le programme SCYP-SAS Software Certified Young Professionals."
  },
  {
    "objectID": "M2SEP.html",
    "href": "M2SEP.html",
    "title": "DATA Camp M2",
    "section": "",
    "text": "En théorie des probabilités, nous nous intéressons souvent au comportement d’un aléa, sachant qu’un autre événement est déjà passé. C’est ce que nous appelons Les Probabilités Conditionnelles.\nConsidérant deux événements de probabilité non nulle, \\(A\\) et \\(B\\), la probabilité conditionnelle de \\(A\\) sachant que \\(B\\) est réalisé (couramment dit \\(A\\) sachant \\(B\\)) est donnée par : \\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nPar commutativité de l’intersection, nous avons : \\[\nP(A \\cap B) = P(B \\cap A)\n\\]\nEn utilisant la formule ci-dessus, nous pouvons également exprimer la probabilité conditionnelle de \\(B\\) sachant \\(A\\) : \\[\nP(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n\\]\nC’est ce que nous appelons la formule de Bayes.\n\n\n\nUne variable statistique est une caractéristique ou une mesure que l’on peut attribuer à chaque individu d’une population ou d’un échantillon.\n\n\n\n\n\n\n\n\n\n\n\nLors d’une analyse statistique, on distingue deux types principaux de variables :\n\nLa variable à expliquer (à prédir, ou à estimer) : Y\nLes variables explicatives (prédictives ou estimatrices) : X_i\n\nTout l’exercice reside à établir la relation la plus pertinente entre les variables explicatives X_i et la variable à expliquer Y.\nTableau des synonymes :\nCatégorique = Qualitative.\nNumérique = Quantitative.\n\n\n\n\n\n\n\n\nJe cherche à estimer le prix d’une maison en fonction de 4 caractéristiques : le type de bien, l’état du bien, le nombre de pièces et la superficie en m2.\nPour ce faire, j’ai à ma disposition une base de données intitulée “data_immobilier” (générée aléatoirement) que je traite en R.\nAvant tout, je dois avoir ces éléments en tête :\n\n\n\n\n\nEnsuite, je peux passer à l’étape suivante.\n\n\n\n\nPeu importe leur origine, les bases de données nécessitent presque toujours un traitement avant d’être exploitables. De la collecte à l’enregistrement, des irrégularités s’introduisent, causant des erreurs lors de l’exploitation. Le traitement vise à corriger ou à gérer ces irrégularités. Bien que chaque base de données présente ses propres spécificités et problèmes, les quatre points que nous aborderons par la suite sont courants et doivent être maîtrisés\n\n\nLes valeurs manquantes, souvent représentées par les NaN, sont parmi les anomalies les plus couramment rencontrées dans les bases de données. Plusieurs stratégies peuvent être adoptées face à ces valeurs :\nConversion : On surpasse le NaN en le convertissant en une autre valeur, comme un flottant.\n\nAvantage : Conservation de données.\nDésavantage : Introduction d’un biais potentiellement significatif.\n\nCode :\n# Convertir les NaN en 0 (ou une autre valeur) en R.\ndf[is.na(df)] &lt;- 0\n# Convertir les NaN en 0 (ou une autre valeur) en python. \ndf.fillna(0, inplace=True)\nimputation : remplacer les valeurs manquantes par des estimations (la moyenne ou la médiane des autres valeurs).\n\nAvantage : Conservation de données.\nDésavantage : Introduction d’un biais potentiellement significatif.\n\nCode :\n## Utiliser la moyenne pour imputer en R \ndf$column_name[is.na(df$column_name)] &lt;- mean(df$column_name, na.rm = TRUE)\n# Utiliser la moyenne pour imputer en python\ndf['column_name'].fillna(df['column_name'].mean(), inplace=True)\nsuppression : supprimer les lignes avec des NaN.\n\nAvantage : On limite le biais .\nDésavantage : perte d’information générale.\n\nCode :\n# Supprimer les lignes contenant des NaN en R\ndf &lt;- df[complete.cases(df), ]\n# Supprimer les lignes contenant des NaN \ndf.dropna(inplace=True)\nIl n’y a pas de solution parfaite, certains cas vont favoriser certains choix, mais la suppression reste quand même la plus sur en terme de qualité de l’information, à privilègier des que possible.\n\n\n\nLa fonction group_by est utilisé pour regrouper des données en fonction de certaines variables catégorielles. Cela permet d’effectuer des opérations et des analyses spécifiques à chaque groupe, et comprendre les comportements ou les anomalies spécifiques à chaque groupe.\nConcretement, si l’on reprend la base data_immobilier, faire une group_by sur la variable Type_de_bien nous permettra de faire une etude sur le groupe maison, loft, appartement et studio séparemment.\nR :\n# Groupement des données par Type_de_bien et calcul de la moyenne des autres variables\ndata_grouped &lt;- data_immobilier %&gt;%                                 #Nouveau DataFrame \"data_grouped\"\n  group_by(Type_de_bien) %&gt;%                                        #Selection par groupe \"Type de bien\"\n  summarise(                                                        #Affiche les infomations\n    Prix_moyen = mean(Prix, na.rm = TRUE),                          #La moyenne de prix pour chaque groupe\n    Superficie_moyenne = mean(Superficie_m2, na.rm = TRUE),         #La moyenne de superficie pour chaque groupe\n    Nombre_moyen_de_pieces = mean(Nombre_de_pieces, na.rm = TRUE)   #La moyenne de Nombre de piece pour chaque groupe\n  )\nprint(data_grouped)                                                 #Affichage\nPython :\n# Groupement des données par Type_de_bien et calcul de la moyenne des autres variables \ndata_grouped = data_immobilier.groupby('Type_de_bien').agg({\n    'Prix': 'mean',\n    'Superficie_m2': 'mean',\n    'Nombre_de_pieces': 'mean'\n}).reset_index()\nprint(data_grouped)\n\n\n\nLa fonction merge est utilisée pour fusionner deux dataframes sur la base d’au moins une colonne commune. Cette fonction est extremement utile si l’on souhaite combiner des données provennant de differentes bases pour une même analyse.\nApplication concrète avec la base de données data_immobilier:\nOn a une autre base de données, data_Localisation, avec les variables Superficie_m2 et Localisation. En utilisant la fonction merge, on va fusionner les deux bases de données en utilisant la colonne commune, Superficie_m2 , pour avoir une base de données plus riche.\n# Exemple de code R utilisant merge\ndata_complete &lt;- merge(data_immobilier, data_Localisation, by = \"Superficie_m2\", all = TRUE)\n# Exemple de code Python utilisant merge\ndata_complete = pd.merge(data_immobilier, data_Localisation, on='Superficie_m2', how='outer')\n\n\n\n\n\n\n\n\nLes variables dummy sont utilisées pour convertir des variables catégorielles en variables numériques.\nObjectifs : Utiliser ces variables dans des analyses statistiques et des modèles de machine learning qui requièrent des entrées numériques. Comment créer des variables dummy ? Exemple concret :\nOn reprend le dataframe qui a une desormais colonne catégorielle nommée Localisation avec des noms de villes. On crée les variables dummy, soit pour chaque catégorie unique dans la colonne Localisation deviendra une nouvelle colonne dans le dataframe.\n# En R\ndata_with_dummies &lt;- model.matrix(~ Localisation - 1, data = data_complete) %&gt;% \n                     as.data.frame()\n# En python\ndata_with_dummies = pd.get_dummies(data_complete, columns=['Localisation'], prefix='', prefix_sep='')\nDans le nouveau dataframe, data_with_dummies, chaque ville unique de la colonne Localisation originale a été transformée en une nouvelle colonne. Si une observation dans la colonne Localisation originale était “Paris”, alors la colonne LocalisationParis serait marquée avec un 1, et toutes les autres colonnes de ville seraient marquées avec des 0.\n\nAttention aux problémes de multicolinéarité, supprimer une colonne pour une utilisation dans certains modèles.\n\n\n\n\nLes statistiques descriptives permettent de résumer, décrire et comprendre les données.\nPour les variables quantitatives, on utilise :\nMoyenne : La valeur moyenne.\nMédiane : La valeur centrale.\nMode : La valeur la plus fréquente.\nMin,Max= valeur minimal et maximum. Écart Type : Mesure de la dispersion des valeurs.\n# En python\ndescribe(data_quantitative)\n# En R \nsummary(data_quantitative)\nPour les variables qualitatives, on utilise:\nFréquences : Nombre de fois qu’une catégorie apparaît.\nPourcentages : Proportion d’une catégorie par rapport au total.\n# En python\n# Calculer les fréquences\nfreq = data_qualitative.value_counts()\n# Calculer les pourcentages\nperce = frequencies / len(data_qualitative) * 100\n# En R \n# Calculer les fréquences\nfrequencies &lt;- table(data_qualitative)\n# Calculer les pourcentages\npercentages &lt;- prop.table(frequencies) * 100\nOn illustre également par des graphiques descriptifs:\nHistogrammes et Diagrammes en Barres : Pour montrer la distribution des données.\nBoîtes à Moustaches (Boxplots) : Pour montrer la médiane, quartiles et valeurs aberrantes.\n# En python\n# Créer un histogramme pour les données quantitatives\nplt.hist(data_quantitative, bins=5, edgecolor='k')\nplt.xlabel(\"Valeurs\")\nplt.ylabel(\"Fréquence\")\nplt.title(\"Histogramme des données quantitatives\")\nplt.show()\n# En R \n# Créer un histogramme pour les données quantitatives\nggplot(data = data.frame(x = data_quantitative)) +\n  geom_histogram(aes(x = x), binwidth = 5, fill = \"blue\", color = \"black\") +\n  labs(x = \"Valeurs\", y = \"Fréquence\", title = \"Histogramme des données quantitatives\")\nLa statistique descriptive offre une première compréhension des données, indispensable avant toute analyse plus approfondie. Elle permet de déceler des tendances, anomalies, ou relations à explorer davantage. C’est une étape indispensable à ne surtout pas negliger.\n\n\n\n\n\nDéfinition d’une régression linéaire :\nLa régression linéaire simple est une méthode statistique qui permet de modéliser la relation entre deux variables en ajustant une ligne droite à un ensemble de données. L’équation de la régression linéaire est : \\[y = a + bx\\] où \\(y\\) est la variable dépendante, \\(x\\) est la variable indépendante, \\(a\\) est l’ordonnée à l’origine (l’interception de la ligne avec l’axe des ordonnées), et \\(b\\) est la pente de la ligne (le taux de changement de \\(y\\) par rapport à \\(x\\)).\nLa régression linéaire multiple reprend les mêmes principes, mais elle s’étend à plusieurs variables indépendantes. Ainsi, au lieu d’ajuster une ligne droite, on ajuste un hyperplan dans un espace multidimensionnel. L’équation de la régression linéaire multiple est la suivante :\n\\[\ny = a + b_1 x_1 + b_2 x_2 + \\dots + b_p x_p\n\\]\noù : - \\(y\\) est la variable dépendante, - \\(x_1, x_2, \\dots, x_p\\) sont les variables indépendantes, - \\(a\\) est l’ordonnée à l’origine (ou l’interception avec l’axe des ordonnées), - \\(b_1, b_2, \\dots, b_p\\) sont les coefficients de régression qui mesurent l’effet de chaque variable indépendante sur (y).\nDans ce cas, \\(b_1, b_2, \\dots, b_p\\) indiquent l’effet individuel de chaque variable \\(x_1, x_2, \\dots, x_p\\) sur la variable \\(y\\), tout en prenant en compte les autres variables. L’objectif de la régression linéaire multiple est d’estimer ces coefficients afin de prédire \\(y\\) à partir des valeurs des \\(x_i\\).\n\n\n\n\n\nMéthode des moindres carrés ordinaires :\nObjectif : Regarder à quel point la droite obtenue est meilleure que la droite de la moyenne des observations. Donc, \\(R^2 = \\min\\left(\\sum(y - \\hat{y})^2\\right)\\)\nMoindres carrés ajustés :\nLe \\(R^2\\) carré ordinaire peut seulement augmenter ou rester constant par l’ajout d’une nouvelle variable. Concretement, ne réduira jamais la capacité explicative du modèle. Le adjusted - \\(R^2\\) est une methode par pénalisation qui compense ce défaut. Il faut donc le privilègier à l’etude.\nP-value :\nC’est un indicateur statistique utilisé pour évaluer la significativité d’un résultat. On pose que l’hypothèse nulle (généralement l’absence d’effet ou de relation) est vraie. Une p-value faible suggère que les observations sont peu probables sous l’hypothèse nulle, indiquant ainsi une évidence forte contre l’hypothèse nulle et en faveur de l’hypothèse alternative, donc qu’il y a probablement une relation.\nUne p-value inférieure à un seuil défini (souvent 0,05) est généralement interprétée comme statistiquement significative, suggérant que le modèle ou la variable examinée a un effet réel et non dû au hasard.\nConcrètement,\n\np-value &lt; 5%, la variable est statistiquement significative, donc probablement explicative, on la garde dans le modèle.\np-value &gt; 5%, la variable n’est pas statistiquement significative, donc probablement pas explicative, on l’exclut du modèle.\n\nGestion des outliers :\nCertaines observations extrêmes, ou outliers, peuvent fausser les résultats en raison de leur décalage significatif par rapport au reste des données. Il faut les identifier et, si nécessaire, les exclure en amont de l’analyse. Pour ce faire, on utilise souvent des méthodes telles que DFFITS et DFBETAS. Ces techniques aident à déterminer si une observation individuelle est particulièrement influente et si elle devrait être considérée comme un outlier devant être exclu de l’analyse pour obtenir des résultats plus fiables.\nMulticollinéarité :\nLa multicollinéarité dans les modèles de régression linéaire est un phénomène où deux ou plusieurs variables explicatives sont fortement corrélées entre elles. Cette forte corrélation peut causer des problèmes dans l’estimation des coefficients de régression, rendant les résultats moins fiables. Pour mesurer le degré de multicollinéarité dans un modèle, on utilise souvent l’indice VIF.\n\nVIF &lt; 5, peu de risque de multicollinéarité .\nVIF &gt; 5, risque de multicollinéarité.\n\nMéthode Backward élimination pour affiner la précision du modèle :\nInitialement, on a une variable à expliquer et plusieurs variables explicatives.\nOn cherche la meilleure combinaison possible entre ces variables pour definir ce modèle, du point de vue de la significativité à travers la p-value, et de l’explicativité à travers le adjusted- \\(R^2\\).\nUne idée serait de tester toutes les combinaisons une à une, en théorie cela fonctionnerait, mais cela n’est pas réaliste au vu de la quantité de calcul nécessaire.\nla méthode Backward élimination consiste alors à évaluer le modèle par itération suivant le schéma suivant :\n\n1 - Je fais mon modèle avec l’ensemble des variables.\n2 - Je supprime LA variable qui à la p-value &gt; 5%, la plus élevé.\n3 - Je réévalue le modèle\n4 - Je regarde comment le adjusted-\\(R^2\\) à évoluer :\n\nIl augmente, c’est bien le modèle est plus explicatif\nIl diminue, c’est mauvais, la variable avait quand même une importance\n\nJe refléchis à la conserver ou non si la p-value est pas trop haute.\n\n\n5 - Je répète les étapes 2,3 et 4 autant de fois que nécessaire.\n\nCodes :\nRégression linéaire simple :\n#var1 -&gt; a expliquer\n#var2 -&gt; explicative\n\nReg1&lt;-lm(var1~var2, data=df)\nsummary(Reg1) # Le détail \nabline(Reg1) #Representation de la regression linéaire \nRégression linéaire multiple :\n#var1 -&gt; a expliquer\n\nReg1&lt;-lm(var1~var2+var3+var4, data=df)\nsummary(Reg1) # Le détail \nabline(Reg1)  #Representation de la regression linéaire \n\n\n\nDefinition d’une régression logistique : Utilisée pour des problèmes de classification ( variable dependante bianire ).\n\nPrincipe: Modélise la probabilité que la variable dépendante appartienne à une catégorie particulière.\n\n# Régression logistique en R (y binaire à expliquer)\nglm_model &lt;- glm(y ~ x1 + x2, data = dataset, family = \"binomial\")\nsummary(glm_model)\n# Régression logistique en Python (y binaire à expliquer)\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\n\n\n\n\nUsage: Utilisée pour traiter le problème de multicollinéarité dans les données. Ajoute une pénalité au carré des coefficients. Principe: Minimise une somme pondérée des carrés des résidus et des carrés des coefficients.\n# Régression Ridge en R\nlibrary(glmnet)\nridge_model &lt;- glmnet(x, y, alpha = 0, lambda = lambda_value)\n# Régression Ridge en Python\nfrom sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0)\nmodel.fit(X, y)\n\n\n\nUsage: Usage: Permet de sélectionner des variables en réduisant les coefficients de certaines à zéro.\nPrincipe: Semblable à Ridge, mais ajoute une pénalité absolue aux coefficients.\n# Régression Lasso en R\nlibrary(glmnet)\nlasso_model &lt;- glmnet(x, y, alpha = 1, lambda = lambda_value)\n# Régression Lasso en Python\nfrom sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=1.0)\nmodel.fit(X, y)\n\n\n\n\n\nLes tests d’indépendance, sont utilisés en statistique pour déterminer si deux variables semblent être liées ou non. L’intérêt principal de ces tests est de vérifier l’existence d’une association ou d’une relation entre les variables.\nCas 1: Les deux variables sont nominales\n# Tableaux des effectifs croisés ou fréquences croisées\ntab &lt;- table(var1, var2)\nprint(tab)\nprop_table &lt;- prop.table(tab, margin = 2)\nprint(prop_tab)\n\n# Représentation graphique des profils\nbarplot(tab, legend = TRUE, beside = TRUE)\nbarplot(prop_table, legend = TRUE, beside = TRUE)\n\n# Test d'indépendance du khi-carré\nchi_sq_test &lt;- chisq.test(tab)\nprint(chi_sq_test)\n\n# Si chi_sq_test$p.value &lt; 0.05 & all(chi_sq_test$expected &gt; 5)\n# Alors test significatif et effectifs espérés supérieurs à 5, il y a dependance. \n\n# Analyse des résidus standardisés via leur représentation avec la fonction mosaicplot()\nmosaicplot(tab)\nCas 2: Une variable est quantitative et l’autre est nominale binaire\n# var1 -&gt; quantitative \n# var2 -&gt; nominale binaire\n\n# Sous-populations définies par la variable binaire\ngroupe1 &lt;- df$var1[df$var2 == \"Oui\"]\ngroupe2 &lt;- df$var1[df$var2 == \"Non\"]\n\n# Indicateurs statistiques \nsummary(groupe1)\nsummary(groupe2)\n\n# Representation graphique\nggplot(df, aes(x = variable_nominale, y = variable_quantitative)) +\n  geom_boxplot() +\n  theme_minimal()\n\n# Tester la normalité\nshapiro1 &lt;- shapiro.test(groupe1)\nshapiro2 &lt;- shapiro.test(groupe2)\nprint(shapiro1)\nprint(shapiro2)\n\n# Si shapiro1$p.value &gt; 0.05 et shapiro2$p.value &gt; 0.05\n# Normalité non rejetté \n\n# Procédure paramétrique\n\n# Tester l'égalité des variances\nvar_test &lt;- var.test(groupe1, groupe2)\nprint(var_test)\n\n# Si var_test$p.value &gt; 0.05\n# Égalité des variances non rejeté \n# Faire un test de comparasion des moyennes \nt_test &lt;- t.test(var_quanti ~ var_nominale, var.equal = TRUE)\nprint(t_test)\n\n# Si var_test$p.value &lt; 0.05\n# Égalité des variances rejetée\n# les variables ne sont pas indépendantes\n# Faire un test de comparasion des moyennes \nt_test &lt;- t.test(var_quanti ~ var_nominale, var.equal = FALSE)\nprint(t_test)\n\n# Procédure non paramétrique (shapiro1$p.value &lt; 0.05 ou shapiro2$p.value &lt; 0.05)\n\n# Tester l'égalité des variances\nansari_test &lt;- ansari.test(groupe1, groupe2)\nprint(ansari_test)\n\n# Si ansari_test$p.value &gt; 0.05\n# Égalité des variances non rejetée\n# Faire un test de comparaison des medianes \nwilcox_test &lt;- wilcox.test(var_quanti ~ var_nominale)\nprint(wilcox_test)\n\n# Si ansari_test$p.value &lt; 0.05\n# Égalité des variances rejetée\n\n\"Les distributions conditionnelles de X connaissant Y diffèrent d'un paramètre d'échelle\"\nCas 3 : une variable est quantitative et l’autre nominale non binaire\n# var1 -&gt; quantitative \n# var2 -&gt; nominale non binaire\n\n# Indicateurs statistiques\nindicateurs &lt;- df %&gt;%\n  group_by(var2) %&gt;%\n  summarise(moyenne = mean(var1),\n            mediane = median(var1),\n            ecart_type = sd(var1),\n            minimum = min(var1),\n            maximum = max(var1),\n            q1 = quantile(var1, 0.25),\n            q3 = quantile(var1, 0.75))\nindicateurs\n\n# Représentations graphiques\nggplot(df, aes(x = choux$var2, y = choux$var1)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.size = 2) +\n  scale_fill_manual(values = c(\"lightgray\", \"lightblue\"), guide = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"\", y = \"Ventes \", title = \"Boîtes à Moustaches des ...\")\n\n# Test de normalité\nnormality &lt;- df %&gt;%\n  group_by(var2) %&gt;%\n  summarise(shapiro.test(var1)$p.value)\nnormality\n\n# si tous les shapiro.test(var1)$p.value &gt; 0.05\n# Normalité non rejetté \n# procédure Paramétrique\n\nbartlett_res &lt;- bartlett.test(var1 ~ var2, data = df)\nprint(bartlett_res)\n\n#si bartlett_res$p.value &gt; 0.05 \n#l’égalité des variances n’est pas rejetée\n\noneway_res &lt;- oneway.test(var1 ~ var2, data = df, var.equal = TRUE)\nprint(oneway_res)\n\n# Vérifier l'indépendance: \n\n##si oneway_res$p.value &gt; 0.05\n##alors Les variables sont indépendantes (pas de relation significative)\n\n##si oneway_res$p.value &lt; 0.05\n##Les variables ne sont pas indépendantes (relation significative)\n\n#si bartlett_res$p.value &lt; 0.05 (l’égalité des variances est rejetée)\n#Les variables ne sont pas indépendantes\n\n#si au moins un shapiro.test(tonnage)$p.value &lt; 0.05\n#Procédure Non paramétrique\n\nfligner_res &lt;- fligner.test(var1 ~ var2, data = df)\nprint(fligner_res)\n\n#si fligner_res$p.value &gt; 0.05 \n\n##l’égalité des variances n’est pas rejetée\nkruskal_res &lt;- kruskal.test(var1 ~ var2, data = df)\nprint(kruskal_res)\n\n## Vérifier l'indépendance\n\n## Si kruskal_res$p.value &gt; 0.05\n##Les variables sont indépendantes (pas de relation significative)\n\n## Si kruskal_res$p.value &lt; 0.05\n##Les variables ne sont pas indépendantes (relation significative)\n\n## Comparaison deux-à-deux\npairwise_wilcox_res &lt;- pairwise.wilcox.test(df$var_quanti, df$var_nominale)\nprint(pairwise_wilcox_res)\n\n#si fligner_res$p.value &gt; 0.05 \n#l’égalité des variances est rejetée\n\n'Les distributions conditionnelles de X connaissant Y diffèrent d un paramètre d echelle'\nCas 4 :Les deux variables sont quantitatives\n# Indicateurs statistiques\nsummary(var1)\nsummary(var2)\n\n# Représentation du nuage de points\nggplot() +\n  geom_point(aes(x = var1, y = var2)) +\n  theme_minimal()\n\n# Tester la normalité des couples d'observations\nmshapiro_test &lt;- shapiro.test(cbind(var1, var2))\nprint(mshapiro_test)\n\n# Si mshapiro_test$p.value &gt; 0.05\n# Normalité non rejeté\n\n## Test de non-corrélation de Pearson\npearson_test &lt;- cor.test(var1, var2, method = \"pearson\")\nprint(pearson_test)\n\n## Si la p-value &lt; 0,05 on peut rejeter l'hypothèse nulle de non-corrélation, \n## Conclure qu'il y a une corrélation significative entre les deux variables\n\n# Si mshapiro_test$p.value &lt; 0.05\n# Normalité rejetée\n\n# Test de non-corrélation monotone de Spearman\nspearman_test &lt;- cor.test(var1, var2, method = \"spearman\")\nprint(spearman_test)\n\n# Si la p-value &lt; 0,05 on peut rejeter l'hypothèse nulle de non-corrélation, \n# Conclure qu'il y a une corrélation significative entre les deux variables"
  },
  {
    "objectID": "M2SEP.html#quest-ce-quune-variable",
    "href": "M2SEP.html#quest-ce-quune-variable",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Une variable statistique est une caractéristique ou une mesure que l’on peut attribuer à chaque individu d’une population ou d’un échantillon"
  },
  {
    "objectID": "M2SEP.html#vocabulaire-autour-de-la-variable",
    "href": "M2SEP.html#vocabulaire-autour-de-la-variable",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Ton contenu ici…"
  },
  {
    "objectID": "LOGICIELS.html",
    "href": "LOGICIELS.html",
    "title": "DATA Camp Logiciels",
    "section": "",
    "text": "Dans le cadre de notre parcours SEP (Master pour l’Évaluation et la Prévision), l’utilisation de logiciels joue un rôle central dans notre formation. Ces outils informatiques, soigneusement sélectionnés pour répondre aux besoins variés de la recherche, de l’analyse de données et de la visualisation, contribuent à renforcer notre expertise dans le domaine. Dans ce document, nous allons vous présenter un éventail de logiciels essentiels tout au long de votre formation, des langages de programmation en passant par des logiciels utiles au bon déroulement. Nous expliquerons également comment les installer, en fournissant des liens directs pour faciliter la mise en place de ces outils incontournables. Que vous soyez un étudiant débutant ou un professionnel expérimenté, ce guide vous sera précieux pour tirer le meilleur parti de ces logiciels au cours de votre parcours SEP."
  },
  {
    "objectID": "LOGICIELS.html#rstudio",
    "href": "LOGICIELS.html#rstudio",
    "title": "DATA Camp Logiciels",
    "section": "RStudio",
    "text": "RStudio\nRStudio est un logiciel convivial spécialement conçu pour la programmation en R, un langage de statistiques. Il offre un environnement complet pour l’analyse de données, la création de graphiques et la génération de rapports, facilitant ainsi la manipulation des données.\nRStudio propose une version gratuite appelée RStudio Desktop. Il faut au préalable installer R puis RStudio Deskop."
  },
  {
    "objectID": "LOGICIELS.html#anaconda",
    "href": "LOGICIELS.html#anaconda",
    "title": "DATA Camp Logiciels",
    "section": "Anaconda",
    "text": "Anaconda\nAnaconda est une plateforme tout-en-un pour Python, un langage de programmation. Il simplifie l’installation et la gestion de packages Python, tandis que Jupyter Notebook permet de créer des documents interactifs, et Spyder est un environnement de développement Python.\nAnaconda offre une documentation complète pour l’installation. Vous pouvez vous rendre sur le site officiel d’Anaconda. Choisissez la version appropriée pour votre système d’exploitation (Windows, macOS, ou Linux) et suivez les instructions fournies."
  },
  {
    "objectID": "LOGICIELS.html#excel",
    "href": "LOGICIELS.html#excel",
    "title": "DATA Camp Logiciels",
    "section": "Excel",
    "text": "Excel\nMicrosoft Excel est un tableur qui vous aide à organiser, analyser et visualiser des données. Il est couramment utilisé pour effectuer des calculs, créer des graphiques et des tableaux, et est adapté à de nombreuses tâches liées aux chiffres. Vous l’utiliserez également pour les macros.\nMicrosoft Excel est généralement installé avec la suite Microsoft Office. Suivez les instructions de Microsoft pour installer Office, puis Excel sera inclus.\n\nAvec votre adresse étudiante vous devriez avoir un accès gratuit."
  },
  {
    "objectID": "LOGICIELS.html#github-desktop",
    "href": "LOGICIELS.html#github-desktop",
    "title": "DATA Camp Logiciels",
    "section": "Github Desktop",
    "text": "Github Desktop\nGithub Desktop est un outil simple qui simplifie la gestion des versions de code sur la plateforme de développement GitHub/GitLab. Il vous permet de collaborer efficacement sur des projets informatiques.\nPour GitHub Desktop, rendez-vous sur la page officielle de GitHub Desktop et téléchargez la version appropriée pour votre système d’exploitation. Ils fournissent également des guides d’installation détaillés."
  },
  {
    "objectID": "LOGICIELS.html#qgis",
    "href": "LOGICIELS.html#qgis",
    "title": "DATA Camp Logiciels",
    "section": "QGIS",
    "text": "QGIS\nQGIS est un logiciel de cartographie qui vous permet de créer des cartes, d’analyser des données géospatiales et de visualiser des informations géographiques de manière interactive.\nPour installer QGIS, vous pouvez visiter le site officiel de QGIS. Choisissez la version correspondant à votre système d’exploitation, puis suivez les instructions d’installation."
  },
  {
    "objectID": "LOGICIELS.html#gephi",
    "href": "LOGICIELS.html#gephi",
    "title": "DATA Camp Logiciels",
    "section": "Gephi",
    "text": "Gephi\nGephi est un logiciel de visualisation de réseaux qui vous aide à représenter graphiquement des données relationnelles. Il est largement utilisé pour explorer des structures de réseaux complexes.\nGephi est disponible en téléchargement sur le site officiel de Gephi. Vous y trouverez des guides d’installation pour les différentes plateformes."
  },
  {
    "objectID": "LOGICIELS.html#powerbi",
    "href": "LOGICIELS.html#powerbi",
    "title": "DATA Camp Logiciels",
    "section": "PowerBI",
    "text": "PowerBI\nPower BI est un outil de business intelligence de Microsoft qui vous permet de créer des tableaux de bord interactifs et des rapports à partir de données, facilitant ainsi la prise de décisions basée sur les informations.\nPower BI Desktop est disponible sur le site de Microsoft. Rendez-vous sur la page de téléchargement pour obtenir le logiciel et suivez les instructions."
  },
  {
    "objectID": "LOGICIELS.html#spss",
    "href": "LOGICIELS.html#spss",
    "title": "DATA Camp Logiciels",
    "section": "SPSS",
    "text": "SPSS\nSPSS est un logiciel d’analyse statistique largement utilisé dans la recherche en sciences sociales. Il simplifie la gestion des données, l’analyse statistique et la création de graphiques.\nIBM SPSS est une solution propriétaire et payante. L’éditeur propose tout de même une période d’essai gratuite, variant de 15 à 30 jours. Cette version est limitée en termes de fonctionnalités. Il faudra pour bénéficier de la solution complète, opter pour la version premium. Cependant, l’enseignant concerné vous accompagnera dans cette démarche."
  },
  {
    "objectID": "LOGICIELS.html#veracrypt",
    "href": "LOGICIELS.html#veracrypt",
    "title": "DATA Camp Logiciels",
    "section": "Veracrypt",
    "text": "Veracrypt\nVeraCrypt est un outil de chiffrement de données. Il vous permet de créer des disques virtuels cryptés pour protéger vos données sensibles, garantissant ainsi leur confidentialité.\nLe site officiel de VeraCrypt propose des instructions d’installation détaillées pour chiffrer vos données."
  },
  {
    "objectID": "LOGICIELS.html#zotero",
    "href": "LOGICIELS.html#zotero",
    "title": "DATA Camp Logiciels",
    "section": "Zotero",
    "text": "Zotero\nZotero est un gestionnaire de références bibliographiques qui vous aide à collecter, organiser et citer des sources dans vos travaux de recherche, simplifiant ainsi la gestion de vos références.\nPour Zotero, visitez le site officiel et suivez les guides d’installation pour votre navigateur et votre système d’exploitation."
  },
  {
    "objectID": "LOGICIELS.html#obs-studio",
    "href": "LOGICIELS.html#obs-studio",
    "title": "DATA Camp Logiciels",
    "section": "OBS Studio",
    "text": "OBS Studio\nOBS Studio est un logiciel d’enregistrement et de diffusion en direct. Il est utilisé pour capturer des vidéos de haute qualité, enregistrer des sessions, et diffuser en direct sur des plateformes.\nVous pouvez télécharger OBS Studio depuis le site officiel. Ils fournissent des instructions pour l’installation et la configuration."
  },
  {
    "objectID": "M1SEP.html",
    "href": "M1SEP.html",
    "title": "DATA Camp M1",
    "section": "",
    "text": "La trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés :\n\nLa trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\]\nInvariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\nUne matrice carré \\(A\\) d’ordre \\(n\\) est dite inversible s’il existe \\(B\\) tel que : \\[AB = BA = I_n\\]\nB est alors noté \\(A^{-1}\\) l’inverse de A.\n\n\n\n\n\n\n\nTip\n\n\n\nSi le déterminant d’une matrice \\(A\\) est différent de 0 alors la matrice est inversible.\n\n\n\n\n\nInverse d’une matrice \\(A\\in \\mathcal{M}_{2 \\times 2}\\) de déterminant non nul (\\(det(A) = ad -bc \\ne 0\\)) :\n\\[A^{-1} = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)^{-1}\n= \\frac{1}{ad-bc}\\left(\\begin{array}{cc} d & -b \\\\ a & -c \\end{array} \\right)\n\\]\n\n\n\nInverse d’une matrice \\(A\\in \\mathcal{M}_{n \\times n}\\) de déterminant non nul (\\(det(A) = d_1 \\times d_2 \\times \\cdots \\times d_n \\ne 0\\)) : \\[D^{-1} =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)^{-1}\n= \\left(\\begin{array}{cccc}\n\\frac{1}{d_1} & 0 & \\cdots & 0 \\\\\n0 & \\frac{1}{d_2} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\frac{1}{d_n}\n\\end{array} \\right)\\]\n\n\n\nUn espace vectoriel est un ensemble de vecteurs qui peuvent être combinés entre eux par des opérations comme l’addition et la multiplication. Ces combinaisons permettent de construire de nouveaux vecteurs dans le même ensemble. Un vecteur \\(v = (v_1,...,v_d)\\) n’a pas de dimension mais admet une longueur de taille \\(d\\) ( = d coefficients). Mais, il est d’usage de représenter \\(v\\) avec sa représentation matricielle notée \\(V = \\left(\\begin{array}{c} v_1 \\\\\n\\cdots \\\\\nv_d\n\\end{array}\n\\right)\\), matrice de \\(d\\) lignes et une colonne. On écrit donc \\(V = v^t\\).\nSoient \\(v,u\\) deux vecteurs d’un espace vectoriel réel de dimension finie muni d’un produit scalaire usuel : \\[\\langle v, u \\rangle_2 = v_1 u_1 + v_2 u_2 + \\cdots + v_n u_n\\] (le produit scalaire est associée à la norme 2 \\(\\langle v, v \\rangle_2 = \\|v\\|_2^2\\))\nQuelques propriétés importantes du produit scalaire :\n\n\\(\\langle v, v \\rangle_2 = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\)\n\\(\\langle v, u \\rangle_2 = \\langle u, v \\rangle_2\\) (symétrie)\n\\(\\langle v, u \\rangle_2 &gt; 0\\) si \\(x\\) \\(0\\)\n\\(\\langle v, w \\rangle_2 = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle_2 = \\langle w, v \\rangle_2\\)\n\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leqslant \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leqslant \\|x\\| + \\|y\\|\\]\n\n\n\n\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\).\n\n\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|v\\|_2 = 1\\).\nDeux vecteurs \\(v\\) et \\(u\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle v, u \\rangle = 0\\] et on note \\(v \\perp u\\)\n\n\n\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\n\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\\Pi_{W^\\perp} B = B - \\Pi_{W} B\\]\n\n\n\n\nUne base \\(E\\) est un ensemble de vecteurs linéairement indépendants qui permet de décrire tous les vecteurs d’un espace (par combinaison linéaire). On note alors \\(E = \\text{Vect}(\\mathbf{v_1}, \\mathbf{v_2}, \\dots, \\mathbf{v_n})\\). Cette notation désigne l’ensemble de tous les vecteurs qui peuvent s’écrire comme une combinaison linéaire de \\(\\mathbf{v_1}, \\mathbf{v_2}, \\dots, \\mathbf{v_n}\\).\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leqslant n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(\\text{W} = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection W de \\(\\mathbb{R}^n\\) sur W est : \\[\\text{W} = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de W, alors : \\[\n\\text{W} = V V^t\n\\]\n\n\n\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\nÉtapes du Procédé\nLe premier vecteur orthogonal ( \\(u_1\\) ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où $ k $), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]\n\n\n\n\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite.\nPour plus d’informations sur la base duale cliquez ici\n\n\n\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\] \\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\) et \\(P\\) est formé de vecteurs propres dans l’ordre des valeurs propres mis dans \\(D\\).\n\n\n\n\n\n\n\nTip\n\n\n\nSi les vecteurs propres sont normalisés alors \\(P^{-1} = P^t\\) et \\(A = PDP^t\\).\n\n\n\n\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\]\n\n\n\n\n\n\n\nEn théorie, on représente la moyenne comme l’espérance : Dans le cas discret : \\[E(X) = \\sum k \\cdot P(X = k)\\] \\[k \\in X(\\Omega)\\] Alors que dans le cas continu : \\[E(X) = \\int x \\cdot f_X(x) \\, dx\\] \\[x \\in X(\\Omega)\\]\n\n\nLa fonction de répartition est définie par : \\[F_X(x) = P(X \\leqslant x)\\]\nPour tout \\(x\\), \\(0 \\leqslant F_X(x) \\leqslant 1\\), \\(F_X\\) est une fonction croissante. De plus, \\(\\lim_{x \\to -\\infty} F_X(x) = 0\\) et \\(\\lim_{x \\to \\infty} F_X(x) = 1\\)\n\n\n\n\n\n\n\n\nLa loi marginale de X est définie comme suit : \\[f_X(x) = \\int f_{X, Y}(x, y) \\, dy, \\text{ où } -\\infty &lt; x &lt; \\infty,\\] dans le cas continu, ou encore : \\[f_X(x_i) = \\sum p_{ij}, \\text{ où } j \\text{ tel que } y_j \\leqslant y\\]\nSi X et Y sont indépendants, alors : \\[f_{X, Y}(x, y) = f_X(x) \\cdot f_Y(y)\\] \n\n\n\n\n\n\nLe centrage consiste à localiser la distribution autour de l’origine et la réduction consiste à normaliser la dispersion. On crée une nouvelle variable aléatoire \\(Y\\) issu de \\(X\\) dont l’espérance est null et la variable est égale à 1. \\[Y = \\frac{X - E(X)}{\\sqrt{\\sigma(X)^2}}\\] où \\(E(X)\\) représente l’espérance de X et \\(\\sigma^2\\) est la variance de \\(X\\).\n\n\n\nLe moment d’ordre r est défini par : \\[\\mu_r = E(X^r)\\] Le moment centré d’ordre r est défini par : \\[\\mũ_r = E((X - E(X))^r)\\]\n\n\n\n\n\nLa fonction conjointe est appelée la distribution conjointe de X et Y. \\[F_{X, Y}(x, y) = P(X \\leqslant x \\cap Y \\leqslant y)\\]\nDans le cas continu, la fonction définie par : \\[f_{X, Y}(x, y) = \\frac{\\partial^2 F_{X, Y}(x, y)}{\\partial x \\partial y}\\] est la densité conjointe du couple (X, Y). On a donc : \\[F_{X, Y}(x, y) = \\int \\int f_{X, Y}(t, u) \\, dt \\, du, \\text{ où } -\\infty &lt; x, y &lt; +\\infty,\\]\nDans le cas discret, on définit la fonction de probabilité conjointe : \\[P(X = x_i, Y = y_j) = p_{ij}\\] On a donc : \\[F_{X, Y}(x, y) = \\sum \\sum p_{ij}, \\text{ où } x_i \\leqslant x \\text{ et } y_j \\leqslant y\\]\n\n\n\nLa covariance mesure l’intensité de la relation linéaire entre deux variables aléatoires X et Y. Elle est définie comme suit : \\[Cov(X, Y) = E(XY) - E(X) \\cdot E(Y)\\]\nSi X et Y sont indépendants, alors : \\[Cov(X, Y) = 0\\]\n\n\n\n\n\n\nWarning\n\n\n\nIl est important de noter que la réciproque n’est pas vraie : la covariance n’implique pas nécessairement l’indépendance entre X et Y.\n\n\n\n\n\n\n\nEspérance \\[\n\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y)\n\\]\n\\[\n\\mathbb{E}(a) = a\n\\] Variance\n\\[\n\\text{Var}(aX) = a^2\\text{Var}(X)\n\\] \\[\n\\text{Var}(a) = 0\n\\] \\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\n\\]\n\\[ \\text{Si } X \\coprod Y \\text{ alors } \\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y)\\]\nCovariance \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X)\n\\]\n\\[\n\\text{Cov}(aX + bY, cU + dV) = ac\\text{Cov}(X, U) + ad\\text{Cov}(X, V) + bc\\text{Cov}(Y, U) + bd\\text{Cov}(Y, V)\n\\]\n\n\n\nL’espérance d’un vecteur aléatoire \\(X = (X_1, X_2, \\vdots, X_n)^t\\) de X est le vecteur des espérances de \\(X_i\\) c’est-à-dire \\(\\mathbb{E}(X) = \\left(\\begin{array}{c} E(X_1) \\\\ \\ldots \\\\ \\mathbb{E}(X_n) \\end{array} \\right)\\).\nL’espérance reste linéaire, en particulier pour \\(X\\) et \\(Y\\) appartenant à \\(R^n\\) on a :\n\\[\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y) \\text{ où } a,b \\in \\mathbb{R}\\] \\[\\mathbb{E}(AX + B) = A\\mathbb{E}(X)+B\\]\nLa variance-covariance de X notée \\(\\Sigma\\) une matrice \\(n \\times n\\) où chaque élément \\(\\Sigma_{ij}\\) représente la covariance entre les variables aléatoires \\(X_i\\) et \\(X_j\\). Les éléments diagonaux de \\(\\Sigma\\) correspondent aux variances des composantes \\(X_i\\), tandis que les éléments hors-diagonaux représentent les covariances entre les différentes composantes de \\(X\\). La matrice \\(\\Sigma\\) est donc définie comme suit :\n\\[\n\\Sigma = \\begin{pmatrix}\n\\text{Var}(X_1) & \\text{Cov}(X_1, X_2) & \\dots & \\text{Cov}(X_1, X_n) \\\\\n\\text{Cov}(X_2, X_1) & \\text{Var}(X_2) & \\dots & \\text{Cov}(X_2, X_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(X_n, X_1) & \\text{Cov}(X_n, X_2) & \\dots & \\text{Var}(X_n)\n\\end{pmatrix}\n\\] \\[ \\Sigma_{AX + B} = A\\Sigma_X(X)A^t\\] où \\(\\Sigma\\) est la variance de X et A,B sont des matrices (deterministe)\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nLes variables \\(X_1, \\ldots, X_n\\) sont indépendantes et identiquement distribuées (i.i.d.) si et seulement si :\nDans le cas discret : \\[P(X_1 = x_1, \\ldots, X_n = x_n) = P(X_1 = x_1) \\times \\ldots \\times P(X_n = x_n)\\]\nDans le cas continu :\n\\[P(X_1 \\leq x_1, X_2 \\leq x_2, \\ldots, X_n \\leq x_n) = P(X_1 \\leq x_1) \\cdot P(X_2 \\leq x_2) \\cdots P(X_n \\leq x_n)\\]\n\n\nCes tableaux récapitulent les lois usuelles que vous pourrez rencontrer dans différents cours du master.\n\n\n\n\n\n\n\n\n\n\n\nNom\nNotation\n\\(X(\\Omega)\\)\n\\(P(X = k)\\)\n\\(E[X]\\)\n\\(Var(X)\\)\n\n\n\n\nUniforme\n\\(X \\sim U(\\{1, 2, \\ldots, n\\})\\)\n\\(\\{1, 2, \\ldots, n\\}\\)\n\\(\\frac{1}{n}\\)\n\\(\\frac{n+1}{2}\\)\n\\(\\frac{n^2-1}{12}\\)\n\n\nBernouilli\n\\(X \\sim B(p), 0 &lt; p &lt; 1\\)\n\\(\\{0, 1\\}\\)\n\\(P(X = 1) = p\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\n\n\n\n\\(P(X = 0) = 1 - p\\)\n\n\n\n\nBinomiale\n\\(X \\sim B(n, p), 0 &lt; p &lt; 1\\)\n\\(\\{1, 2, \\ldots, n\\}\\)\n\\(C_k^n p^k (1 - p)^{n-k}\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\nGéométrique\n\\(X \\sim G(p), 0 &lt; p &lt; 1\\)\n\\(\\mathbb{N}^{*}\\)\n\\(p(1-p)^{k}\\)\n\\(\\frac{1-p}{p}\\)\n\\(\\frac{1-p}{p^2}\\)\n\n\nPoisson\n\\(X \\sim P(\\lambda), \\lambda &gt; 0\\)\n\\(\\mathbb{N}\\)\n\\(\\frac{\\lambda^k}{k!}e^{-\\lambda}\\)\n\\(\\lambda\\)\n\\(\\lambda\\)"
  },
  {
    "objectID": "M1SEP.html#matrices",
    "href": "M1SEP.html#matrices",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Une matrice est un tableau de nombres disposés en \\(m\\) lignes et \\(n\\) colonnes. Soit \\(A\\) de taille \\((m, n)\\) : \\[\nA = (a_{ij})_{i=1,\\ldots,m \\atop j=1,\\ldots,n} =\n\\begin{bmatrix}\na_{11} & \\cdots & a_{1n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\na_{m1} & \\cdots & a_{mn}\n\\end{bmatrix}\n\\]\nLe terme \\(a_{ij}\\) est situé à la \\(i\\)-ème ligne de la \\(j\\)-ème colonne de la matrice \\(A\\).\n\n\\[\nA =\n\\begin{bmatrix}\n-2 & 1 \\\\\n8 & -3 \\\\\n1 & 3\n\\end{bmatrix}\n;\\quad\nB =\n\\begin{bmatrix}\n-2 \\\\\n-3 \\\\\n5\n\\end{bmatrix}\n;\\quad\nC =\n\\begin{bmatrix}\n3 & -1 & 6\n\\end{bmatrix}\n;\\quad\nD =\n\\begin{bmatrix}\n3 & -1 \\\\\n4 & -3\n\\end{bmatrix}\n\\]\n\\(A\\) est une matrice de taille \\((3, 2)\\), \\(B\\) est une matrice de taille \\((3, 1)\\), \\(C\\) est une matrice de taille \\((1, 3)\\), \\(D\\) est une matrice de taille \\((2, 2)\\).\nUne matrice \\((m, 1)\\) est dite matrice colonne. Une matrice \\((1, n)\\) est dite une matrice ligne. Une matrice \\((n, n)\\) est dite une matrice carrée d’ordre \\(n\\).\nOn appelle transposée de \\(A\\) (et on note \\(A^t\\) ou \\(A'\\)), la matrice dont les lignes sont les colonnes de \\(A\\), et dont les colonnes sont les lignes de \\(A\\).\n \\[\nA =\n\\begin{bmatrix}\n-2 & 1 \\\\\n8 & -3 \\\\\n1 & 3\n\\end{bmatrix}\n\\Rightarrow\nA^t =\n\\begin{bmatrix}\n-2 & 8 & 1 \\\\\n1 & -3 & 3\n\\end{bmatrix}\n\\]\n \\[\n(A + B)^t = A^t + B^t\n\\] \\[\n(AB)^t = B^t A\n\\]"
  },
  {
    "objectID": "M1SEP.html#matrices-usuelles",
    "href": "M1SEP.html#matrices-usuelles",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Une matrice carrée d’ordre \\(n\\) est dite diagonale lorsque, pour tout \\(i \\neq j\\), on a \\(a_{ij} = 0\\) : \\[\nA =\n\\begin{bmatrix}\n-2 & 0 & 0 \\\\\n0 & -3 & 0 \\\\\n0 & 0 & 5\n\\end{bmatrix}\n\\]\nLa matrice unité \\(I_n\\) est la matrice diagonale telle que \\(\\forall i = 1, \\ldots, n\\), \\(a_{ii} = 1\\) : \\[\nI_3 =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "M1SEP.html#opérations-de-base",
    "href": "M1SEP.html#opérations-de-base",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Soient \\(A\\) et \\(B\\) deux matrices de même taille \\((m, n)\\) de termes généraux respectifs \\(a_{ij}\\) et \\(b_{ij}\\), et \\(\\lambda\\) un nombre réel.\n\\(A = B\\) si et seulement si \\(a_{ij} = b_{ij}\\) pour tous \\(i,j\\).\n\nLa somme de \\(A\\) et \\(B\\) est la matrice de terme général \\(a_{ij} + b_{ij}\\)\n\n\\[\nA + B =\n\\begin{bmatrix}\n5 + (-4) & 2 + 1 \\\\\n6 + 1 & 1 + (-3)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 3 \\\\\n7 & -2\n\\end{bmatrix}\n\\]\n\n\nLe produit de \\(A\\) par \\(\\lambda\\) est la matrice de terme général \\(\\lambda a_{ij}\\) : \\[\n\\lambda A =\n3 \\times\n\\begin{bmatrix}\n5 & 2 \\\\\n6 & 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n15 & 6 \\\\\n18 & 3\n\\end{bmatrix}\n\\]\n \\[\nA =\n\\begin{bmatrix}\n5 & 2 \\\\\n6 & 1\n\\end{bmatrix}\n;\\quad\nB =\n\\begin{bmatrix}\n-4 & 1 \\\\\n1 & -3\n\\end{bmatrix}\n;\\quad\n\\lambda = 3\n\\] \\[\nA + B =\n\\begin{bmatrix}\n1 & 3 \\\\\n7 & -2 \\\\\n\\end{bmatrix}\n\\hspace{2cm}\n\\lambda A =\n\\begin{bmatrix}\n15 & 6 \\\\\n18 & -2 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "M1SEP.html#multiplication-matricielle",
    "href": "M1SEP.html#multiplication-matricielle",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Le produit de matrices A et B (noté \\(AB\\)) n’est défini que si le nombre de colonnes de \\(A\\) est égal au nombre de lignes de \\(B\\). C’est-à-dire \\(A\\) doit être de taille \\((m, p)\\) et \\(B\\) de taille \\((p, n)\\). Alors \\(AB\\) est de taille \\((m, n)\\). De plus, soient \\(a_{ij}\\) et \\(b_{ij}\\) les termes généraux respectifs de \\(A\\) et \\(B\\), alors le terme général de \\(C\\) = \\(AB\\) est \\(c_{ij}\\) défini par : \\[\nc_{ij} = \\sum_{k=1}^{p} a_{ik} b_{kj}\n\\] \\[A =\n\\begin{bmatrix}\n2 & -2 & 1 \\\\\n-3 & 6 & 8 \\\\\n5 & 2 & 1\n\\end{bmatrix}\n\\hspace{2cm}\nB = \\begin{bmatrix}\n-1 & 5 \\\\\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\\] Alors, la matrice \\(C = AB\\) est donnée par : \\[C = \\begin{bmatrix}\n-1 & 10 \\\\\n33 & 29 \\\\\n0 & 33\n\\end{bmatrix}\\]\nEn effet, l’élément qui se trouve au croisement de la i-ème ligne et la j-ème colonne est : \\[c_{ij} = \\sum_{k=1}^{p} a_{ik} b_{kj}\\]\nPar exemple, \\[c_{2,1} = (-3) \\times (-1) + 6 \\times 1 + 8 \\times 3 = 33\\]"
  },
  {
    "objectID": "M1SEP.html#propriétés",
    "href": "M1SEP.html#propriétés",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Le produit est distributif par rapport à l’addition. C’est-à-dire : \\[\nA (B + C) = AB + AC \\quad \\text{et} \\quad (B + C)A = BA + CA\n\\]\nLe produit est associatif, c’est-à-dire : \\[\nABC = A(BC) = (AB)C\n\\]\nSi A est une matrice carrée d’ordre n, alors \\[A I_n = I_n A = A\\]\nLe produit de deux matrices peut être nul sans que l’une des deux matrices ne soit la matrice nulle, par exemple : \\[\n\\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix} \\times\n\\begin{bmatrix}\n-2 & 10 \\\\\n1 & -5\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "M1SEP.html#inverse",
    "href": "M1SEP.html#inverse",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Une matrice carrée \\(A\\) d’ordre \\(n\\) est dite inversible lorsqu’il existe une matrice \\(B\\) telle que : \\[ A B = B A = I_n \\] \\(B\\) est alors notée \\(A^{-1}\\), l’inverse de \\(A\\)."
  },
  {
    "objectID": "M1SEP.html#systèmes-linéaires",
    "href": "M1SEP.html#systèmes-linéaires",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Grâce au produit matriciel, on peut représenter un système linéaire par une équation matricielle. Soit le système linéaire de \\(n\\) équations et \\(p\\) inconnues :\n\\[\n\\begin{cases}\na_{11} x_1 + a_{12} x_2 + \\ldots + a_{1p} x_p = b_1 \\\\\na_{21} x_1 + a_{22} x_2 + \\ldots + a_{2p} x_p = b_2 \\\\\na_{n1} x_1 + a_{n2} x_2 + \\ldots + a_{np} x_p = b_n\n\\end{cases}\n\\]\nOn peut le représenter par \\(AX = B\\) où :\n\\[A = \\begin{bmatrix}\na_{11} & \\ldots & a_{1p} \\\\\n\\vdots & \\ddots & \\vdots \\\\\na_{n1} & \\ldots & a_{np}\n\\end{bmatrix} ;\n\\hspace{2cm}\nX = \\begin{bmatrix}\nx_1 \\\\\n\\vdots \\\\\nx_p\n\\end{bmatrix} ;\n\\hspace{2cm}\nB = \\begin{bmatrix}\nb_1 \\\\\n\\vdots \\\\\nb_n\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "M1SEP.html#déterminant",
    "href": "M1SEP.html#déterminant",
    "title": "DATA Camp M1",
    "section": "Déterminant",
    "text": "Déterminant\nSoit \\(A = (a_{ij})\\) une matrice carrée d’ordre 2. Le déterminant de \\(A\\) est le réel noté \\(\\text{det}(A)\\) tel que : \\[\n\\text{det}(A) = \\begin{vmatrix}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{vmatrix} = a_{11}a_{22} - a_{12}a_{21}\n\\]\nSoient \\(A = (a_{ij})\\) et \\(B = (b_{ij})\\) deux matrices carrées d’ordre \\(n\\) et \\(\\lambda \\in \\mathbb{R}\\). On a les propriétés suivantes :\n\n\\(\\text{det}(AB) = \\text{det}(A) \\cdot \\text{det}(B) = \\text{det}(BA)\\)\n\\(\\text{det}(A^T) = \\text{det}(A)\\)\n\\(\\text{det}(\\lambda A) = \\lambda^n \\cdot \\text{det}(A)\\)\nSi \\(A\\) est diagonale, alors \\(\\text{det}(A) = a_{11}a_{22}\\ldots a_{nn}\\)\n\\(\\text{det}(I_n) = 1\\)\n\\(A\\) est inversible si et seulement si \\(\\text{det}(A) \\neq 0\\)\nSi \\(\\text{det}(A) \\neq 0\\), alors \\(\\text{det}(A^{-1}) = \\frac{1}{\\text{det}(A)}\\)"
  },
  {
    "objectID": "M1SEP.html#diagonalisation",
    "href": "M1SEP.html#diagonalisation",
    "title": "DATA Camp M1",
    "section": "Diagonalisation",
    "text": "Diagonalisation\n\nUne valeur propre de \\(A\\) est un scalaire \\(\\lambda\\) tel qu’il existe un vecteur colonne non nul \\(V\\) vérifiant : \\(AV = \\lambda V\\). \\(V\\) est alors appelé vecteur propre de \\(A\\) associé à \\(\\lambda\\).\n\nUne matrice carrée \\(A\\) d’ordre \\(n\\) est diagonalisable lorsqu’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\(A = PDP^{-1}\\). \\(D\\) est constituée des valeurs propres de \\(A\\). \\(P\\) est obtenue par la concaténation des vecteurs propres de \\(A\\). Si les valeurs propres de \\(A\\) sont distinctes, alors \\(A\\) est diagonalisable (réciproque fausse)."
  },
  {
    "objectID": "M1SEP.html#matrice-symétrique",
    "href": "M1SEP.html#matrice-symétrique",
    "title": "DATA Camp M1",
    "section": "Matrice symétrique",
    "text": "Matrice symétrique\nUne matrice carrée \\(A\\) d’ordre \\(n\\) est symétrique lorsque \\(A^T = A\\). Si \\(A\\) est symétrique, alors :\n\n\\(A\\) a des valeurs propres réelles.\n\\(A\\) est diagonalisable.\nIl existe une matrice \\(P\\) telle que \\(P^{-1} = P^T\\) et \\(A = PDP^{-1}\\)."
  },
  {
    "objectID": "M1SEP.html#produit-scalaire",
    "href": "M1SEP.html#produit-scalaire",
    "title": "DATA Camp M1",
    "section": "Produit scalaire",
    "text": "Produit scalaire\nSoit \\(x\\), \\(y\\), \\(z\\) trois vecteurs de \\(\\mathbb{R}^n\\) et \\(\\lambda\\) un scalaire. On définit par produit scalaire (qu’on note \\(\\langle \\cdot, \\cdot \\rangle\\)) toute application qui vérifie les propriétés suivantes :\n\n\\(\\langle x + \\lambda y, z \\rangle = \\langle x, z \\rangle + \\lambda \\langle y, z \\rangle\\)\n\\(\\langle x, y + \\lambda z \\rangle = \\langle x, z \\rangle + \\lambda \\langle x, z \\rangle\\)\n\\(\\langle x, y \\rangle = \\langle y, x \\rangle\\)\n\\(\\langle x, x \\rangle \\geq 0\\)\n\\(\\langle x, x \\rangle = 0 \\Rightarrow x = 0\\)\n\nLe produit scalaire canonique et usuel est défini comme : \\[\n\\langle x, y \\rangle = \\sum_{i=1}^{n} x_i \\cdot y_i\n\\]"
  },
  {
    "objectID": "M1SEP.html#norme",
    "href": "M1SEP.html#norme",
    "title": "DATA Camp M1",
    "section": "Norme",
    "text": "Norme\nOn appelle norme associée à un produit scalaire le réel \\(\\|x\\| = \\sqrt{\\langle x, x \\rangle}\\). Elle vérifie les propriétés suivantes :\n\n\\(|\\langle x, y \\rangle| \\leq \\|x\\| \\cdot \\|y\\|\\) (Inégalité de Cauchy-Schwartz)\n\\(\\|x + y\\| \\leq \\|x\\| + \\|y\\|\\) (Inégalité triangulaire)\n\\(\\|x\\| \\geq 0\\) avec égalité si \\(x = 0\\)\n\\(\\|\\lambda x\\| = |\\lambda| \\cdot \\|x\\|\\)\n\\(\\|x + y\\|^2 = \\|x\\|^2 + \\|y\\|^2 + 2\\langle x, y \\rangle\\)\n\nUn vecteur est dit unitaire ou normé si \\(\\|x\\| = 1\\)"
  },
  {
    "objectID": "M1SEP.html#orthogonalité",
    "href": "M1SEP.html#orthogonalité",
    "title": "DATA Camp M1",
    "section": "Orthogonalité",
    "text": "Orthogonalité\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) associé à la norme euclidienne \\(\\|\\cdot\\|_2\\).On note \\(v = (v_1, \\ldots, v_n)^t\\) et \\(w = (w_1, \\ldots, w_n)^t\\) où $ v_i$ et \\(w_j\\) sont des scalaires (i.e. des réels).\n\nNormalisation d’un vecteur\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|x\\|_2 = 1\\). Un espace vectoriel engendré par \\(v_1, \\ldots, v_p\\) est identique à celui engendré par leurs versions normalisées.\nDeux vecteurs \\(x\\) et \\(y\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle x, y \\rangle = 0\\] Une base orthonormale est une base où tous les vecteurs sont orthogonaux et de norme 1.\n\n\nMatrice de Projection Orthogonale\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\nPropriétés\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\n\\Pi_{W^\\perp} B = B - \\Pi_{W} B\n\\]\n\n\n\nConstruction de matrice de projection Orthogonale\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leq n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(W = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection \\(W\\) de \\(\\mathbb{R}^n\\) sur \\(W\\) est : \\[\nW = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de \\(W\\), alors : \\[\nW = V V^t\n\\]\n\n\nProcédé d’orthogonalisation de Gram-Schmidt\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\n\n\n\n\n\n\nTip\n\n\n\nAvant de recourir au procédé de Gram-Schmidt, il faut s’assurer que les vecteurs ne soient pas déjà orthogonaux, cela serait une perte de temps de les recalculer. Ce calcul est long, il faut bien prendre son temps pour le faire et ne pas se précipiter.\n\n\nÉtapes du Procédé\nLe premier vecteur orthogonal ( u_1 ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où \\(( k \\geq 2 )\\)), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]"
  },
  {
    "objectID": "M1SEP.html#projection-orthogonale",
    "href": "M1SEP.html#projection-orthogonale",
    "title": "DATA Camp M1",
    "section": "Projection orthogonale",
    "text": "Projection orthogonale\nSoit \\(x\\) un vecteur d’un espace muni d’un produit scalaire \\(E\\). Soit \\(F\\) un sous-espace vectoriel de \\(E\\), \\(x\\) s’écrit de façon unique sous la forme : \\(x = f + f^\\perp\\) où \\(f \\in F\\) et \\(f^\\perp \\in F^\\perp\\). On dit que \\(f\\) est le projeté orthogonal de \\(x\\) sur \\(F\\) et on note \\(f = P_F(x)\\).\nPour \\(x\\) et \\(y\\) de \\(E\\), on a \\(\\langle P_F(x),y\\rangle = \\langle x, P_F(y)\\&gt;\\).\nSi \\((e_1, e_2, \\ldots, e_n)\\) est une base orthonormée, alors : \\(P_F(x) = \\sum_{i=1}^n \\langle x, e_i \\rangle e_i\\)\nNotons que : \\(\\|x - P_F(x)\\| = \\inf_{f \\in F} \\|x - f\\|\\)"
  },
  {
    "objectID": "M1SEP.html#matrice-orthogonale",
    "href": "M1SEP.html#matrice-orthogonale",
    "title": "DATA Camp M1",
    "section": "Matrice orthogonale",
    "text": "Matrice orthogonale\nSoit \\(M\\) une matrice carrée d’ordre \\(n\\). On dit que \\(M\\) est une matrice orthogonale si elle vérifie : \\[M \\cdot M^T = M^T \\cdot M = I_n\\]\nLe déterminant d’une matrice orthogonale est égal à \\(\\pm 1\\). L’ensemble des valeurs propres de \\(M\\) est inclus dans l’ensemble \\(\\{0, 1\\}\\)."
  },
  {
    "objectID": "M1SEP.html#quelques-définitions",
    "href": "M1SEP.html#quelques-définitions",
    "title": "DATA Camp M1",
    "section": "Quelques définitions",
    "text": "Quelques définitions\n\nOn appelle épreuve \\(E\\) toute expérience probabiliste.\nOn appelle univers de \\(E\\) l’ensemble, généralement noté \\(\\Omega\\), de tous les résultats possibles de l’épreuve \\(E\\) (appelés “événements élémentaires”).\n\nLancer une paire de dés équilibrés et en retenir la somme est une épreuve. \\(\\Omega = \\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}\\)"
  },
  {
    "objectID": "M1SEP.html#evénements",
    "href": "M1SEP.html#evénements",
    "title": "DATA Camp M1",
    "section": "Evénements",
    "text": "Evénements\nUn événement est un sous-ensemble de \\(\\Omega\\).\n\nL’intersection de \\(A\\) et \\(B\\), notée \\(A \\cap B\\), est un événement. Il est réalisé uniquement si \\(A\\) et \\(B\\) se produisent.\nLa réunion de \\(A\\) et \\(B\\), notée \\(A \\cup B\\), est un événement. Il est réalisé si \\(A\\) ou \\(B\\) se produit. Deux événements remarquables sont à retenir :\n\nL’événement certain \\(\\Omega\\) ;\nL’événement impossible \\(\\emptyset\\) ;\n\nTous les éléments qui n’appartiennent pas à \\(A\\) appartiennent à un événement que l’on appelle le complémentaire de \\(A\\). On le note \\(\\overline{A}\\) ou \\(A^C\\).\nOn dit que deux événements \\(A\\) et \\(B\\) sont incompatibles s’ils ne peuvent pas être réalisés en même temps.\n\nSi \\(A\\), \\(B\\) et \\(C\\) sont des événements de \\(\\Omega\\), les propriétés suivantes sont toujours vérifiées :\n\n\\(A \\cup \\overline{A} = \\Omega\\) et \\(A \\cap \\overline{A} = \\emptyset\\)\n\\(\\overline{\\overline{A} \\cap \\overline{B}} = \\overline{A} \\cup \\overline{B}\\) et \\(\\overline{\\overline{A} \\cup \\overline{B}} = \\overline{A} \\cap \\overline{B}\\) (lois de De Morgan)\n\\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\)\n\\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)"
  },
  {
    "objectID": "M1SEP.html#partitions",
    "href": "M1SEP.html#partitions",
    "title": "DATA Camp M1",
    "section": "Partitions",
    "text": "Partitions\nLa famille d’événements forme une partition de \\(\\Omega\\) si : \\[\n\\bigcup_{i \\in I} A_i = \\Omega \\quad \\text{et} \\quad A_i \\cap A_j = \\emptyset \\text{ pour tout } i \\neq j.\n\\] Une partition remarquable est la famille qui contient l’événement \\(A\\) et son complémentaire."
  },
  {
    "objectID": "M1SEP.html#tribus-et-boréliens",
    "href": "M1SEP.html#tribus-et-boréliens",
    "title": "DATA Camp M1",
    "section": "Tribus et boréliens",
    "text": "Tribus et boréliens\n \n\nUne tribu est une famille \\(T\\) de parties de l’ensemble \\(\\Omega\\) qui vérifie les propriétés suivantes : - \\(\\Omega \\in T\\)\n- Si \\((A_n)\\) est une suite dénombrable d’éléments de \\(T\\), alors \\(\\bigcup A_n \\in T\\)\n— Si \\(A\\) est un élément de \\(T\\), alors son complémentaire l’est aussi.\nDe plus, si \\(T\\) est une tribu, alors : - \\(\\emptyset \\in T\\)\n- Si \\((A_n)\\) est une suite d’éléments de \\(T\\), alors \\(\\bigcap A_n \\in T\\).\n\nPour le cas discret, on considère l’expérience “Lancer une pièce de monnaie équilibrée”.\nOn notera : \\(P\\) pour “PILE apparaît” et \\(F\\) pour “FACE apparaît”.\nDans ce cas, l’univers est l’ensemble \\(\\{P, F\\}\\) et \\(T = \\{\\Omega, \\emptyset, P, F\\}\\) est une tribu.\nEn général, l’ensemble des parties est une tribu classique.\nPour le cas continu, les intervalles du type \\([a, +\\infty[\\), \\(]a, +\\infty[\\), \\(]-\\infty, a[\\), \\(]-\\infty, a]\\) sont des tribus. Nous les appelons DES BORÉLIENS.\n\nSoient \\(A\\) et \\(B\\) deux événements. Les propriétés suivantes sont toujours vraies :\n\n\\(P(A^C) = 1 - P(A)\\)\n\n\\(P(B) = P(A \\cap B) + P(A^C \\cap B)\\)\n\nSi \\(A \\subset B\\), alors \\(P(A) \\leq P(B)\\)\n\n\\(0 \\leq P(A) \\leq 1\\)\n\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\n\nDe plus, en considérant une suite \\((A_k)\\) d’événements, on a les relations suivantes : \\[\n\\begin{aligned}\nP\\left(\\bigcup A_k\\right) & = \\lim_{n \\to +\\infty} P\\left(\\bigcup_{k=1}^n A_k\\right) \\\\\nP\\left(\\bigcap A_k\\right) & = \\lim_{n \\to +\\infty} P\\left(\\bigcap_{k=1}^n A_k\\right) \\\\\nP\\left(\\bigcup A_k\\right) & \\leq \\sum_{k=1}^{+\\infty} P(A_k)\n\\end{aligned}\n\\]\nEt si \\(\\bigcup A_k = \\Omega\\), alors : \\[\nP(B) = \\sum_{k=1}^{+\\infty} P(B \\cap A_k)\n\\]"
  },
  {
    "objectID": "M1SEP.html#mesure",
    "href": "M1SEP.html#mesure",
    "title": "DATA Camp M1",
    "section": "Mesure",
    "text": "Mesure\nSoit \\(E\\) un ensemble muni d’une tribu \\(T\\). On appelle mesure toute application \\(m : T \\rightarrow \\mathbb{R}^+\\) telle que : - \\(m(\\emptyset) = 0\\) - Si \\((A_n)\\) est une suite d’éléments de \\(T\\) deux à deux disjoints alors : \\[m\\left(\\bigcup_n A_n\\right) = \\sum_n m(A_n).\\]"
  },
  {
    "objectID": "M1SEP.html#probabilités",
    "href": "M1SEP.html#probabilités",
    "title": "DATA Camp M1",
    "section": "",
    "text": "En théorie, on représente la moyenne comme l’espérance : Dans le cas discret : \\[E(X) = \\sum k \\cdot P(X = k)\\] \\[k \\in X(\\Omega)\\] Alors que dans le cas continu : \\[E(X) = \\int x \\cdot f_X(x) \\, dx\\] \\[x \\in X(\\Omega)\\]\n\n\nLa fonction de répartition est définie par : \\[F_X(x) = P(X \\leqslant x)\\]\nPour tout \\(x\\), \\(0 \\leqslant F_X(x) \\leqslant 1\\), \\(F_X\\) est une fonction croissante. De plus, \\(\\lim_{x \\to -\\infty} F_X(x) = 0\\) et \\(\\lim_{x \\to \\infty} F_X(x) = 1\\)\n\n\n\n\n\n\n\n\nLa loi marginale de X est définie comme suit : \\[f_X(x) = \\int f_{X, Y}(x, y) \\, dy, \\text{ où } -\\infty &lt; x &lt; \\infty,\\] dans le cas continu, ou encore : \\[f_X(x_i) = \\sum p_{ij}, \\text{ où } j \\text{ tel que } y_j \\leqslant y\\]\nSi X et Y sont indépendants, alors : \\[f_{X, Y}(x, y) = f_X(x) \\cdot f_Y(y)\\] \n\n\n\n\n\n\nLe centrage consiste à localiser la distribution autour de l’origine et la réduction consiste à normaliser la dispersion. On crée une nouvelle variable aléatoire \\(Y\\) issu de \\(X\\) dont l’espérance est null et la variable est égale à 1. \\[Y = \\frac{X - E(X)}{\\sqrt{\\sigma(X)^2}}\\] où \\(E(X)\\) représente l’espérance de X et \\(\\sigma^2\\) est la variance de \\(X\\).\n\n\n\nLe moment d’ordre r est défini par : \\[\\mu_r = E(X^r)\\] Le moment centré d’ordre r est défini par : \\[\\mũ_r = E((X - E(X))^r)\\]\n\n\n\n\n\nLa fonction conjointe est appelée la distribution conjointe de X et Y. \\[F_{X, Y}(x, y) = P(X \\leqslant x \\cap Y \\leqslant y)\\]\nDans le cas continu, la fonction définie par : \\[f_{X, Y}(x, y) = \\frac{\\partial^2 F_{X, Y}(x, y)}{\\partial x \\partial y}\\] est la densité conjointe du couple (X, Y). On a donc : \\[F_{X, Y}(x, y) = \\int \\int f_{X, Y}(t, u) \\, dt \\, du, \\text{ où } -\\infty &lt; x, y &lt; +\\infty,\\]\nDans le cas discret, on définit la fonction de probabilité conjointe : \\[P(X = x_i, Y = y_j) = p_{ij}\\] On a donc : \\[F_{X, Y}(x, y) = \\sum \\sum p_{ij}, \\text{ où } x_i \\leqslant x \\text{ et } y_j \\leqslant y\\]\n\n\n\nLa covariance mesure l’intensité de la relation linéaire entre deux variables aléatoires X et Y. Elle est définie comme suit : \\[Cov(X, Y) = E(XY) - E(X) \\cdot E(Y)\\]\nSi X et Y sont indépendants, alors : \\[Cov(X, Y) = 0\\]\n\n\n\n\n\n\nWarning\n\n\n\nIl est important de noter que la réciproque n’est pas vraie : la covariance n’implique pas nécessairement l’indépendance entre X et Y.\n\n\n\n\n\n\n\nEspérance \\[\n\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y)\n\\]\n\\[\n\\mathbb{E}(a) = a\n\\] Variance\n\\[\n\\text{Var}(aX) = a^2\\text{Var}(X)\n\\] \\[\n\\text{Var}(a) = 0\n\\] \\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\n\\]\n\\[ \\text{Si } X \\coprod Y \\text{ alors } \\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y)\\]\nCovariance \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X)\n\\]\n\\[\n\\text{Cov}(aX + bY, cU + dV) = ac\\text{Cov}(X, U) + ad\\text{Cov}(X, V) + bc\\text{Cov}(Y, U) + bd\\text{Cov}(Y, V)\n\\]\n\n\n\nL’espérance d’un vecteur aléatoire \\(X = (X_1, X_2, \\vdots, X_n)^t\\) de X est le vecteur des espérances de \\(X_i\\) c’est-à-dire \\(\\mathbb{E}(X) = \\left(\\begin{array}{c} E(X_1) \\\\ \\ldots \\\\ \\mathbb{E}(X_n) \\end{array} \\right)\\).\nL’espérance reste linéaire, en particulier pour \\(X\\) et \\(Y\\) appartenant à \\(R^n\\) on a :\n\\[\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y) \\text{ où } a,b \\in \\mathbb{R}\\] \\[\\mathbb{E}(AX + B) = A\\mathbb{E}(X)+B\\]\nLa variance-covariance de X notée \\(\\Sigma\\) une matrice \\(n \\times n\\) où chaque élément \\(\\Sigma_{ij}\\) représente la covariance entre les variables aléatoires \\(X_i\\) et \\(X_j\\). Les éléments diagonaux de \\(\\Sigma\\) correspondent aux variances des composantes \\(X_i\\), tandis que les éléments hors-diagonaux représentent les covariances entre les différentes composantes de \\(X\\). La matrice \\(\\Sigma\\) est donc définie comme suit :\n\\[\n\\Sigma = \\begin{pmatrix}\n\\text{Var}(X_1) & \\text{Cov}(X_1, X_2) & \\dots & \\text{Cov}(X_1, X_n) \\\\\n\\text{Cov}(X_2, X_1) & \\text{Var}(X_2) & \\dots & \\text{Cov}(X_2, X_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(X_n, X_1) & \\text{Cov}(X_n, X_2) & \\dots & \\text{Var}(X_n)\n\\end{pmatrix}\n\\] \\[ \\Sigma_{AX + B} = A\\Sigma_X(X)A^t\\] où \\(\\Sigma\\) est la variance de X et A,B sont des matrices (deterministe)\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nLes variables \\(X_1, \\ldots, X_n\\) sont indépendantes et identiquement distribuées (i.i.d.) si et seulement si :\nDans le cas discret : \\[P(X_1 = x_1, \\ldots, X_n = x_n) = P(X_1 = x_1) \\times \\ldots \\times P(X_n = x_n)\\]\nDans le cas continu :\n\\[P(X_1 \\leq x_1, X_2 \\leq x_2, \\ldots, X_n \\leq x_n) = P(X_1 \\leq x_1) \\cdot P(X_2 \\leq x_2) \\cdots P(X_n \\leq x_n)\\]\n\n\nCes tableaux récapitulent les lois usuelles que vous pourrez rencontrer dans différents cours du master.\n\n\n\n\n\n\n\n\n\n\n\nNom\nNotation\n\\(X(\\Omega)\\)\n\\(P(X = k)\\)\n\\(E[X]\\)\n\\(Var(X)\\)\n\n\n\n\nUniforme\n\\(X \\sim U(\\{1, 2, \\ldots, n\\})\\)\n\\(\\{1, 2, \\ldots, n\\}\\)\n\\(\\frac{1}{n}\\)\n\\(\\frac{n+1}{2}\\)\n\\(\\frac{n^2-1}{12}\\)\n\n\nBernouilli\n\\(X \\sim B(p), 0 &lt; p &lt; 1\\)\n\\(\\{0, 1\\}\\)\n\\(P(X = 1) = p\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\n\n\n\n\\(P(X = 0) = 1 - p\\)\n\n\n\n\nBinomiale\n\\(X \\sim B(n, p), 0 &lt; p &lt; 1\\)\n\\(\\{1, 2, \\ldots, n\\}\\)\n\\(C_k^n p^k (1 - p)^{n-k}\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\nGéométrique\n\\(X \\sim G(p), 0 &lt; p &lt; 1\\)\n\\(\\mathbb{N}^{*}\\)\n\\(p(1-p)^{k}\\)\n\\(\\frac{1-p}{p}\\)\n\\(\\frac{1-p}{p^2}\\)\n\n\nPoisson\n\\(X \\sim P(\\lambda), \\lambda &gt; 0\\)\n\\(\\mathbb{N}\\)\n\\(\\frac{\\lambda^k}{k!}e^{-\\lambda}\\)\n\\(\\lambda\\)\n\\(\\lambda\\)"
  },
  {
    "objectID": "M1SEP.html#probabilités-conditionnelles",
    "href": "M1SEP.html#probabilités-conditionnelles",
    "title": "DATA Camp M1",
    "section": "Probabilités conditionnelles",
    "text": "Probabilités conditionnelles\nEn théorie des probabilités, nous nous intéressons souvent au comportement d’un aléa, sachant qu’un autre événement est déjà passé. C’est ce que nous appelons Les Probabilités Conditionnelles.\nConsidérant deux événements de probabilité non nulle, \\(A\\) et \\(B\\), la probabilité conditionnelle de \\(A\\) sachant que \\(B\\) est réalisé (couramment dit \\(A\\) sachant \\(B\\)) est donnée par : \\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nPar commutativité de l’intersection, nous avons : \\[\nP(A \\cap B) = P(B \\cap A)\n\\]\nEn utilisant la formule ci-dessus, nous pouvons également exprimer la probabilité conditionnelle de \\(B\\) sachant \\(A\\) : \\[\nP(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n\\]\nC’est ce que nous appelons ."
  },
  {
    "objectID": "M1SEP.html#indépendance",
    "href": "M1SEP.html#indépendance",
    "title": "DATA Camp M1",
    "section": "Indépendance",
    "text": "Indépendance\nDeux événements \\(A\\) et \\(B\\) sont dits indépendants si et seulement si : \\[P(A \\cap B) = P(A) \\cdot P(B)\\] En termes courants, deux événements sont indépendants si le résultat de l’un n’influence aucunement l’aboutissement de l’autre. Sous condition d’indépendance de \\(A\\) et \\(B\\), la notion de la probabilité conditionnelle tombe à l’eau, car les événements évoluent l’un sans se soucier de l’autre. Ceci se traduit par : \\[P(A|B) = P(A)\\] \\[P(B|A) = P(B)\\]\nNotons que si \\(A\\) est indépendant de \\(B\\), il le sera par rapport à son complémentaire également, et vice versa. En général, pour une suite \\((A_n)\\) d’événements indépendants, on a : \\[P\\left(\\bigcap A_i\\right) = \\prod P(A_i) = P(A_1) \\cdot \\ldots \\cdot P(A_n)\\] Cette formule est largement utilisée en statistique."
  },
  {
    "objectID": "M1SEP.html#variable-aléatoire",
    "href": "M1SEP.html#variable-aléatoire",
    "title": "DATA Camp M1",
    "section": "Variable aléatoire",
    "text": "Variable aléatoire\nUne variable aléatoire est un nombre qui dépend du résultat d’une expérience aléatoire. Chaque exécution de l’expérience génère une réalisation de la variable aléatoire.\nMathématiquement, on définit une variable aléatoire X comme une fonction \\(X : T \\rightarrow \\mathbb{R}\\) qui associe à chaque événement s, un réel \\(X(s)\\).\nPar exemple, dans une queue pour la caisse d’un magasin, le nombre de clients est une variable aléatoire. La durée de traitement de chaque requête aussi. Remarquons que la première est un nombre entier. On dit qu’elle est à support discret. Alors que la deuxième est une durée (un nombre réel). On dit qu’elle est à support continu."
  },
  {
    "objectID": "M1SEP.html#fonction-de-répartition",
    "href": "M1SEP.html#fonction-de-répartition",
    "title": "DATA Camp M1",
    "section": "Fonction de répartition",
    "text": "Fonction de répartition\nUne variable aléatoire traduit le résultat d’une expérience aléatoire en nombre réel. La fonction de répartition transporte le calcul des probabilités concernant les réalisations de la variable aléatoire. C’est la fonction définie par : \\[F_X(x) = P(X \\leq x)\\] \nPour tout \\(x\\), \\(0 \\leq F_X(x) \\leq 1\\) \\(F_X\\) est une fonction croissante. \\(\\lim_{x \\to -\\infty} F_X(x) = 0\\) et \\(\\lim_{x \\to \\infty} F_X(x) = 1\\)"
  },
  {
    "objectID": "M1SEP.html#probabilité-ponctuelle-densité",
    "href": "M1SEP.html#probabilité-ponctuelle-densité",
    "title": "DATA Camp M1",
    "section": "Probabilité ponctuelle / Densité",
    "text": "Probabilité ponctuelle / Densité\n\nLa probabilité ponctuelle est la fonction qui décrit les sauts de la fonction de répartition : \\[P(X = k) = P(X \\leq k) - P(X \\leq k - 1) = p_k\\] \\[\\sum p_i = 1\\]\n\nLa densité est la fonction qui décrit les variations de la fonction de répartition : \\[f(x) = \\frac{dF_X}{dx}(x)\\] \\[\\int f(x) dx = 1\\]"
  },
  {
    "objectID": "M1SEP.html#moments",
    "href": "M1SEP.html#moments",
    "title": "DATA Camp M1",
    "section": "Moments",
    "text": "Moments\n\nL’espérance d’une variable aléatoire est sa valeur attendue. C’est une mesure de localisation de la distribution.\nDans le cas discret : \\[E(X) = \\sum k \\cdot P(X = k)\\] \\[k \\in X(\\Omega)\\] Alors que dans le cas continu : \\[E(X) = \\int x \\cdot f_X(x) \\, dx\\] \\[x \\in X(\\Omega)\\]\n \\[E(g(X)) = \\sum g(k) \\cdot P(X = k)\\] \\[\\forall k \\in X(\\Omega)\\] \\[E(g(X)) = \\int g(x) \\cdot f_X(x) \\, dx\\] \\[\\forall x \\in X(\\Omega)\\] \nLa variance d’une variable aléatoire décrit la dispersion de la variable aléatoire autour de sa valeur moyenne (son espérance).\nElle est définie par : \\[Var(X) = E(X^2) - (E(X))^2 = E((x - E(X))^2)\\] Sa racine carrée est appelée écart-type et notée généralement : \\[\\sigma(X) = \\sqrt{Var(X)}\\]\n\nLe centrage consiste à localiser la distribution autour de l’origine et la réduction consiste à normaliser la dispersion. La technique est simple : \\[Y = \\frac{X - E(X)}{\\sigma(X)}\\]\n\nLe moment d’ordre r est défini par : \\[\\mu_r = E(X^r)\\] Le moment centré d’ordre r est défini ainsi : \\[\\mũ_r = E((X - E(X))^r)\\]"
  },
  {
    "objectID": "M1SEP.html#couples-aléatoires",
    "href": "M1SEP.html#couples-aléatoires",
    "title": "DATA Camp M1",
    "section": "Couples aléatoires",
    "text": "Couples aléatoires\nLa fonction conjointe \\[F_{X, Y}(x, y) = P(X \\leq x \\cap Y \\leq y)\\] est appelée la distribution conjointe de X et Y.\nDans le cas continu, la fonction définie par : \\[f_{X, Y}(x, y) = \\frac{\\partial^2 F_{X, Y}(x, y)}{\\partial x \\partial y}\\] est la densité conjointe du couple (X, Y). On a donc : \\[F_{X, Y}(x, y) = \\int \\int f_{X, Y}(t, u) \\, dt \\, du, \\text{ où } -\\infty &lt; x, y &lt; +\\infty,\\]\nDans le cas discret, on définit la fonction de probabilité conjointe : \\[P(X = x_i, Y = y_j) = p_{ij}\\] On a donc : \\[F_{X, Y}(x, y) = \\sum \\sum p_{ij}, \\text{ où } x_i \\leq x \\text{ et } y_j \\leq y\\]\n\nLa loi marginale de X est définie comme suit : \\[f_X(x) = \\int f_{X, Y}(x, y) \\, dy, \\text{ où } -\\infty &lt; x &lt; \\infty,\\] dans le cas continu, ou encore : \\[f_X(x_i) = \\sum p_{ij}, \\text{ où } j \\text{ tel que } y_j \\leq y\\]\nSi X et Y sont indépendants, alors : \\[f_{X, Y}(x, y) = f_X(x) \\cdot f_Y(y)\\]\n\nLa covariance mesure l’intensité de la relation linéaire entre deux variables aléatoires X et Y. Elle est définie comme suit : \\[Cov(X, Y) = E(XY) - E(X) \\cdot E(Y)\\]\nSi X et Y sont indépendants, alors : \\[Cov(X, Y) = 0\\]"
  },
  {
    "objectID": "M1SEP.html#propriétés-1",
    "href": "M1SEP.html#propriétés-1",
    "title": "DATA Camp M1",
    "section": "Propriétés",
    "text": "Propriétés\n \\[\n\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y)\n\\] \\[\n\\mathbb{E}(a) = a\n\\]\n \\[\n\\text{Var}(aX) = a^2\\text{Var}(X)\n\\] \\[\n\\text{Var}(a) = 0\n\\] \\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\n\\] \\[\n\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\text{Cov}(X,Y)\n\\]\n \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X)\n\\] \\[\n\\text{Cov}(aX + b, cY + d) = ac\\text{Cov}(X, Y)\n\\] \\[\n\\text{Cov}(aX + bY, U) = a\\text{Cov}(X, U) + b\\text{Cov}(Y, U)\n\\] \\[\n\\text{Cov}(X, cU + dV) = c\\text{Cov}(X, U) + d\\text{Cov}(X, V)\n\\] \\[\n\\text{Cov}(aX + bY, cU + dV) = ac\\text{Cov}(X, U) + ad\\text{Cov}(X, V) + bc\\text{Cov}(Y, U) + bd\\text{Cov}(Y, V)\n\\]"
  },
  {
    "objectID": "M1SEP.html#vecteurs-aléatoires",
    "href": "M1SEP.html#vecteurs-aléatoires",
    "title": "DATA Camp M1",
    "section": "Vecteurs aléatoires",
    "text": "Vecteurs aléatoires\nPour un vecteur aléatoire \\[(X_1, X_2, \\ldots, X_n)\\], l’espérance est toujours linéaire. Pour une suite \\[(a_i)_{i \\in \\{1, \\ldots, n\\}}\\] de réels, on a : \\[\n\\mathbb{E}(a_1X_1 + a_2X_2 + \\ldots + a_nX_n) = a_1\\mathbb{E}(X_1) + a_2\\mathbb{E}(X_2) + \\ldots + a_n\\mathbb{E}(X_n)\n\\]\nSi les variables aléatoires \\[X_1, X_2, \\ldots, X_n\\] sont indépendantes, alors la variance de leur somme est égale à la somme de leurs variances individuelles : \\[\n\\text{Var}(X_1 + X_2 + \\ldots + X_n) = \\text{Var}(X_1) + \\ldots + \\text{Var}(X_n)\n\\]"
  },
  {
    "objectID": "M1SEP.html#lois-usuelles",
    "href": "M1SEP.html#lois-usuelles",
    "title": "DATA Camp M1",
    "section": "Lois usuelles",
    "text": "Lois usuelles\nCes tableaux récapitulent les lois usuelles que vous pourrez rencontrer dans différents cours du master.\n\\[\\Gamma(x) = \\int_0^{\\infty} t^{x-1}e^{-t} \\, dt \\text{ : désigne la fonction Gamma d'Euler}\\]\n\\[B(x, y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)} \\text{ : désigne la fonction Bêta}\\]\nNous allons souvent rencontrer les lois grisées dans les Tests statistiques. Là encore, connaître les densités ne servirait pas à grand chose, mais ceci nous évitera de parler de lois dont nous ne connaissons pas la tête."
  },
  {
    "objectID": "M1SEP.html#vecteurs-aléatoires-1",
    "href": "M1SEP.html#vecteurs-aléatoires-1",
    "title": "DATA Camp M1",
    "section": "Vecteurs aléatoires",
    "text": "Vecteurs aléatoires\n\nLes variables \\(X_1, \\ldots, X_n\\) sont deux à deux indépendantes si et seulement si : \\(\\forall i \\neq j, X_i\\) et \\(X_j\\) sont indépendantes.\n\nLes variables \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes si et seulement si : \\[P(X_1 = x_1, \\ldots, X_n = x_n) = P(X_1 = x_1) \\times \\ldots \\times P(X_n = x_n)\\]\n\nSi \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes, alors pour toute famille de fonctions réelles \\(f_i\\), on a : \\((f_1(X_1), \\ldots, f_n(X_n))\\) sont indépendantes.\n\nSoit \\(X = (X_1, \\ldots, X_n)^T\\) un vecteur aléatoire. Dans le cas multidimensionnel, l’espérance scalaire est remplacée par un vecteur espérance. \\[E(X) = (E(X_1), \\ldots, E(X_n))^T\\]\nLa variance unidimensionnelle est remplacée par la matrice symétrique de variance-covariance. Elle contient les variances en diagonale et les covariances ailleurs. On la note généralement \\(\\Sigma_X\\). \\[\\Sigma_X = \\begin{bmatrix}\nV(X_1) & \\ldots & \\text{Cov}(X_1, X_n) \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(X_n, X_1) & \\ldots & V(X_n)\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "M1SEP.html#notions-de-convergence",
    "href": "M1SEP.html#notions-de-convergence",
    "title": "DATA Camp M1",
    "section": "Notions de convergence",
    "text": "Notions de convergence\nSi l’on pense à des données, vues comme réalisation de variables aléatoires \\(X_1, \\ldots, X_n\\), il serait intéressant de se poser la question de savoir comment évolue cette suite lorsque \\(n\\) tend vers l’infini.\n\nOn dit que \\((X_n)\\) converge presque sûrement vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p.s.}} X\\) si et seulement si : \\(P\\left(\\lim_{{n\\to+\\infty}} X_n = X\\right) = 1\\)\n\nOn dit que \\((X_n)\\) converge en probabilité vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p}} X\\) si et seulement si : \\(\\forall \\varepsilon &gt; 0, \\quad P(|X_n - X| &gt; \\varepsilon) \\rightarrow 0\\)\n\nOn dit que \\((X_n)\\) converge en loi vers \\(X\\) et on note \\(X_n \\xrightarrow{\\mathcal{L}} X\\) si et seulement si : \\(F_{X_n} \\xrightarrow{n \\to +\\infty} F_X\\) Où \\(F_X\\) dénote la fonction de répartition de \\(X\\).\n\nOn dit que \\((X_n)\\) converge en moyenne quadratique vers \\(X\\) et on note \\(X_n \\xrightarrow{m.q.} X\\) si et seulement si : \\(\\mathbb{E}((X_n - X)^2) \\rightarrow 0\\) Cette définition peut se généraliser jusqu’à l’ordre \\(n\\), mais nous n’en aurons pas besoin."
  },
  {
    "objectID": "M1SEP.html#loi-faible-des-grands-nombres",
    "href": "M1SEP.html#loi-faible-des-grands-nombres",
    "title": "DATA Camp M1",
    "section": "Loi faible des grands nombres",
    "text": "Loi faible des grands nombres\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\) alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p} \\mu \\]"
  },
  {
    "objectID": "M1SEP.html#loi-forte-des-grands-nombres",
    "href": "M1SEP.html#loi-forte-des-grands-nombres",
    "title": "DATA Camp M1",
    "section": "Loi forte des grands nombres",
    "text": "Loi forte des grands nombres\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p.s.} \\mu\\]"
  },
  {
    "objectID": "M1SEP.html#théorème-central-limite",
    "href": "M1SEP.html#théorème-central-limite",
    "title": "DATA Camp M1",
    "section": "Théorème Central Limite",
    "text": "Théorème Central Limite\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors : \\[\\sqrt{n}\\frac{\\overline{X}_n - \\mu}{\\sigma} \\xrightarrow{\\mathcal{Loi}} \\mathcal{N}(0, 1)\\]"
  },
  {
    "objectID": "M1SEP.html#echantillon-estimateur",
    "href": "M1SEP.html#echantillon-estimateur",
    "title": "DATA Camp M1",
    "section": "Echantillon / Estimateur",
    "text": "Echantillon / Estimateur\nLe point de départ est un vecteur (ou un tableau dans le cas multidimensionnel) de données. Ces données peuvent être vues comme les réalisations \\((x_1, x_2, \\ldots, x_n)\\) d’une variable aléatoire \\(X\\) qui dépend d’un certain paramètre \\(\\theta\\) que nous allons chercher à estimer. Pour ce faire, nous allons construire un échantillon de cette variable. Un échantillon \\((X_1, X_2, \\ldots, X_n)\\) est un n-uplet de variables aléatoires indépendantes qui suivent toutes la même loi (celle de \\(X\\)). Un estimateur de \\(\\theta\\) est une fonction \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) de notre échantillon, qui possède une loi de probabilité. Lorsque l’aléa est réalisé, \\(\\hat{\\theta}(\\omega) = f(x_1, x_2, \\ldots, x_n)\\) est une estimation de \\(\\theta\\). Le but de ce cours est de construire le meilleur estimateur possible de \\(\\theta\\)."
  },
  {
    "objectID": "M1SEP.html#estimateur-sans-biais",
    "href": "M1SEP.html#estimateur-sans-biais",
    "title": "DATA Camp M1",
    "section": "Estimateur sans biais",
    "text": "Estimateur sans biais\nPour que l’estimation soit bonne, il faut que \\(\\hat{\\theta}\\) soit proche de \\(\\theta\\). Comme \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) est une variable aléatoire, on ne peut imposer de condition qu’à sa valeur moyenne.\nOn définit ainsi le biais : \\[b_n(\\hat{\\theta}, \\theta) = \\mathbb{E}(\\hat{\\theta}_n) - \\theta\\]\nUn estimateur est dit sans biais si \\(b_n(\\hat{\\theta}, \\theta) = 0\\), c’est-à-dire : \\[\\mathbb{E}(\\hat{\\theta}_n) = \\theta\\]"
  },
  {
    "objectID": "M1SEP.html#estimateur-convergent",
    "href": "M1SEP.html#estimateur-convergent",
    "title": "DATA Camp M1",
    "section": "Estimateur convergent",
    "text": "Estimateur convergent\nUn estimateur est dit convergent s’il converge en probabilité vers le paramètre à estimer : \\[\\hat{\\theta}_n \\xrightarrow{P} \\theta\\]\nEn pratique, tout estimateur sans biais et dont la variance tend vers 0 est convergent."
  },
  {
    "objectID": "M1SEP.html#estimateur-optimal",
    "href": "M1SEP.html#estimateur-optimal",
    "title": "DATA Camp M1",
    "section": "Estimateur optimal",
    "text": "Estimateur optimal\n\nLa qualité d’un estimateur est mesurée à travers son erreur quadratique moyenne définie par : \\[EQM(\\hat{\\theta}_n) = (b_n(\\hat{\\theta}, \\theta))^2 + V(\\hat{\\theta}_n)\\] Comme nous cherchons tout le temps (presque) des estimateurs sans biais, il reste à comparer les variances.\nUn estimateur 𝜃̂1 est meilleur que 𝜃̂2 si : \\[V(\\hat{\\theta}_1) &lt; V(\\hat{\\theta}_2)\\]\n\nOn définit la quantité d’information apportée par l’estimateur par : \\[\nI(\\hat{\\theta}_n) = -\\left( \\mathbb{E} \\left( \\frac{\\partial L}{\\partial \\theta} \\right) \\right)^2\n\\] Où 𝐿(𝑥, 𝜃) = ∏ 𝑓(𝑥𝑖) (nous reviendrons sur sa définition)\nL’inégalité de Rao-Cramer postule que la variance d’un estimateur ne peut pas aller en delà d’un certain seuil : \\[V(\\hat{\\theta}_n) \\geq \\frac{1}{I(\\hat{\\theta}_n)}\\] Un estimateur est optimal (ou efficace) si sa variance vérifie le cas d’égalité."
  },
  {
    "objectID": "M1SEP.html#construction-dun-estimateur",
    "href": "M1SEP.html#construction-dun-estimateur",
    "title": "DATA Camp M1",
    "section": "Construction d’un estimateur",
    "text": "Construction d’un estimateur\n\nLa méthode du maximum de vraisemblance consiste à affecter \\(𝜃\\) la valeur qui maximise la probabilité d’observer \\((𝑥_1, 𝑥_2, … , 𝑥_𝑛)\\) lorsque l’aléa du vecteur \\((𝑋_1, 𝑋_2, … , 𝑋_𝑛)\\) tombe. Sans trop rentrer dans la théorie de la vraisemblance, nous allons présenter un algorithme en cinq étapes pour calculer cet estimateur (qui présente des propriétés assez séduisantes) :\n\nDans le cas continu : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} f(x_i)\\]\nDans le cas discret : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} P(X_i = x_i)\\] \nIl s’agit de calculer un maximum, ce qui revient à dériver. Il s’agit ici d’un produit de n facteurs, ce qui rend la dérivation assez coriace. La fonction logarithmique présente des propriétés assez sympas pour faciliter cette tâche.\n\n \\[\\frac{\\partial (\\ln(L))}{\\partial \\theta} = 0 \\Rightarrow \\theta = \\theta_0\\]\n\nEn s’assurant que : \\[\\frac{\\partial^2 (\\ln(L))}{\\partial \\theta^2} &lt; 0\\]\n\nComme le paramètre à estimer intervient dans la densité de probabilité, les moments théoriques sont souvent en fonction de ce paramètre. Ainsi, la méthode des moments consiste à égaliser les moments théoriques (espérance, variance) à leurs équivalents empiriques et à en dégager une estimation ponctuelle.\nEn pratique, il faut résoudre l’(les) équation(s) : \\[\\mathbb{E}(X) = \\overline{X} \\text{ et } \\text{Var}(X) = S_n^2\\] avec : \\[\\overline{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\hspace{2cm}\nS_n^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\overline{X})^2\\]\n\nLorsqu’il s’agit de prendre une mesure 𝜃 avec un appareil doté d’une imprécision \\(𝜀\\), alors le problème d’estimation peut s’écrire : \\(𝑋 = 𝜃 + 𝜀\\). La méthode des moindres-carrés ordinaires consiste à trouver le paramètre \\(𝜃\\) qui minimise la somme des carrées des erreurs : \\[𝜃_{𝑀𝐶𝑂} = \\arg\\min \\left( \\sum_{i=0}^n \\varepsilon_i^2 \\right) = \\arg\\min \\left( \\sum_{i=0}^n (X_i - \\theta)^2 \\right)\\]"
  },
  {
    "objectID": "M1SEP.html#intervalles-de-confiance",
    "href": "M1SEP.html#intervalles-de-confiance",
    "title": "DATA Camp M1",
    "section": "Intervalles de confiance",
    "text": "Intervalles de confiance\nUn intervalle de confiance [\\(A\\), \\(B\\)] de niveau \\(1 - \\alpha\\) est un intervalle aléatoire qui a la probabilité \\(1 - \\alpha\\) de contenir le paramètre à estimer \\(\\theta\\). Formellement, on écrit : \\(P (t_1 (\\theta) \\leq f(X_1, \\ldots, X_n) \\leq t_2 (\\theta)) = P(A \\leq \\theta \\leq B) = 1 - \\alpha\\)"
  },
  {
    "objectID": "M1SEP.html#test-dhypothèses",
    "href": "M1SEP.html#test-dhypothèses",
    "title": "DATA Camp M1",
    "section": "Test d’hypothèses",
    "text": "Test d’hypothèses\nDans le cadre d’un test d’hypothèse, nous cherchons à faire valoir une hypothèse en dépit d’une autre, qui lui est contradictoire.\nOn appellera la première (celle dont le rejet à tort sera le plus préjudiciable) « Hypothèse nulle » et la deuxième « Hypothèse alternative ».\n\n\n\n\n\nLes calculs qui se cachent derrière le choix de l’hypothèse à garder sont compliqués. Mais BONNE NOUVELLE, la machine fera tour à notre place. Il suffit juste de suivre correctement la méthode :"
  },
  {
    "objectID": "M1SEP.html#construction-dintervalles-de-confiance",
    "href": "M1SEP.html#construction-dintervalles-de-confiance",
    "title": "DATA Camp M1",
    "section": "Construction d’intervalles de confiance",
    "text": "Construction d’intervalles de confiance\nLes intervalles de confiance sont des outils essentiels en statistique pour estimer des paramètres inconnus tout en mesurant l’incertitude associée à cette estimation. Ci-dessous, vous trouverez un tableau présentant la construction des intervalles de confiance pour différents paramètres."
  },
  {
    "objectID": "M1SEP.html#définitions",
    "href": "M1SEP.html#définitions",
    "title": "DATA Camp M1",
    "section": "Définitions",
    "text": "Définitions\n\nCovariance : La covariance entre deux variables \\(X\\) et \\(Y\\) mesure la manière dont deux variables varient ensemble. Elle est donnée par deux formules :\n\n\nPour un échantillon de données : \\[\n\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n\\] où \\(x_i\\) et \\(y_i\\) sont les valeurs des échantillons, et \\(\\bar{x}\\) et \\(\\bar{y}\\) sont les moyennes des échantillons.\nPour des variables aléatoires : \\[\n\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n\\] où \\(\\mathbb{E}[X]\\) et \\(\\mathbb{E}[Y]\\) sont les espérances (moyennes théoriques) des variables aléatoires \\(X\\) et \\(Y\\).\n\n\nRégression linéaire:\n\nLa régression linéaire est une méthode statistique qui permet de modéliser la relation entre deux variables en ajustant une ligne droite à un ensemble de données. L’équation de la régression linéaire est : \\[\ny = a + bx\n\\] où \\(y\\) est la variable dépendante, \\(x\\) est la variable indépendante, \\(a\\) est l’ordonnée à l’origine (l’interception de la ligne avec l’axe des ordonnées), et \\(b\\) est la pente de la ligne (le taux de changement de \\(y\\) par rapport à \\(x\\))."
  },
  {
    "objectID": "M1SEP.html#la-dissertation-en-économie",
    "href": "M1SEP.html#la-dissertation-en-économie",
    "title": "DATA Camp M1",
    "section": "La dissertation en économie",
    "text": "La dissertation en économie\n“On tient tout d’abord à remercier l’enseignant chercheur (en Philosophie économique, Théories économiques de la justice, Redistribution des revenus, Economie sociale, Economie publique), monsieur Jean-Sébastien Gharbi pour cette rubrique d’aide à la dissertation.”\n\n\n\n\n\nOn pense souvent que la dissertation en économie est un exercice difficile et qui récompense mal le travail. C’est totalement faux. La dissertation est un exercice dans lequel il est facile d’obtenir la moyenne, et même (avec un peu d’entraînement) d’obtenir systématiquement de très bonnes notes. C’est un exercice relativement facile parce que c’est un exercice en très grande partie formel : tout est une question de méthode.\nFaire une dissertation, c’est montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances pour répondre à une question de manière argumentée (c’est-à-dire sous la forme d’un raisonnement). Autrement dit :\n\nUne dissertation n’est pas une question de cours.\n\nLa première chose à faire, c’est de différencier question de cours et dissertation (qui sont souvent confondues). Une question de cours demande simplement de réciter un cours. Si vous ne faites que réciter votre cours dans un exercice de dissertation, vous aurez une mauvaise note. Pourquoi ? Parce que l’exercice de dissertation suppose de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances (dans un temps limité) – pas seulement de réciter une leçon apprise plus ou moins par cœur. Comme la question de cours, la dissertation suppose donc que vous savez des choses sur le sujet, mais il est important de comprendre que la dissertation porte tout autant sur votre aptitude à organiser vos idées que sur vos connaissances.\n\nDans une dissertation, la réponse donnée n’est pas importante !\n\nUne dissertation consiste toujours à répondre à une question. Les étudiants pensent parfois qu’il y a une « bonne » réponse à la question posée – qu’il s’agirait de trouver. D’ailleurs, cela contribue à l’idée (fausse) que la dissertation est un exercice aléatoire : si vous ne trouvez pas la bonne réponse, vous avez perdu. Cela aussi est faux : il n’y a (en général) pas de « bonne » réponse à la question posée par la dissertation. L’exercice de dissertation vient de la philosophie. Pensez-vous sérieusement que l’on puisse demander à un étudiant (ou à un professeur, d’ailleurs) de régler de façon définitive un débat philosophique qui a donné lieu à des controverses pendant des siècles en trois, quatre ou même sept heures ? La réponse évidente est « non ».\n\nDans une dissertation, le plus important c’est l’argumentation !\n\nSi on ne s’intéresse pas à la réponse donnée. C’est tout simplement, parce que ce qui intéresse votre lecteur, c’est la manière dont vous répondez : votre aptitude à utiliser vos connaissances de manière argumentative pour défendre une conclusion. Sur le principe, il serait donc possible de défendre une conclusion choquante ou même offensante dans une dissertation, pour la bonne raison qu’on n’évalue pas la réponse que vous donnez, mais la manière dont vous amenez votre réponse. Votre réponse, à la limite, on ne s’y intéresse pas. Une fois cela dit, il est assez évident qu’il est beaucoup plus facile de défendre une position modérée et consensuelle, qu’une position offensante pour de nombreuses personnes. C’est la raison pour laquelle, il n’est pas du tout conseillé de chercher la provocation gratuite dans une dissertation.\nComment on fait une dissertation ?\n\n\n\n\n\n\nAnalyse du sujet\nL’analyse du sujet est la première étape de la dissertation et l’une des plus importantes. Une dissertation se présente sous la forme d’un sujet. Il faut isoler la ou les deux notions principales du sujet.\nIl y a quatre grands types de sujets : les sujets ne contenant qu’une seule notion (ex : « Les discriminations en France »), les couples de notions (ex : « Capitalisme et démocratie »), les citations (ex : « Le système de production capitaliste est une démocratie économique dans laquelle chaque sou donne un droit de vote. Les consommateurs constituent le peuple souverain », Ludwig von Mises) ou une question (ex : « La croissance économique s’oppose-t-elle à la préservation de l’environnement ? »).\nDans tous les cas, l’objectif est d’arriver à une question (donc les sujets les plus simples à traiter à ce stade, ce sont les questions : ils vous donnent immédiatement le problème à traiter). Mais la première chose à faire (même quand on a déjà la question), c’est de trouver le couple de notions impliquées dans le sujet. Souvent, c’est absolument évident, mais parfois il faut un peu chercher.\nIl faut éviter à tout prix de faire un exposé quand on attend de vous une dissertation. Un hors-sujet, c’est de ne pas traiter le bon sujet. Si vous répondez de manière factuelle à un sujet de dissertation, vous faites pire : vous faites un hors-exercice.\n\n\nRecherche des idées\nUne fois qu’on a identifié un couple de notions, il faut (au brouillon) essayer de faire la liste des éléments du cours qui relient les deux notions. Il est important de ne noter que les éléments qui relient les deux notions (pour ne pas risquer de se perdre dans des éléments qui concernent seulement une seule des deux notions). Sur chacune des notions que vous aurez à traiter en dissertation, on a écrit des livres entiers. Il est impossible de tout dire dessus dans une dissertation. On se limite donc à ce qui relie les deux notions de notre sujet. Évidemment, si un élément pertinent vous vient en tête et qu’il ne se trouve pas dans votre cours, n’hésitez pas à le noter. Si cet élément peut être utilisé dans votre raisonnement, même comme exemple, ce sera un plus indiscutable.\nDans un premier temps, on note tout ce qui se présente à l’esprit. Ce n’est que dans un deuxième temps, quand on a un certain nombre d’éléments que l’on se pose la question : « Est-ce qu’il y a une manière qui saute aux yeux de relier tous ces éléments en répondant à la question (si elle a été posée de manière directe) ou pour répondre à une question comprenant le couple de notions (si la question n’a pas été formulée dans le sujet) ? ». Si la réponse est positive, on a trouvé la question qui structurera notre devoir. Si ce n’est pas le cas, il faut essayer de trouver une question qui relie le plus grand nombre des éléments que l’on a noté sur son brouillon – et donc laisser de côté les éléments qui ne servent pas. Il arrive souvent qu’une partie des éléments que l’on note sur son brouillon ne soit pas utilisée dans le devoir. Bref, si notre sujet est un couple de notions ou une citation, il faut que l’on arrive à une question. Évidemment, quand notre sujet est déjà une question, on n’a pas autant de marge de manœuvre, mais en vérité, si on vous pose une question précise, c’est que vous avez les éléments pour y répondre dans le cours (donc la différence n’est pas très importante).\n\n\nMise en évidence d’un problème\nPuisqu’elle ne doit pas être une question de fait, la question qui relie le plus d’éléments possibles parmi ceux qui associent les deux notions dans votre cours doit être une question conceptuelle. Pour le dire autrement, cette question doit être un problème (on parle souvent de « problématique » pour désigner ce problème dans le cadre d’une dissertation). Qu’est-ce qu’un problème ? C’est une question qui met en tension deux concepts et qui analyse les différents aspects de leur relation (conceptuelle).\nSouvent les étudiants ont peur de ne pas trouver le « bon » problème. Pourtant, si on suit la méthode de dissertation, il n’y a pas de risque de se tromper. En effet, on ne doit pas choisir un problème d’abord (sans savoir si on a de quoi le traiter) et le traiter ensuite. Vous aurez noté qu’on procède exactement dans le sens inverse : on voit à quelle question on peut répondre avec les éléments qu’on a sur son brouillon et on pose précisément la question à laquelle on sait qu’on peut répondre.\n\n\nConstruction du plan\nPour la même raison qu’au-dessus, la construction du plan ne doit pas être très difficile : il s’agit de rassembler les différents éléments qui permettent de répondre à la question (au problème que l’on va poser) de façon à y apporter une réponse.\nOn va apporter la réponse que les éléments disponibles nous permettent d’atteindre. Il y a une seule contrainte : votre plan doit être suffisamment détaillé. Comme l’objectif de la dissertation, c’est de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances. Si vous ne faites que deux parties sans sous-parties à l’intérieur (il n’y aurait donc qu’une seule articulation logique), on trouvera que vous n’avez pas assez structuré votre devoir. Le découpage minimal, c’est d’avoir quatre éléments (en général, on fait deux grandes parties avec deux sous-parties chacune, donc on a trois articulations).\nVos parties et vos sous-parties doivent correspondre à des étapes de votre raisonnement (on dit souvent qu’il faut une idée par sous-partie), donc votre plan doit donner la structure du raisonnement grâce auquel vous allez répondre à la question posée. Le plan (qui est annoncé à la fin de l’introduction et qui doit être apparent dans le devoir, nous reviendrons sur ce point un peu plus loin) doit permettre de comprendre la structure de votre devoir d’un coup d’œil – simplement en lisant les titres.\nUn élément qui permet de savoir si votre plan est bon, c’est de se demander si à la fin de la première partie, on est arrivé à un état de la réflexion différent de celui de la fin de l’introduction.\nQu’est-ce que la première partie a permis de comprendre ? Et est-ce que la seconde partie apporte quelque chose d’autre ? Si chaque partie représente une étape dans un raisonnement et que votre devoir complet est donc un raisonnement, votre plan est forcément bon : vu que c’est précisément ce qu’on attend de vous.\nIl ne faut jamais faire deux sous-parties dans une partie sous la forme d’une seule phrase coupée par des points de suspension (ex : « A) L’organisation scientifique du travail a permis la croissance des trente glorieuses… », « B) mais, elle a aussi eu des conséquences négatives, notamment sur le plan social »). En effet, cela revient à pointer du doigt que vous opérez une coupure arbitraire (donc que vous n’articulez pas de manière assez nette les différentes parties de votre devoir). Sur le principe, les deux sous-parties sont reliées par les points de suspension et donc ne forment qu’une partie sans coupure. Préférez toujours les titres qui se succèdent sans être grammaticalement liés les uns aux autres. Dans l’exemple ci-dessus, il suffit de faire deux phrases pour découper les deux idées. Si on ne peut pas couper grammaticalement les deux titres, c’est la preuve que l’articulation pose problème.\nDans l’idéal, un plan est équilibré : chaque partie comprend le même nombre de sous-parties que l’autre et elles font à peu près la même longueur. Et si vous faites plus de sous-parties dans une partie que dans l’autre, il faut que les sous-parties soient un peu plus longues dans la partie qui contient moins de sous-parties. Remarquez que si vous faites un plan avec deux parties, deux sous-parties, ce dernier problème ne se pose pas.\nUn point important et souvent totalement négligé par les étudiants : même quand c’est tentant, on ne fait jamais de plan centré sur les auteurs. Un plan par auteurs conduit très souvent à suivre l’ordre chronologique et à présenter les positions des auteurs sans les confronter réellement les unes aux autres . Ce qui doit structurer le plan, ce sont les concepts (c’est-à-dire les notions qui nous avaient permis de construire le problème à résoudre).\nEn réalité, il n’est pas rare qu’on suive plus ou moins l’ordre chronologie, mais il est essentiel de se focaliser sur les concepts, et pas sur les auteurs. Pourquoi ? Parce que l’enchaînement ou l’opposition de concepts constitue un raisonnement (ce que vous devez faire !), alors que l’enchaînement ou l’opposition d’auteurs constitue un exposé (ce que vous ne devez pas faire !). En réalité, c’est assez facile à faire il suffit de s’interdire de mentionner le nom des auteurs dans les titres de partie ou de sous-partie.\nVu que l’objectif du plan, c’est de répondre à une question qui met les deux notions du sujet en relation, les parties (ou les sous-parties) qui se focalisent sur une seule des deux notions sont à éviter à tout prix : elles sont simplement hors-sujet. Sur un sujet comme « capitalisme et démocratie », le plan « première partie : capitalisme », « deuxième partie : démocratie » est parmi les pires possibles.\nJusqu’à présent, nous n’avons encore rien écrit sur la copie elle-même. Nous n’avons travaillé que sur le brouillon. Nous avons deux notions clés, un problème et un plan. Ce sont les éléments fondamentaux du devoir. Il faut à présent passer à la rédaction. Nous allons nous intéresser d’abord à l’introduction.\n\n\nLa rédaction\n(Introduction, Conclusion, Développement)\nL’introduction est la partie la plus importante de la dissertation. Elle permet de savoir pourquoi le problème se pose, comment il se pose et comment il va être résolu. A quoi sert l’introduction ?\nLe rôle de l’introduction, sa raison d’être, c’est de construire et d’énoncer le problème (la problématique) auquel le reste du devoir va répondre. Il ne suffit donc pas de poser la question (pour cela deux lignes suffiraient) et de commencer le développement. L’introduction, comme son nom le dit très bien, va introduire le problème, c’est-à-dire qu’elle va nous y amener, rapidement, certes, mais en plusieurs étapes très codifiées.\nUne introduction de dissertation comprend obligatoirement (au minimum) cinq éléments : une accroche, une définition des termes du sujets, la construction du problème, l’énoncé du problème et l’annonce du plan. Comme une introduction de dissertation fait entre 20 lignes et une page et demie (grand maximum), il faut être efficace.\n\nL’accroche\n\nUne introduction de dissertation suit des règles assez rigides. Elle commence toujours par une accroche.\nUne « accroche », c’est une phrase ou deux qui vont contenir la ou les deux notion(s) du sujet. Son rôle est d’amener par étapes le lecteur vers la question que vous allez poser. Elle sert donc d’introduction à l’introduction. Une accroche peut être une citation (il y en a toujours dans un cours) ou un fait récent (le chômage a-t-il baissé récemment ? Un candidat à l’élection présidentielle a-t-il dit qu’il fallait juger sa politique en fonction de son impact sur le niveau de chômage ?). Si on n’a pas de citation ou de fait relevant de l’actualité, on peut amener le sujet de façon plus habituelle.\nIl est important d’éviter un certain nombre de formules toutes faites et souvent utilisées comme « De tous temps… », « De tous temps, les hommes… » ou encore les affirmations très générales (et que vous ne justifierez pas) comme : « Le chômage est un phénomène économique important, c’est pourquoi il faut l’étudier ». Le défaut de tous ces débuts d’accroche, c’est qu’ils peuvent servir pour n’importe quel sujet et que cela se voit.\nOn met une accroche parce que cela permet de mentionner les termes du sujet sans commencer directement par une définition – ce qui constitue l’étape suivante.\n\nDéfinition des termes du sujet\n\nL’accroche a introduit les notions, mais sans les définir – comme si tout le monde savait précisément de quoi il s’agit (ce qui n’est pas si surprenant, on ne passe pas son temps à définir tous les mots qu’on utilise). Mais, pour utiliser les deux notions du sujet de façon un peu plus précise, il faut les définir. Les définitions que l’on va donner dans une introduction n’ont pas pour objectif de définir les notions de manière exhaustive ou dans l’absolu. Elles doivent permettre de comprendre le lien (ou l’opposition) entre les deux notions et orienter l’introduction de façon à ce que l’on puisse construire le problème – avant de l’énoncer (autrement dit, elles doivent ouvrir la voie aux deux étapes suivantes de l’introduction).\nDu coup, les définitions que l’on va donner vont dépendre du problème que l’on souhaite atteindre.\n\nConstruction du problème\n\nComme on sait à quelle question on doit arriver (que cette question nous ait été donnée par le sujet ou que ce soit la question à laquelle on est le mieux armé pour apporter une réponse), il ne va pas être difficile de passer des définitions au problème. Cela suppose juste de montrer qu’avec les définitions que l’on vient de donner, il y a une question se pose avec force.\nEncore une fois, cela peut sembler très artificiel (et ça l’est). Toutefois, l’intérêt de cet aspect artificiel, c’est qu’il nous garantit que l’on ne va pas se perdre en chemin. Quand on fait une dissertation, on ne cherche pas son chemin : on sait où on va et on ne fait qu’expliquer pourquoi on y va. Le sujet que l’on construit ne tombe pas du ciel, il vient de notre cours. Les définitions ne tombent pas du ciel, elles donnent les éléments qui vont nous permettre de poser la question à laquelle on sait déjà comment on va répondre. Bref, l’étape de construction du problème est importante parce qu’elle montre que vous avez des aptitudes pour vous faire comprendre à l’écrit (et il ne faut surtout pas la négliger), mais elle n’est pas une étape difficile ou magique.\nVous pourriez être surpris que l’on construise le sujet, alors qu’il nous est parfois donné sous forme de question (dans les autres cas, on comprend mieux pourquoi il est nécessaire de construire le problème). En fait, c’est une manière de montrer que vous êtes capable de vous approprier le sujet. Vous ne traitez pas le sujet parce qu’on vous l’a donné (même si vous c’est une des raisons pour lesquelles vous faites une dissertation), mais parce que vous comprenez pourquoi la question se pose. Et comment mieux montrer qu’on comprend un problème qu’en montrant en quoi il est problématique ? Autrement dit, même quand votre sujet a la forme d’une question, vous devez passer par l’étape de construction du sujet dans l’introduction.\n\nEnoncé du problème\n\nL’énoncé du problème doit prendre la forme d’une question. Il est le point final de l’étape juste précédente. Une fois qu’on a les éléments qui permettent de comprendre que le problème se pose, il faut explicitement exprimer le problème lui-même. On exprime toujours le problème sous la forme d’une question (parce que c’est une manière de montrer qu’il appelle une réponse) et d’une question unique. Poser deux, trois ou quatre questions ce serait soit redire plusieurs fois la même chose (et si votre première question est claire, c’est inutile), soit poser (volontairement ou pas) plusieurs questions différentes. Or, vous ne pourrez pas répondre convenablement et dans les règles de la dissertation à plusieurs questions en un seul devoir. Vous devrez donc choisir entre ne pas traiter certaines des questions que vous avez explicitement posées (et dans ce cas pourquoi les poser explicitement) ou essayer de les traiter toutes (ce qui vous conduira à un devoir dont la ligne directrice sera au mieux difficile à suivre, au pire inexistante). Si on se rappelle du côté formel et rhétorique d’une dissertation, on comprend qu’il ne faut poser qu’une seule question : celle à laquelle vous apportez une réponse.\nLorsque le sujet est une question, faut-il répéter mot pour mot le sujet comme énoncé du problème ? Il y a deux écoles : la première dit qu’il faut reformuler la question pour montrer que vous la comprenez. Ainsi un sujet comme « Les dépenses publiques permettent-elles de réduire le chômage ? », on pourrait proposer une problématique comme « les dépenses publiques sont-elles efficaces à court et à long terme pour lutter contre le chômage ? ».\nSi vous faites correctement votre travail de définition des termes et de construction du sujet (dans les deux étapes précédentes), je pense qu’aucun correcteur ne vous reprochera de reprendre le sujet mot pour mot dans votre énoncé du problème. Ce qui pose problème pour les partisans de la première façon de faire, c’est quand on peut se demander si l’étudiant comprend que la question qu’il pose est un problème conceptuel, c’est-à-dire qui vient d’une tension entre deux notions. Dans une introduction qui remplit correctement son rôle de construction du problème, le fait de répéter le sujet mot pour mot n’est pas un souci.\n\nAnnonce du plan\n\nUne introduction doit toujours se terminer par une annonce du plan (ce n’est pas une option, c’est une obligation). L’annonce de plan dit à votre lecteur comment vous allez répondre au problème que vous venez de poser. Dans une dissertation, on ne joue pas sur le suspens. On ne cherche pas à surprendre son correcteur. Il faut donc annoncer le plan de manière à ce qu’il comprenne que vous allez répondre au problème posé par un raisonnement et qu’il comprenne aussi quels vont être les principales étapes de votre raisonnement (c’est-à-dire de votre devoir).\nVous allez donc annoncer vos (deux ou trois) grandes parties. Il est conseillé fortement d’utiliser les formules (un peu lourdes en termes de style, mais très claires) « dans une première partie, nous montrerons que… », puis « dans une deuxième partie, nous verrons que … ». Quand vous ne le faites pas, il arrive trop souvent que votre lecteur ne sache pas si vous allez faire formellement deux ou trois parties – pour peu que vous utilisiez des mots comme « et », « puis » ou « ensuite », qui peuvent aussi bien marquer des étapes à l’intérieur d’une grande partie que le passage d’une partie à une autre.\nLa conclusion\nVous pourriez être surpris de voir la conclusion arriver aussi tôt dans le devoir. La raison, c’est qu’il est inconcevable de ne pas répondre à la question posée en introduction – si vous ne répondez pas le devoir n’aura, littéralement, servi à rien. Or, il est évident qu’en partiel, on est souvent pris par le temps. On rédige donc la conclusion juste après avoir rédigé l’introduction au brouillon (on la rédige aussi au brouillon, d’ailleurs). Comme ça si on est pris par le temps, on pourra recopier la conclusion déjà prête avant de rendre le devoir. S’il faut couper quelque chose en raison du temps limité de l’épreuve, il vaut mieux couper un bout du développement que rendre une dissertation sans conclusion.\nLa première phrase de votre conclusion doit apporter la réponse à la question que vous avez posée en introduction. Elle doit le faire de façon absolument claire et donc il est conseillé de reprendre exactement la question en la tournant en une phrase affirmative ou en une phrase négative selon votre réponse. Le rôle de la conclusion, c’est de répondre à la question. Il ne faut pas qu’on relise la conclusion en se demandant quelle était la réponse – et même en se demandant si une réponse a été donnée. Cela ne vous empêche pas de donner une réponse nuancée, mais il faut une réponse claire.\nUne conclusion de dissertation ne résume pas le devoir (on vient de le lire, c’est tout à fait inutile). Une conclusion n’introduit jamais un élément qui n’a pas été abordé dans le devoir, mais qui aurait pu y être discuté. Si jamais votre correcteur n’a pas vu que vous avez oublié de parler de quelque chose d’important, vous n’allez tout de même pas lui dire qu’il manque quelque chose dans votre devoir (chacun son boulot). La dissertation est un exercice de rhétorique, votre objectif, c’est de convaincre votre lecteur : ce n’est pas à vous de dire qu’il manque quelque chose, même si vous le savez.\nOn conseille parfois de finir sa dissertation sur une ouverture. Une ouverture est un nouveau problème qui se pose une fois que vous avez répondu au problème de votre devoir. Cela revient à suggérer une autre dissertation possible une fois qu’on considère votre réponse comme acceptée. Trop souvent, les étudiants finissent leurs devoirs de manière particulièrement maladroite parce qu’ils ne comprennent pas ce qu’est une ouverture. Mon conseil est d’éviter de faire une ouverture, au moins au début : ce n’est pas une obligation et cela peut donner une très mauvaise impression finale.\nLa rédaction du devoir\nUne fois tout cela fait, on prend sa copie (totalement vierge à ce moment) et on commence à écrire dessus : on recopie l’introduction, on rédige le développement directement sur la copie (on ne rédige jamais son développement sur le brouillon, cela prend beaucoup trop de temps à recopier). Le développement du devoir doit contenir des titres apparents pour les parties et les sous-parties. Cela signifie que le titre de votre grande partie est marqué dans votre copie (précédé d’un « I) ») et qu’il est isolé du texte et souligné. Bref, on doit pouvoir voir apparaître d’un coup d’œil votre plan en survolant votre copie du regard.\nComme dit juste au-dessus, si on manque de temps, on coupe une partie du développement et on recopie la conclusion qui se trouve sur le brouillon. Attention : si vous ne rédigez pas tout le développement, mettez tout de même le plan apparent pour les parties et sous-parties non développées. C’est précisément parce qu’on a une idée de ce que vous auriez écrit qu’il est possible (en cas de gros manque de temps) de ne pas rédiger tout le développement. Si vous ne détaillez pas votre plan, c’est la trame de votre raisonnement qui manque et c’est beaucoup plus ennuyeux. Si vous ne pouvez pas rédiger tout le développement, je vous conseille de mettre des éléments que vous auriez utilisé sous forme de liste de tirets (en plus des titres apparents qui sont obligatoires)."
  },
  {
    "objectID": "Mathématiques.html#fondements-de-probabilité",
    "href": "Mathématiques.html#fondements-de-probabilité",
    "title": "Prérequis des mathématiques",
    "section": "Fondements de Probabilité ",
    "text": "Fondements de Probabilité \n\nQuelques définitions\n\nOn appelle épreuve E toute expérience probabiliste.\nOn appelle univers de E l’ensemble, généralement noté Ω, de tous les résultats possibles de l’épreuve E (appelés ‘’événements élémentaires’’)\nLancer une paire de dés équilibrés et en retenir la somme est une épreuve.\n\n\\[\n𝛀 = \\bigl\\{ 2,3,4,5,6,7,8,9,10,11,12\\bigl\\}\n\\]\n\n\nEvénements\nUn événement est un sous-ensemble de Ω.\n\nL’intersection de A et B, notée \\(A\\ ∩ B\\), est un événement. Il est réalisé uniquement si A et B se produisent.\n\n\n\nLa réunion de A et B, notée A B, est un événement. Il est réalisé si A ou B se produit.\nDeux événements remarquables sont à retenir:\nL’événement certain \\(𝛀_i\\).\nL’événement impossible \\(∅_i\\).\n\nTous les éléments qui n’appartiennent pas à \\(A\\) appartiennent à un événement que l’on appelle le complémentaire de \\(A\\). On le note \\(A^c\\ ou\\ \\overline{A}\\) .\nOn dit que deux événements A et B sont incompatibles s’ils ne peuvent pas être réalisés enmême temps.\nSi A, B et C sont des événements de Ω, les propriétés suivantes sont toujours vérifiées:\n\\(A\\ ∪ \\ \\overline{A}\\ = 𝛀\\)\n\\(A\\ ∩ \\ \\overline{A}\\ = ∅\\)\n\\(\\overline{A∩B}\\ = \\bar{A}\\ ∪\\ \\bar{B}\\ et\\ \\overline {A∪B}\\ = \\bar{A}\\ ∩\\ \\bar{B}\\ (lois\\ de\\ Morgan)\\)\n\\(A\\ ∩\\ (B\\ ∪\\ C)\\ = (A\\ ∩ B)\\ ∪\\ (A\\ ∩\\ C)\\)\n\\(A\\ ∪\\ (B\\ ∩\\ C)\\ = (A\\ ∪ B)\\ ∩\\ (A\\ ∪ \\ C)\\)\n\n\nPartitions\nLa famille d’événements forme une partition de 𝛀 si :\n\\[\n∪_i\\ A_i\\ =\\ \\Omega\\ et\\ A_i\\ \\cap\\ A_j\\ = \\emptyset;\\ \\forall i\\ \\ne\\ j;\\ i\\ \\in I\n\\]\nUne partition remarquable est la famille qui contient l’événement A et son complémentaire.\n\n\nTribus et boréliens\nComment pouvons nous qualifier l’ensemble des événements ?\nUne tribu est une famille \\(T\\) de parties de l’ensemble \\(\\Omega\\) qui vérifie les propriétés suivantes:\n\n\\(\\Omega\\ \\in T\\)\nSi \\((A_n)_n\\) est une suite dénombrable d’éléments de \\(T_i\\) alors \\(\\cup\\ A_n\\ \\in\\ T\\)\n\nSi \\(A\\) est un élément de \\(T_i\\) alors son complémentaire l’est aussi\nDe plus, si \\(T\\) est une tribu, alors:\n\n\\(\\emptyset\\ \\in\\ T\\)\nSi \\((A_n)_n\\) est une suite d’éléments de \\(T_i\\) alors \\(\\cap\\ A_n\\ \\in\\ T\\).\n\nExemple de Tribus:\nCommençons par le cas discret.\nOn considère l’expérience “Lancer une pièce de monnaie équilibrée”.\nOn notera: P “Pile apparait” et F “Face apparait”.\nDans ce cas, l’univers est l’ensemble {P,F} et \\(T\\) = { \\(\\Omega,\\ \\emptyset,\\) P, F } est une tribu.\nEn général, l’ensemble des parties est une tribu (classique).\nPour le cas continu, les intervalles du type \\([a, +\\infty[\\ ;\\ ]-\\infty,a]\\) sont des tribus.\nNous les appelons des Boréliens.\nSoient A et B deux événements. Les propriétés suivantes sont toujours vraies:\n\n\n\n\n\n\n\\(P(\\bar{A})\\ =\\ 1\\ -\\ P(A)\\)\n\\(P(B)\\ =\\ P(A\\ \\cap\\ B)\\ +\\ P(\\bar{A}\\ \\cap\\ B)\\)\n\\(Si\\ A\\ \\subset\\ B\\ alors\\ P(A)\\ \\leq\\ P(B)\\)\n\\(0\\ \\leq\\ P(A)\\ \\leq\\ 1\\)\n\\(P(A\\ \\cup\\ B)\\  =\\ P(A)\\ +\\ P(B)\\ -\\ P(A\\ \\cap\\ B)\\)\n\n\n\n\n\n\nDe plus, Considérant une suite \\((A_n)_n\\) d’événements. On a alors :\n\\[\nP(\\bigcup\\limits_{k=1}^{+\\infty} A_{k})\\ =  \\lim_{x\\to+\\infty} (P(\\bigcup\\limits_{k=1}^{n} A_{k}))\n\\]\n\\[\nP(\\bigcap\\limits_{k=1}^{+\\infty} A_{k})\\ =  \\lim_{x\\to+\\infty} (P(\\bigcap\\limits_{k=1}^{n} A_{k}))\n\\]\n\\[\nP \\Bigl( \\bigcup\\limits_{k=1}^{+\\infty} A_{k}\n\\Bigl)\n\\ \\leq\\ \\sum_{k=1}^{+\\infty}\\ P(A_k)\n\\]\nEt si :\n\n\n\n\n\n\\[\n\\bigcup\\limits_{k=1}^{n} A_{k}\\ =\\ \\Omega\n\\]\nAlors :\n\\[\nP(B)\\ =\\ \\sum_{k=1}^{n}\\ P(B\\ \\cap\\ A_k)\n\\]\n\n\nMesure\nSoit E un ensemble muni d’une tirbu \\(T\\) . On appelle mesure toute application m : \\(T\\) \\(\\rightarrow\\) \\(R^+\\) telle que:\n\nm(\\(\\emptyset\\)) = 0.\nSi \\((A_n)_n\\) est une suite d’éléments de \\(T\\) deux à deux disjoints alors:\n\n\\[\nm(\\cup_n\\ A_n)\\ =\\ \\Sigma_n\\ m(A_n)\n\\]\n\n\nProbabilité\nSoit E un ensemble muni d’une tribu \\(T\\) On appelle probabilité toute m : \\(T\\ \\rightarrow\\ R^+\\) telle que:\n\nP(\\(\\emptyset\\)) = 0\nSi \\((A_n)_n\\) est une suite d’éléments de \\(T\\) deux à deux disjoints alors:\n\\[\nP(\\cup_n\\ A_n)\\ =\\ \\Sigma_n\\ P(A_n)\n\\]\n\n\n\nProbabilités conditionnelles\nEn théorie des probabilités, nous nous intéressons souvent au comportement d’un aléa, sachant qu’un autre événement est déjà passé.\nC’est ce que nous appelons Les Probabilités Conditionnelles.\nConsidérant deux événements de proba non nulles A et B, la probabilité conditionnelle de A sachant que B est réalisé (couramment dit A sachant B) est :\n\\[\nP(A\\setminus B)\\ =\\\n\\frac{P(A\\ \\cap\\ B)}{P(B)}\n\\]\nPar commutativité de l’intersection nous avons : \\(P(A\\ \\cap\\ B)\\ =\\ P(B\\ \\cap\\ A)\\)\nEt donc en utilisant la formule ci-dessus :\n\\[\nP(B\\setminus A)P(A)\\ =\\ P(A\\setminus B)P(B)\n\\]\nD’où alors :\n\\[\nP(B\\setminus A)\\ =\\\n\\frac{P(A\\setminus B)P(B)}{P(A)}\n\\]\nC’est ce que nous appelons : La formule de BAYES\n\n\nIndépendance\nDeux événements A et B sont dits indépendants si et seulement si :\n\\[\nP(A\\ \\cap\\ B)\\ =\\ P(A)P(B)\n\\]\nEn termes courants, deux événements sont indépendants si le résultat de l’un n’influence aucunement l’aboutissement de l’autre.\nSous condition d’indépendance de A et B, la notion de la probabilité conditionnelle tombe à l’eau, car les événements évoluent l’un sans se soucier de l’autre.\nCeci se traduit par :\n\\[\nP(A\\setminus B)\\ =\\ P(A)\\\\P(B\\setminus A)\\ =\\ P(B)\n\\]\nNotons que si A est indépendant de B, il le sera par rapport à son coplémentaire également et vice versa.\nEn général, pour une suite \\((A_n)_n\\) d’événements indépendants, on a :\n\\[\nP(\\bigcap_{i=1}^{n}A_i)\\ =\\ \\prod_{i=1}^{n} P(A_i)\\ =\\ P(A_1)\\ ...\\ P(A_n)\n\\]\nCette formule est largement utilisée en statistique.\nRemarque importante :\nIl ne faut pas confondre l’indépendance et l’incompatibilité des événements.\n\n\nVariable aléatoire\nUne variable aléatoire est un nombre qui dépend du résultat d’une expérience aléatoire. Chaque exécution de l’expérience génère une réalisation de la variable aléatoire.\nMathématiquement, on définit une variable aléatoire X comme une fonction X : \\(T\\ \\rightarrow\\ R\\) qui associe à chaque événement S, un réel X(S).\nPar exemple, dans une queue pour la caisse d’un magasin, le nombre de clients est une variable aléatoire. La durée de traitement de chaque requte aussi.\nRemarquons que la première est un nombre entier. On dit qu’elle est à support discret. Alors que la deuxième est une durée (un nombre réel). On dit qu’elle est à support continu.\n\n\nQu’est ce qui caractérise une variable aléatoire ?\n\nFonction de répartition\nUne VA traduit le résultat d’une expérience aléatoire en nombre réel. La fontion de répartition transporte le calcul des probabilités concernant les réalisations de la VA.\nC’est la fonction définie par :\n\\[\nF_x(x)\\ =\\ P(X\\ \\leq\\ x)\n\\]\nPropriétés :\n\\[\n\\forall x;\\ 0\\leq F_x(x)\\leq 1\n\\]\n\\(F_x\\) est une fonction croissante.\n\\[\n\\lim_{x\\to-\\infty} F_x(x)\\ =\\ 0\\\\\\lim_{x\\to\\infty} F_x(x)\\ =\\ 1\n\\]\n\n\n\n\n\nCas discret Cas continu\n\n\nProbabilité ponctuelle / Densité\nCas discret : Probabilité ponctuelle\nLa probabilité ponctuelle est la fonction qui décrit les sauts de la fonction de répartition :\n\\[\nP(X=K)\\ =\\ P(X\\leq K)\\ -\\ P(X\\leq K-1)\\ =\\ P_K\n\\]\n\n\n\n\n\nCas continu : densité de probabilité\nLa densité est la fonction qui décrit les variations de la fonction de répartition :\n\\[\nf_x(x)\\ =\\ \\frac{\\delta F_x}{\\delta x}(x)\\\\\\int f_x = 1\n\\]\n\n\n\nMoments\nEspérance\nL’éspérance d’une variable aléatoire est sa valeur attendue. C’est une mesure de localisation de la distribution.\nDans le cas discret :\n\\[\nE(X)= \\sum_{k\\in X(\\Omega)} k.P(X=k)\n\\]\nAlors que dans le cas continu :\n\\[\nE(X) = \\int_{x\\in X(\\Omega)} x.f_x(x).dx\n\\]\nThérorème de Transfert :\n\\[\nE(\\phi(X)) = \\sum_{k\\in X(\\Omega)} \\phi(k).P(X=k)\\\\ E(\\phi(X)) = \\int_{x\\in X(\\Omega)} \\phi(x).f_x(x).dx\n\\]\nVariance\nLa variance d’une variable aléatoire décrit la dispersion de la variable aléatoire autour de sa valeur moyenne (son espérance). Elle est définie par :\n\\[\nV(X)=E(X^2)\\ -\\ (E(X))^2\\ =\\  E((x\\ -\\ E(X)^2)\n\\]\nSa racine carrée est appelée écart-type et notée généralement :\n\\[\n\\sigma(X)= \\sqrt{V(X)}\n\\]\nCentrage et réduction\nLe centrage consiste à localiser la distribution autour de l’origine et la réduction consiste à normaliser la dispersion. La technique est simple :\n\\[\nY= \\frac{X\\ -\\ E(X)}{\\sigma (X)}\n\\]\nMoments d’ordre r :\nLe moment d’ordre r est défini par :\n\\[\n\\mu_r = E(X^r)\n\\]\nLe moment centré d’ordre r est défini ainsi :\n\\[\n\\tilde{\\mu_r}= E((X\\ -\\ E(X))^r)\n\\]\n\n\nCouples aléatoires\nLa fonction \\(F_{x,y}(x,y) = P(X\\leq x\\ \\cap\\ Y\\leq y)\\) est dite distribution conjointe de X et de Y.\nDans le cas continu, la fonction définie par :\n\\[\nf_{x,y}(x,y) = \\frac{\\delta^2}{\\delta_x \\delta_y} F_{x,y}(x,y)\n\\]\nEst une densité conjointe du couple (X,Y). On a donc :\n\\[\nF_{x,y}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f_{x,y}(t,u)dtdu\n\\]\nDans le cas discret, on définit la fonction de fréquences conjointes :\n\\[\nP(X=x_i,Y=y_j) = p_{ij}\n\\]\nEt on a donc :\n\\[\nF_{x,y}= \\sum_{i:x_i\\leq x}\\sum_{j:y_j\\leq y} p_{ij}\n\\]\nLoi marjinale\nOn définit la loi marginale de X:\n\\[\nf_x(x) = \\int_{-\\infty}^{+\\infty} f_{x,y}(x,y)dy\n\\]\nDans le cas continu, ou encore :\n\\[\nf_x(x_i) = \\sum_j p_{ij}\n\\]\nDans le cas discret :\n(De meme on peut définir la densité marginale de Y)\nSi X et Y sont indépendants, alors :\n\\[\nf_{x,y}(x,y) = f_x(x)f_y(y)\n\\]\nCovariance\nLa covariance mesure l’intensité de la relation linéaire entre deux variables aléatoires X et Y.\n\\[\nCov(X,Y) = E(XY)\\ -\\ E(X)E(Y)\n\\]\nSi X et Y sont indépendants, alors :\n\\[\nCov(X,Y) = 0\n\\]\nAttention : La réciproque n’est pas vraie.\n\n\nÀ mémoriser\nSoient U, V, X et Y des variables aléatoires et a, b, c et d des constantes réelles.\nEspérance\n\\[\nE(aX + bY)\\ =\\ aE(X) + bE(Y)\\\\\nE(a) = a\n\\]\nVariance\n\\[\nV(aX) = a^2 V(X)\n\\]\n\\[\nV(A)=0\n\\]\n\\[\nV(X+Y) = V(X)+V(Y)-2Cov(X,Y)\n\\]\n\\[\nV(X-Y)=V(X)+V(Y)-2Cov(X,Y)\n\\]\nCovariance\n\\[\nCov(X,Y)=Cov(Y,X)\n\\]\n\\[\nCov(aX+b,cY+d)= ac.Cov(X,Y)\n\\]\n\\[\nCov(aX+bY,U)=aCov(X,U)+bCov(Y,U)\n\\]\n\\[\nCov(X,cU+dV)=cCov(X,U)+dCov(X,V)\n\\]\n\\[\nCov(aX+bY,cU+dV)=ac.Cov(X,U)+adCov(X,U)+bcCov(Y,U)+bdCov(Y,V)\n\\]\n\n\nVecteurs aléatoires\nUn vecteur aléatoire est un n-uplet formé de variables aléatoires. On note \\((X_1,X_2,…,X_n)^t\\)\nL’espérance est toujours linéaire. Pour une suite \\((a_i)_{i\\in \\left\\{1,…,n\\right\\}}\\) de réels, on a :\n\\[E(a_1X_1+a_2X_2+...+a_nX_n)= a_1E(X_1)+a_2E(X_2)+...+a_nE(X_n)\\]Pour les variables indépendantes, on a :\n\\[V(X_1 +X_2\n+...+ X_n) = V(X_1)+ ...+V(X_n)\n\\]\n\n\nLois usuelles\nLois discètes\n\n\n\n\n\nLois absolument continues\n\n\n\n\n\nThéorème de Fisher :\nSoient \\(\\sigma &gt; 0,\\ m\\in \\mathbb{R}\\ et\\ X_1,...,X_n\\) des variables aléatoires indépedantes et de même loi \\(N(m,\\sigma^2)\\). Alors, si \\(X=(X_1, …, X_n)\\) :\n\n\\(\\bar{X_n}\\ et\\ S_n(X)\\) sont indépedantes;\n\\((n-1)S_n^2\\  /\\  \\sigma^2 \\thicksim \\chi^2_{n-1}\\);\n\\(\\sqrt{n}(\\bar{X}_n - m)\\ /\\ S_n(X)\\thicksim \\tau_{n-1}\\);\n\nThéorème de Cochran :\nSoient \\(\\sigma &gt; 0, X \\thicksim N_n(0,\\sigma^2)\\) et \\(V_1 \\oplus … \\oplus V_p\\) une décomposition de \\(\\mathbb{R}^n\\) en sous-espaces vectoriels orthogonaux de dimensions \\(r_1, … , r_p\\).\nAlors les projectons orthogonales \\(\\pi_1, … , \\pi_p\\) de X sur \\(V_1, … , V_p\\) sont des vecteurs gaussiens indépendants et pour chaque i = 1, … , p:\n\\[\n\\frac{1}{\\sigma^2}\\ ||\\pi_i||^2 \\thicksim \\chi^2_{r_i}\n\\]"
  },
  {
    "objectID": "Exercices.html",
    "href": "Exercices.html",
    "title": "Exercices",
    "section": "",
    "text": "On considère les matrices suivantes :\n\\(A = \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}\\) \\(B = \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}\\) \\(C = \\begin{bmatrix} 2 & 1 \\\\ -3 & 0 \\\\ 1 & 2 \\end{bmatrix}\\) \\(D = \\begin{bmatrix} -2 & 5 \\\\ 5 & 0 \\end{bmatrix}\\) \\(E = \\begin{bmatrix} -1 & 1 & 3 \\\\ -1 & -4 & 0 \\\\ 0 & 2 & 5 \\end{bmatrix}\\)\nQuels sont les produits matriciels possibles ? Quelles sont les matrices carrées et les matrices symétriques ?\n\n\nCliquez pour afficher le corrigé\n\nLes produits matriciels possibles sont : \\(AC\\), \\(AE\\), \\(BD\\), \\(CD\\), \\(DC\\). La matrice carrée est \\(E\\), \\(C\\) et \\(D\\) sont des matrices symétriques.\n\n\n\n\n\nSoit \\(A = \\begin{bmatrix} -1 & 1 & 1 \\\\ -1 & -1 & 1 \\\\ -1 & 1 & -1 \\end{bmatrix}\\). Montrer que \\(A^2 = 2I_3 - A\\), en déduire que \\(A\\) est inversible et calculer \\(A^{-1}\\).\n\nPour montrer que \\(A^2 = 2I_3 - A\\), calculez \\(A^2\\) et démontrez que cette égalité est valide.\nPuisque \\(A^2 = 2I_3 - A\\), cela implique que \\(A\\) est inversible. Pour calculer \\(A^{-1}\\), utilisez cette relation et les propriétés des matrices inverses.\n\nSoit \\(A = \\begin{bmatrix} 1 & 0 & 2 \\\\ 0 & -1 & 1 \\\\ 1 & -2 & 0 \\end{bmatrix}\\). Calculer \\(A^3 - A\\). En déduire que \\(A\\) est inversible puis déterminer \\(A^{-1}\\).\n\nCalculez \\(A^3 - A\\) pour démontrer que \\(A\\) est inversible. En utilisant cette information, trouvez la matrice inverse \\(A^{-1}\\).\n\n\nCliquez pour afficher le corrigé\n\nLe calcul ne pose pas de problèmes. Il mène à: \\(\\frac{{A^2 + A^2}}{2} = I_3 \\implies A \\cdot \\left( \\frac{{A + I_3}}{2} \\right) = \\left( \\frac{{A + I_3}}{2} \\right) \\cdot A = I_3\\)\nA est inversible, et son inverse est : \\(A^{-1} = \\frac{{A + I_3}}{2}\\) Un calcul donne : \\(A^3 - A = 4 \\cdot I_3\\).\nDonc \\(A \\cdot \\frac{{A^2 - I_3}}{4} = I_3\\), ainsi \\(A\\) est inversible et \\(A^{-1} = \\frac{1}{4} \\cdot (A^2 - I_3) = \\frac{1}{4} \\cdot \\begin{bmatrix} 2 & -4 & 2 \\\\ 1 & -2 & -1 \\\\ 1 & 2 & -1 \\end{bmatrix}\\)"
  },
  {
    "objectID": "Exercices.html#exercice-1",
    "href": "Exercices.html#exercice-1",
    "title": "Exercices",
    "section": "",
    "text": "On considère les matrices suivantes :\n\\(A = \\begin{bmatrix} 1 & 2 & 3 \\end{bmatrix}\\) \\(B = \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}\\) \\(C = \\begin{bmatrix} 2 & 1 \\\\ -3 & 0 \\\\ 1 & 2 \\end{bmatrix}\\) \\(D = \\begin{bmatrix} -2 & 5 \\\\ 5 & 0 \\end{bmatrix}\\) \\(E = \\begin{bmatrix} -1 & 1 & 3 \\\\ -1 & -4 & 0 \\\\ 0 & 2 & 5 \\end{bmatrix}\\)\nQuels sont les produits matriciels possibles ? Quelles sont les matrices carrées et les matrices symétriques ?\n\n\nCliquez pour afficher le corrigé\n\nLes produits matriciels possibles sont : \\(AC\\), \\(AE\\), \\(BD\\), \\(CD\\), \\(DC\\). La matrice carrée est \\(E\\), \\(C\\) et \\(D\\) sont des matrices symétriques."
  },
  {
    "objectID": "Quizz.html",
    "href": "Quizz.html",
    "title": "Quizz",
    "section": "",
    "text": "En économie, un agent rationnel est un agent :\n\n\négoïste\n\n\n\ndont les préférences sur les alternatives sont transitives\n\n\n\nqui maximise son bonheur\n\n\n\nqui fait toujours le meilleur choix\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ndont les préférences sur les alternatives sont transitives\n\n\n\n\nUn équilibre de Nash est :\n\n\nune situation où aucun agent ne peut accroitre son utilité étant donné les choix des autres agents\n\n\nune situation où il est impossible d’accroitre l’utilité d’un agent sans diminuer celle d’un autre\n\n\nune situation où la somme des utilités est maximisée\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nune situation où aucun agent ne peut accroitre son utilité étant donné les choix des autres agents\n\n\n\n\n\n\nSoit f: R -&gt; R+ la densité d’une variable aléatoire, notée X qui est définie par f(x)= 3/4 (x2+1) si x appartient à [0,1] et qui vaut 0 ailleurs, alors on a :\n\n\nE(X)=1\n\n\nE(X)=9/16\n\n\nE(X)=3/8\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nE(X)=9/16\n\n\n\nSoient X ~N(-1;3) , Y ~N(4;2) et Cov(X,Y)=-1 alors la variable 2X-Y suit une loi :\n\n\nN(-6; 12)\n\n\nN(-6, 14)\n\n\nN(-6, 16)\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nN(-6; 12)\n\n\n\nSoit f :R² -&gt; R+, la densité d’un couple de variables aléatoires, notées (X,Y) qui est définie par: f(x,y)=12/11 (xy+(x²+3)y) si x appartient à [0,1], et y appartient à [0,1] et qui vaut 0 ailleurs. Les variables X et Y sont-elles indépendantes ?\n\n\noui\n\n\nnon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\noui\n\n\n\nSoient X ~N(1,2) , Y ~N(-1,4) et Cov(X,Y)= -1  alors la variable \\((X-1)²/2^{1/2}+(Y+1)²/2\\) ~ \\(chi²(2)\\)\n\n\nvrai\n\n\nfaux\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nfaux\n\n\n\n\n\n\nQuelle est la différence entre l’objectif de la statistique descriptive et la statistique inférentielle ?\n\n\nLa statistique descriptive résume un phénomène observé sur la population observée. Tandis que la statistique inférentielle généralise un phénomène observé sur un échantillon de la population à la population cible.\n\n\nLa statistique descriptive généralise un phénomène observé sur un échantillon de la population à la population cible. Tandis que la statistique inférentielle résume un phénomène observé sur la population observée.\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nLa statistique descriptive résume un phénomène observé sur la population observée. Tandis que la statistique inférentielle généralise un phénomène observé sur un échantillon de la population à la population cible.\n\n\n\nOn suppose que \\(X_1 , …, X_n\\) forment un n-échantillon que l’on observe. \\(X_1\\) suit la loi \\(𝑃_𝜃\\). On construit un estimateur 𝜃̂ = 𝑆(“\\(X_1,…,X_n\\)” )de 𝜃. 𝜃 ̂ est-il aléatoire ?\n\n\noui\n\n\nnon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\noui\n\n\n\nOn dit qu’un estimateur â est meilleur que ô lorsque :\n\n\nâ est sans biais alors que ô ne l’est pas\n\n\nâ est consistant alors que ô ne l’est pas\n\n\nLe biais de â est plus petit en valeur absolue, que celui de ô\n\n\nLe risque quadratique de â est plus petit que celui de ô\n\n\nLa variance de â est plus petite que la variance de ô\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nLe risque quadratique de â est plus petit que celui de ô\n\n\n\n\n\n\nExcel est un :\n\n\ntraitement de texte\n\n\ntableur\n\n\ncompilateur\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ntableur\n\n\n\nDans une feuille de calcul Excel, les données sont stockées dans\n\n\nune variable\n\n\nune cellule\n\n\nun cadre\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nune cellule\n\n\n\nL’écriture =somme(ventes) est une écriture :\n\n\ncorrecte\n\n\ncorrecte si une plage a été nommée ventes\n\n\nnon correcte\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ncorrecte si une plage a été nommée ventes\n\n\n\n\n\n\nOn dispose d’un échantillon de données numérique nommée sample_x. Et on code\u000bSample_x&lt;-sort(sample_x). Que fait ce code ?\n\n\nil sort l’échantillon x\n\n\nil sort x de l’échantillon\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans le même échantillon\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans un autre échantillon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans un autre échantillon\n\n\n\nOn dispose d’un fichier nommé Sportcourse.csv et du code don&lt;-read.table(“Sportcourse.csv”, header=T, sep=“;”). Que fait ce code ?\n\n\nil lit le fichier « Sportcourse.csv et ouvre un tableur\n\n\nil lit le fichier Sportcourse.csv et le stocke dans un autre csv nommé « don »\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans un tableau de données nommé don\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans une matrice nommée don\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans un tableau de données nommé don\n\n\n\nOn dispose d’un tableau de donnée dans R (un data.frame) nommé « don » et du code : rownames(don)&lt;-don[,1] don&lt;-don[,-1]. Que fait ce code ?\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus.\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus et garde la première colonne.\n\n\nil modifie don en déplaçant les noms de la première ligne comme nom des individus et supprime la première colonne.\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des variables et supprime la première colonne.\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus."
  },
  {
    "objectID": "Quizz.html#quest-ce-quune-variable",
    "href": "Quizz.html#quest-ce-quune-variable",
    "title": "Quizz",
    "section": "",
    "text": "Une variable statistique est une caractéristique ou une mesure que l’on peut attribuer à chaque individu d’une population ou d’un échantillon"
  },
  {
    "objectID": "Quizz.html#vocabulaire-autour-de-la-variable",
    "href": "Quizz.html#vocabulaire-autour-de-la-variable",
    "title": "Quizz",
    "section": "",
    "text": "Ton contenu ici…"
  },
  {
    "objectID": "Exercices.html#exercice-2",
    "href": "Exercices.html#exercice-2",
    "title": "Exercices",
    "section": "",
    "text": "Soit \\(A = \\begin{bmatrix} -1 & 1 & 1 \\\\ -1 & -1 & 1 \\\\ -1 & 1 & -1 \\end{bmatrix}\\). Montrer que \\(A^2 = 2I_3 - A\\), en déduire que \\(A\\) est inversible et calculer \\(A^{-1}\\).\n\nPour montrer que \\(A^2 = 2I_3 - A\\), calculez \\(A^2\\) et démontrez que cette égalité est valide.\nPuisque \\(A^2 = 2I_3 - A\\), cela implique que \\(A\\) est inversible. Pour calculer \\(A^{-1}\\), utilisez cette relation et les propriétés des matrices inverses.\n\nSoit \\(A = \\begin{bmatrix} 1 & 0 & 2 \\\\ 0 & -1 & 1 \\\\ 1 & -2 & 0 \\end{bmatrix}\\). Calculer \\(A^3 - A\\). En déduire que \\(A\\) est inversible puis déterminer \\(A^{-1}\\).\n\nCalculez \\(A^3 - A\\) pour démontrer que \\(A\\) est inversible. En utilisant cette information, trouvez la matrice inverse \\(A^{-1}\\).\n\n\nCliquez pour afficher le corrigé\n\nLe calcul ne pose pas de problèmes. Il mène à: \\(\\frac{{A^2 + A^2}}{2} = I_3 \\implies A \\cdot \\left( \\frac{{A + I_3}}{2} \\right) = \\left( \\frac{{A + I_3}}{2} \\right) \\cdot A = I_3\\)\nA est inversible, et son inverse est : \\(A^{-1} = \\frac{{A + I_3}}{2}\\) Un calcul donne : \\(A^3 - A = 4 \\cdot I_3\\).\nDonc \\(A \\cdot \\frac{{A^2 - I_3}}{4} = I_3\\), ainsi \\(A\\) est inversible et \\(A^{-1} = \\frac{1}{4} \\cdot (A^2 - I_3) = \\frac{1}{4} \\cdot \\begin{bmatrix} 2 & -4 & 2 \\\\ 1 & -2 & -1 \\\\ 1 & 2 & -1 \\end{bmatrix}\\)"
  },
  {
    "objectID": "Exercices.html#exercice-1-1",
    "href": "Exercices.html#exercice-1-1",
    "title": "Exercices",
    "section": "Exercice 1",
    "text": "Exercice 1\nDans la salle des profs 60% sont des femmes ; une femme sur trois porte des lunettes et un homme sur deux porte des lunettes : quelle est la probabilité pour qu’un porteur de lunettes pris au hasard soit une femme ?\n\n\nCliquez pour afficher le corrigé\n\nNotons les différents événements : \\(Fe\\) : « être femme », \\(Lu\\) : « porter des lunettes », \\(H\\) : « être homme ».\nAlors, on a \\(P(Fe) = 0.6\\), \\(P(Lu|Fe) = \\frac{1}{3}\\) ; il s’agit de la probabilité conditionnelle de « porter des lunettes » sachant que la personne est une femme.\nDe même, on a \\(P(Lu|H) = 0.5\\).\nOn cherche la probabilité conditionnelle \\(P(Fe|Lu)\\).\nD’après la formule des probabilités totales, on a : \\(P(Fe|Lu) \\cdot P(Lu) = P(Lu|Fe) \\cdot P(Fe)\\) avec \\(P(Lu) = P(Lu|Fe) \\cdot P(Fe) + P(Lu|H) \\cdot P(H)\\).\nApplication numérique : \\(P(Lu) = 0.4\\), donc \\(P(Fe|Lu) = \\frac{P(Lu|Fe) \\cdot P(Fe) \\cdot P(Lu)}{P(Lu)} = 0.5\\)."
  },
  {
    "objectID": "Exercices.html#exercice-2-1",
    "href": "Exercices.html#exercice-2-1",
    "title": "Exercices",
    "section": "Exercice 2",
    "text": "Exercice 2\nDans une entreprise deux ateliers fabriquent les mêmes pièces. L’atelier 1 fabrique en une journée deux fois plus de pièces que l’atelier 2. Le pourcentage de pièces défectueuses est 3% pour l’atelier 1 et 4% pour l’atelier 2. On prélève une pièce au hasard dans l’ensemble de la production d’une journée.\nDéterminer :\n- la probabilité que cette pièce provienne de l’atelier 1 ; - la probabilité que cette pièce provienne de l’atelier 1 et est défectueuse ; - la probabilité que cette pièce provienne de l’atelier 1 sachant qu’elle est défectueuse.\n\n\nCliquez pour afficher le corrigé\n\nNotons \\(A\\) l’événement “la pièce provient de l’atelier 1”, \\(B\\) l’événement “la pièce provient de l’atelier 2” et \\(D\\) l’événement “la pièce est défectueuse”.\nL’énoncé nous dit que les \\(\\frac{2}{3}\\) des pièces produites proviennent de l’atelier 1. Donc \\(P(A)=\\frac{2}{3}\\).\nOn cherche \\(P(A \\cap D) = P_A(D) \\cdot P(A) = 0.03 \\times 2/3 = 0.02\\). De même, on démontre que \\(P(B \\cap D) = 0.175\\) et donc que \\(P(D) = P(A \\cap D) + P(B \\cap D) = 0.15\\).\nAinsi, on a \\(P_D(A) = \\frac{P(A \\cap D)}{P(D)} = 0.133\\)"
  },
  {
    "objectID": "Exercices.html#exercice-3",
    "href": "Exercices.html#exercice-3",
    "title": "Exercices",
    "section": "Exercice 3",
    "text": "Exercice 3\nSoit \\(F\\) la fonction définie par :\n\\[\nf(x) = \\begin{cases}\n0 & \\text{si } x &lt; 0 \\\\\n0,29 & \\text{si } -1 \\leq x \\leq 1 \\\\\n0,37 & \\text{si } 1 \\leq x \\leq 7 \\\\\n0,69 & \\text{si } 7 \\leq x \\leq 11 \\\\\n1 & \\text{si } x \\geq 11\n\\end{cases}\n\\] 1) Vérifiez que \\(F(x)\\) est une fonction de répartition en vérifiant les conditions requises pour une fonction de répartition.\n\nSoit \\(X\\) la variable aléatoire admettant \\(F\\) pour fonction de répartition ; quelle est la loi de \\(X\\) ?\n\n\n\nCliquez pour afficher le corrigé\n\n\n\\(F\\) est croissante, de limite nulle en \\(-\\infty\\), de limite égale à \\(1\\) en \\(+\\infty\\) et continue à droite ; il s’agit donc bien d’une fonction de répartition.\n\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nx \\in X(\\Omega) & P(X = x) \\\\\n\\hline\n-1 & 0.29 \\\\\n1 & 0.08 \\\\\n7 & 0.32 \\\\\n11 & 0.31 \\\\\n\\hline\n\\end{array}\n\\]"
  },
  {
    "objectID": "Exercices.html#exercice-sur-les-fonctions-de-répartition",
    "href": "Exercices.html#exercice-sur-les-fonctions-de-répartition",
    "title": "Exercices",
    "section": "Exercice sur les fonctions de répartition",
    "text": "Exercice sur les fonctions de répartition\nSoit \\(F\\) la fonction définie par :\n\\[\nf(x) = \\begin{cases}\n0 & \\text{si } x &lt; 0 \\\\\n0,29 & \\text{si } -1 \\leq x \\leq 1 \\\\\n0,37 & \\text{si } 1 \\leq x \\leq 7 \\\\\n0,69 & \\text{si } 7 \\leq x \\leq 11 \\\\\n1 & \\text{si } x \\geq 11\n\\end{cases}\n\\] 1) Vérifiez que \\(F(x)\\) est une fonction de répartition en vérifiant les conditions requises pour une fonction de répartition.\n\nSoit \\(X\\) la variable aléatoire admettant \\(F\\) pour fonction de répartition ; quelle est la loi de \\(X\\) ?"
  },
  {
    "objectID": "Exercices.html#exercice-4",
    "href": "Exercices.html#exercice-4",
    "title": "Exercices",
    "section": "Exercice 4",
    "text": "Exercice 4\nSoit \\(X\\) une variable aléatoire de loi de Poisson de paramètre \\(\\lambda &gt; 0\\). Calculer \\(E[(1 + X)^{-1}]\\).\n\n\nCliquez pour afficher le corrigé\n\n\\(E((1+X)^{-1}) = \\sum_{k=0}^{\\infty} \\frac{1}{1+k} \\cdot e^{-\\lambda} \\cdot \\frac{\\lambda^k}{k!} = e^{-\\lambda} \\sum_{k=0}^{\\infty} \\frac{\\lambda^{k+1}}{(k+1)!} = e^{-\\lambda} \\left(\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} - 1\\right) = e^{-\\lambda} (e^{\\lambda} - 1) = \\frac{1 - e^{-\\lambda}}{\\lambda}\\)"
  },
  {
    "objectID": "Exercices.html#exercice-5",
    "href": "Exercices.html#exercice-5",
    "title": "Exercices",
    "section": "Exercice 5",
    "text": "Exercice 5\nMontrer que \\(\\text{Var}(X) = E(X^2) - 2(E(X))^2\\).\n\n\nCliquez pour afficher le corrigé\n\n$ (X) = E[(X-E(X))^2] = E(X^2 - 2 E(X)X + (E(X))^2) = E(X^2) - 2 E(X)E(X) + (E(X))^2 = E(X^2) - 2(E(X))^2 $"
  },
  {
    "objectID": "Exercices.html#exercice-6",
    "href": "Exercices.html#exercice-6",
    "title": "Exercices",
    "section": "Exercice 6",
    "text": "Exercice 6\nLe nombre \\(X\\) de kg de tomates récoltés dans un jardin en une semaine est une variable aléatoire dont la loi de probabilité est la suivante :\n\nQuelle est l’espérance mathématique de \\(X\\) et quelle est sa variance ?\nPendant les six semaines de la saison de récolte, la distribution de probabilité ne varie pas. Calculer l’espérance mathématique et la variance de la variable aléatoire \\(Y\\) donnant la récolte totale en kg durant les six semaines.\n\n\n\nCliquez pour afficher le corrigé\n\n\n\\(E(X) = 0 \\times 0.1 + 1 \\times 0.5 + 2 \\times 0.3 + 3 \\times 0.1 = 1.4\\); \\(E(X^2) = 0^2 \\times 0.1 + 1^2 \\times 0.5 + 2^2 \\times 0.3 + 3^2 \\times 0.1 = 2.6\\) donc \\(Var(X) = E(X^2) - (E(X))^2 = 0.64\\)\n\\(Y\\) étant la somme de 6 variables aléatoires i.i.d., on a : \\(E(Y) = 6E(X) = 8.4\\) et \\(Var(Y) = 6\\) et \\(Var(X) = 3.84\\)"
  },
  {
    "objectID": "Quizz.html#economie",
    "href": "Quizz.html#economie",
    "title": "Quizz",
    "section": "",
    "text": "En économie, un agent rationnel est un agent :\n\n\négoïste\n\n\n\ndont les préférences sur les alternatives sont transitives\n\n\n\nqui maximise son bonheur\n\n\n\nqui fait toujours le meilleur choix\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ndont les préférences sur les alternatives sont transitives\n\n\n\n\nUn équilibre de Nash est :\n\n\nune situation où aucun agent ne peut accroitre son utilité étant donné les choix des autres agents\n\n\nune situation où il est impossible d’accroitre l’utilité d’un agent sans diminuer celle d’un autre\n\n\nune situation où la somme des utilités est maximisée\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nune situation où aucun agent ne peut accroitre son utilité étant donné les choix des autres agents"
  },
  {
    "objectID": "Quizz.html#probabilités",
    "href": "Quizz.html#probabilités",
    "title": "Quizz",
    "section": "",
    "text": "Soit f: R -&gt; R+ la densité d’une variable aléatoire, notée X qui est définie par f(x)= 3/4 (x2+1) si x appartient à [0,1] et qui vaut 0 ailleurs, alors on a :\n\n\nE(X)=1\n\n\nE(X)=9/16\n\n\nE(X)=3/8\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nE(X)=9/16\n\n\n\nSoient X ~N(-1;3) , Y ~N(4;2) et Cov(X,Y)=-1 alors la variable 2X-Y suit une loi :\n\n\nN(-6; 12)\n\n\nN(-6, 14)\n\n\nN(-6, 16)\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nN(-6; 12)\n\n\n\nSoit f :R² -&gt; R+, la densité d’un couple de variables aléatoires, notées (X,Y) qui est définie par: f(x,y)=12/11 (xy+(x²+3)y) si x appartient à [0,1], et y appartient à [0,1] et qui vaut 0 ailleurs. Les variables X et Y sont-elles indépendantes ?\n\n\noui\n\n\nnon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\noui\n\n\n\nSoient X ~N(1,2) , Y ~N(-1,4) et Cov(X,Y)= -1  alors la variable \\((X-1)²/2^{1/2}+(Y+1)²/2\\) ~ \\(chi²(2)\\)\n\n\nvrai\n\n\nfaux\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nfaux"
  },
  {
    "objectID": "Quizz.html#statistique",
    "href": "Quizz.html#statistique",
    "title": "Quizz",
    "section": "",
    "text": "Quelle est la différence entre l’objectif de la statistique descriptive et la statistique inférentielle ?\n\n\nLa statistique descriptive résume un phénomène observé sur la population observée. Tandis que la statistique inférentielle généralise un phénomène observé sur un échantillon de la population à la population cible.\n\n\nLa statistique descriptive généralise un phénomène observé sur un échantillon de la population à la population cible. Tandis que la statistique inférentielle résume un phénomène observé sur la population observée.\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nLa statistique descriptive résume un phénomène observé sur la population observée. Tandis que la statistique inférentielle généralise un phénomène observé sur un échantillon de la population à la population cible.\n\n\n\nOn suppose que \\(X_1 , …, X_n\\) forment un n-échantillon que l’on observe. \\(X_1\\) suit la loi \\(𝑃_𝜃\\). On construit un estimateur 𝜃̂ = 𝑆(“\\(X_1,…,X_n\\)” )de 𝜃. 𝜃 ̂ est-il aléatoire ?\n\n\noui\n\n\nnon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\noui\n\n\n\nOn dit qu’un estimateur â est meilleur que ô lorsque :\n\n\nâ est sans biais alors que ô ne l’est pas\n\n\nâ est consistant alors que ô ne l’est pas\n\n\nLe biais de â est plus petit en valeur absolue, que celui de ô\n\n\nLe risque quadratique de â est plus petit que celui de ô\n\n\nLa variance de â est plus petite que la variance de ô\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nLe risque quadratique de â est plus petit que celui de ô"
  },
  {
    "objectID": "Quizz.html#excel",
    "href": "Quizz.html#excel",
    "title": "Quizz",
    "section": "",
    "text": "Excel est un :\n\n\ntraitement de texte\n\n\ntableur\n\n\ncompilateur\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ntableur\n\n\n\nDans une feuille de calcul Excel, les données sont stockées dans\n\n\nune variable\n\n\nune cellule\n\n\nun cadre\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nune cellule\n\n\n\nL’écriture =somme(ventes) est une écriture :\n\n\ncorrecte\n\n\ncorrecte si une plage a été nommée ventes\n\n\nnon correcte\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\ncorrecte si une plage a été nommée ventes"
  },
  {
    "objectID": "Quizz.html#code-r",
    "href": "Quizz.html#code-r",
    "title": "Quizz",
    "section": "",
    "text": "On dispose d’un échantillon de données numérique nommée sample_x. Et on code\u000bSample_x&lt;-sort(sample_x). Que fait ce code ?\n\n\nil sort l’échantillon x\n\n\nil sort x de l’échantillon\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans le même échantillon\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans un autre échantillon\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil trie l’échantillon x par ordre croissant et le stocke dans un autre échantillon\n\n\n\nOn dispose d’un fichier nommé Sportcourse.csv et du code don&lt;-read.table(“Sportcourse.csv”, header=T, sep=“;”). Que fait ce code ?\n\n\nil lit le fichier « Sportcourse.csv et ouvre un tableur\n\n\nil lit le fichier Sportcourse.csv et le stocke dans un autre csv nommé « don »\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans un tableau de données nommé don\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans une matrice nommée don\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil lit le fichier Sportcourse.csv avec une ligne avec les noms des variables et un séparateur et le stocke dans un tableau de données nommé don\n\n\n\nOn dispose d’un tableau de donnée dans R (un data.frame) nommé « don » et du code : rownames(don)&lt;-don[,1] don&lt;-don[,-1]. Que fait ce code ?\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus.\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus et garde la première colonne.\n\n\nil modifie don en déplaçant les noms de la première ligne comme nom des individus et supprime la première colonne.\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des variables et supprime la première colonne.\n\n\n\n\nCliquez pour afficher le corrigé\n\n\n\nil modifie don en déplaçant les noms de la première colonne comme nom des individus."
  },
  {
    "objectID": "M2SEP.html#rappels-fondamentaux",
    "href": "M2SEP.html#rappels-fondamentaux",
    "title": "DATA Camp M2",
    "section": "",
    "text": "En théorie des probabilités, nous nous intéressons souvent au comportement d’un aléa, sachant qu’un autre événement est déjà passé. C’est ce que nous appelons Les Probabilités Conditionnelles.\nConsidérant deux événements de probabilité non nulle, \\(A\\) et \\(B\\), la probabilité conditionnelle de \\(A\\) sachant que \\(B\\) est réalisé (couramment dit \\(A\\) sachant \\(B\\)) est donnée par : \\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}\n\\]\nPar commutativité de l’intersection, nous avons : \\[\nP(A \\cap B) = P(B \\cap A)\n\\]\nEn utilisant la formule ci-dessus, nous pouvons également exprimer la probabilité conditionnelle de \\(B\\) sachant \\(A\\) : \\[\nP(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n\\]\nC’est ce que nous appelons la formule de Bayes.\n\n\n\nUne variable statistique est une caractéristique ou une mesure que l’on peut attribuer à chaque individu d’une population ou d’un échantillon.\n\n\n\n\n\n\n\n\n\n\n\nLors d’une analyse statistique, on distingue deux types principaux de variables :\n\nLa variable à expliquer (à prédir, ou à estimer) : Y\nLes variables explicatives (prédictives ou estimatrices) : X_i\n\nTout l’exercice reside à établir la relation la plus pertinente entre les variables explicatives X_i et la variable à expliquer Y.\nTableau des synonymes :\nCatégorique = Qualitative.\nNumérique = Quantitative.\n\n\n\n\n\n\n\n\nJe cherche à estimer le prix d’une maison en fonction de 4 caractéristiques : le type de bien, l’état du bien, le nombre de pièces et la superficie en m2.\nPour ce faire, j’ai à ma disposition une base de données intitulée “data_immobilier” (générée aléatoirement) que je traite en R.\nAvant tout, je dois avoir ces éléments en tête :\n\n\n\n\n\nEnsuite, je peux passer à l’étape suivante."
  },
  {
    "objectID": "M2SEP.html#traitement-des-données",
    "href": "M2SEP.html#traitement-des-données",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Peu importe leur origine, les bases de données nécessitent presque toujours un traitement avant d’être exploitables. De la collecte à l’enregistrement, des irrégularités s’introduisent, causant des erreurs lors de l’exploitation. Le traitement vise à corriger ou à gérer ces irrégularités. Bien que chaque base de données présente ses propres spécificités et problèmes, les quatre points que nous aborderons par la suite sont courants et doivent être maîtrisés\n\n\nLes valeurs manquantes, souvent représentées par les NaN, sont parmi les anomalies les plus couramment rencontrées dans les bases de données. Plusieurs stratégies peuvent être adoptées face à ces valeurs :\nConversion : On surpasse le NaN en le convertissant en une autre valeur, comme un flottant.\n\nAvantage : Conservation de données.\nDésavantage : Introduction d’un biais potentiellement significatif.\n\nCode :\n# Convertir les NaN en 0 (ou une autre valeur) en R.\ndf[is.na(df)] &lt;- 0\n# Convertir les NaN en 0 (ou une autre valeur) en python. \ndf.fillna(0, inplace=True)\nimputation : remplacer les valeurs manquantes par des estimations (la moyenne ou la médiane des autres valeurs).\n\nAvantage : Conservation de données.\nDésavantage : Introduction d’un biais potentiellement significatif.\n\nCode :\n## Utiliser la moyenne pour imputer en R \ndf$column_name[is.na(df$column_name)] &lt;- mean(df$column_name, na.rm = TRUE)\n# Utiliser la moyenne pour imputer en python\ndf['column_name'].fillna(df['column_name'].mean(), inplace=True)\nsuppression : supprimer les lignes avec des NaN.\n\nAvantage : On limite le biais .\nDésavantage : perte d’information générale.\n\nCode :\n# Supprimer les lignes contenant des NaN en R\ndf &lt;- df[complete.cases(df), ]\n# Supprimer les lignes contenant des NaN \ndf.dropna(inplace=True)\nIl n’y a pas de solution parfaite, certains cas vont favoriser certains choix, mais la suppression reste quand même la plus sur en terme de qualité de l’information, à privilègier des que possible.\n\n\n\nLa fonction group_by est utilisé pour regrouper des données en fonction de certaines variables catégorielles. Cela permet d’effectuer des opérations et des analyses spécifiques à chaque groupe, et comprendre les comportements ou les anomalies spécifiques à chaque groupe.\nConcretement, si l’on reprend la base data_immobilier, faire une group_by sur la variable Type_de_bien nous permettra de faire une etude sur le groupe maison, loft, appartement et studio séparemment.\nR :\n# Groupement des données par Type_de_bien et calcul de la moyenne des autres variables\ndata_grouped &lt;- data_immobilier %&gt;%                                 #Nouveau DataFrame \"data_grouped\"\n  group_by(Type_de_bien) %&gt;%                                        #Selection par groupe \"Type de bien\"\n  summarise(                                                        #Affiche les infomations\n    Prix_moyen = mean(Prix, na.rm = TRUE),                          #La moyenne de prix pour chaque groupe\n    Superficie_moyenne = mean(Superficie_m2, na.rm = TRUE),         #La moyenne de superficie pour chaque groupe\n    Nombre_moyen_de_pieces = mean(Nombre_de_pieces, na.rm = TRUE)   #La moyenne de Nombre de piece pour chaque groupe\n  )\nprint(data_grouped)                                                 #Affichage\nPython :\n# Groupement des données par Type_de_bien et calcul de la moyenne des autres variables \ndata_grouped = data_immobilier.groupby('Type_de_bien').agg({\n    'Prix': 'mean',\n    'Superficie_m2': 'mean',\n    'Nombre_de_pieces': 'mean'\n}).reset_index()\nprint(data_grouped)\n\n\n\nLa fonction merge est utilisée pour fusionner deux dataframes sur la base d’au moins une colonne commune. Cette fonction est extremement utile si l’on souhaite combiner des données provennant de differentes bases pour une même analyse.\nApplication concrète avec la base de données data_immobilier:\nOn a une autre base de données, data_Localisation, avec les variables Superficie_m2 et Localisation. En utilisant la fonction merge, on va fusionner les deux bases de données en utilisant la colonne commune, Superficie_m2 , pour avoir une base de données plus riche.\n# Exemple de code R utilisant merge\ndata_complete &lt;- merge(data_immobilier, data_Localisation, by = \"Superficie_m2\", all = TRUE)\n# Exemple de code Python utilisant merge\ndata_complete = pd.merge(data_immobilier, data_Localisation, on='Superficie_m2', how='outer')\n\n\n\n\n\n\n\n\nLes variables dummy sont utilisées pour convertir des variables catégorielles en variables numériques.\nObjectifs : Utiliser ces variables dans des analyses statistiques et des modèles de machine learning qui requièrent des entrées numériques. Comment créer des variables dummy ? Exemple concret :\nOn reprend le dataframe qui a une desormais colonne catégorielle nommée Localisation avec des noms de villes. On crée les variables dummy, soit pour chaque catégorie unique dans la colonne Localisation deviendra une nouvelle colonne dans le dataframe.\n# En R\ndata_with_dummies &lt;- model.matrix(~ Localisation - 1, data = data_complete) %&gt;% \n                     as.data.frame()\n# En python\ndata_with_dummies = pd.get_dummies(data_complete, columns=['Localisation'], prefix='', prefix_sep='')\nDans le nouveau dataframe, data_with_dummies, chaque ville unique de la colonne Localisation originale a été transformée en une nouvelle colonne. Si une observation dans la colonne Localisation originale était “Paris”, alors la colonne LocalisationParis serait marquée avec un 1, et toutes les autres colonnes de ville seraient marquées avec des 0.\n\nAttention aux problémes de multicolinéarité, supprimer une colonne pour une utilisation dans certains modèles."
  },
  {
    "objectID": "M2SEP.html#statistiques-descriptives",
    "href": "M2SEP.html#statistiques-descriptives",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Les statistiques descriptives permettent de résumer, décrire et comprendre les données.\nPour les variables quantitatives, on utilise :\nMoyenne : La valeur moyenne.\nMédiane : La valeur centrale.\nMode : La valeur la plus fréquente.\nMin,Max= valeur minimal et maximum. Écart Type : Mesure de la dispersion des valeurs.\n# En python\ndescribe(data_quantitative)\n# En R \nsummary(data_quantitative)\nPour les variables qualitatives, on utilise:\nFréquences : Nombre de fois qu’une catégorie apparaît.\nPourcentages : Proportion d’une catégorie par rapport au total.\n# En python\n# Calculer les fréquences\nfreq = data_qualitative.value_counts()\n# Calculer les pourcentages\nperce = frequencies / len(data_qualitative) * 100\n# En R \n# Calculer les fréquences\nfrequencies &lt;- table(data_qualitative)\n# Calculer les pourcentages\npercentages &lt;- prop.table(frequencies) * 100\nOn illustre également par des graphiques descriptifs:\nHistogrammes et Diagrammes en Barres : Pour montrer la distribution des données.\nBoîtes à Moustaches (Boxplots) : Pour montrer la médiane, quartiles et valeurs aberrantes.\n# En python\n# Créer un histogramme pour les données quantitatives\nplt.hist(data_quantitative, bins=5, edgecolor='k')\nplt.xlabel(\"Valeurs\")\nplt.ylabel(\"Fréquence\")\nplt.title(\"Histogramme des données quantitatives\")\nplt.show()\n# En R \n# Créer un histogramme pour les données quantitatives\nggplot(data = data.frame(x = data_quantitative)) +\n  geom_histogram(aes(x = x), binwidth = 5, fill = \"blue\", color = \"black\") +\n  labs(x = \"Valeurs\", y = \"Fréquence\", title = \"Histogramme des données quantitatives\")\nLa statistique descriptive offre une première compréhension des données, indispensable avant toute analyse plus approfondie. Elle permet de déceler des tendances, anomalies, ou relations à explorer davantage. C’est une étape indispensable à ne surtout pas negliger."
  },
  {
    "objectID": "M2SEP.html#premiers-modèles",
    "href": "M2SEP.html#premiers-modèles",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Définition d’une régression linéaire :\nLa régression linéaire simple est une méthode statistique qui permet de modéliser la relation entre deux variables en ajustant une ligne droite à un ensemble de données. L’équation de la régression linéaire est : \\[y = a + bx\\] où \\(y\\) est la variable dépendante, \\(x\\) est la variable indépendante, \\(a\\) est l’ordonnée à l’origine (l’interception de la ligne avec l’axe des ordonnées), et \\(b\\) est la pente de la ligne (le taux de changement de \\(y\\) par rapport à \\(x\\)).\nLa régression linéaire multiple reprend les mêmes principes, mais elle s’étend à plusieurs variables indépendantes. Ainsi, au lieu d’ajuster une ligne droite, on ajuste un hyperplan dans un espace multidimensionnel. L’équation de la régression linéaire multiple est la suivante :\n\\[\ny = a + b_1 x_1 + b_2 x_2 + \\dots + b_p x_p\n\\]\noù : - \\(y\\) est la variable dépendante, - \\(x_1, x_2, \\dots, x_p\\) sont les variables indépendantes, - \\(a\\) est l’ordonnée à l’origine (ou l’interception avec l’axe des ordonnées), - \\(b_1, b_2, \\dots, b_p\\) sont les coefficients de régression qui mesurent l’effet de chaque variable indépendante sur (y).\nDans ce cas, \\(b_1, b_2, \\dots, b_p\\) indiquent l’effet individuel de chaque variable \\(x_1, x_2, \\dots, x_p\\) sur la variable \\(y\\), tout en prenant en compte les autres variables. L’objectif de la régression linéaire multiple est d’estimer ces coefficients afin de prédire \\(y\\) à partir des valeurs des \\(x_i\\).\n\n\n\n\n\nMéthode des moindres carrés ordinaires :\nObjectif : Regarder à quel point la droite obtenue est meilleure que la droite de la moyenne des observations. Donc, \\(R^2 = \\min\\left(\\sum(y - \\hat{y})^2\\right)\\)\nMoindres carrés ajustés :\nLe \\(R^2\\) carré ordinaire peut seulement augmenter ou rester constant par l’ajout d’une nouvelle variable. Concretement, ne réduira jamais la capacité explicative du modèle. Le adjusted - \\(R^2\\) est une methode par pénalisation qui compense ce défaut. Il faut donc le privilègier à l’etude.\nP-value :\nC’est un indicateur statistique utilisé pour évaluer la significativité d’un résultat. On pose que l’hypothèse nulle (généralement l’absence d’effet ou de relation) est vraie. Une p-value faible suggère que les observations sont peu probables sous l’hypothèse nulle, indiquant ainsi une évidence forte contre l’hypothèse nulle et en faveur de l’hypothèse alternative, donc qu’il y a probablement une relation.\nUne p-value inférieure à un seuil défini (souvent 0,05) est généralement interprétée comme statistiquement significative, suggérant que le modèle ou la variable examinée a un effet réel et non dû au hasard.\nConcrètement,\n\np-value &lt; 5%, la variable est statistiquement significative, donc probablement explicative, on la garde dans le modèle.\np-value &gt; 5%, la variable n’est pas statistiquement significative, donc probablement pas explicative, on l’exclut du modèle.\n\nGestion des outliers :\nCertaines observations extrêmes, ou outliers, peuvent fausser les résultats en raison de leur décalage significatif par rapport au reste des données. Il faut les identifier et, si nécessaire, les exclure en amont de l’analyse. Pour ce faire, on utilise souvent des méthodes telles que DFFITS et DFBETAS. Ces techniques aident à déterminer si une observation individuelle est particulièrement influente et si elle devrait être considérée comme un outlier devant être exclu de l’analyse pour obtenir des résultats plus fiables.\nMulticollinéarité :\nLa multicollinéarité dans les modèles de régression linéaire est un phénomène où deux ou plusieurs variables explicatives sont fortement corrélées entre elles. Cette forte corrélation peut causer des problèmes dans l’estimation des coefficients de régression, rendant les résultats moins fiables. Pour mesurer le degré de multicollinéarité dans un modèle, on utilise souvent l’indice VIF.\n\nVIF &lt; 5, peu de risque de multicollinéarité .\nVIF &gt; 5, risque de multicollinéarité.\n\nMéthode Backward élimination pour affiner la précision du modèle :\nInitialement, on a une variable à expliquer et plusieurs variables explicatives.\nOn cherche la meilleure combinaison possible entre ces variables pour definir ce modèle, du point de vue de la significativité à travers la p-value, et de l’explicativité à travers le adjusted- \\(R^2\\).\nUne idée serait de tester toutes les combinaisons une à une, en théorie cela fonctionnerait, mais cela n’est pas réaliste au vu de la quantité de calcul nécessaire.\nla méthode Backward élimination consiste alors à évaluer le modèle par itération suivant le schéma suivant :\n\n1 - Je fais mon modèle avec l’ensemble des variables.\n2 - Je supprime LA variable qui à la p-value &gt; 5%, la plus élevé.\n3 - Je réévalue le modèle\n4 - Je regarde comment le adjusted-\\(R^2\\) à évoluer :\n\nIl augmente, c’est bien le modèle est plus explicatif\nIl diminue, c’est mauvais, la variable avait quand même une importance\n\nJe refléchis à la conserver ou non si la p-value est pas trop haute.\n\n\n5 - Je répète les étapes 2,3 et 4 autant de fois que nécessaire.\n\nCodes :\nRégression linéaire simple :\n#var1 -&gt; a expliquer\n#var2 -&gt; explicative\n\nReg1&lt;-lm(var1~var2, data=df)\nsummary(Reg1) # Le détail \nabline(Reg1) #Representation de la regression linéaire \nRégression linéaire multiple :\n#var1 -&gt; a expliquer\n\nReg1&lt;-lm(var1~var2+var3+var4, data=df)\nsummary(Reg1) # Le détail \nabline(Reg1)  #Representation de la regression linéaire \n\n\n\nDefinition d’une régression logistique : Utilisée pour des problèmes de classification ( variable dependante bianire ).\n\nPrincipe: Modélise la probabilité que la variable dépendante appartienne à une catégorie particulière.\n\n# Régression logistique en R (y binaire à expliquer)\nglm_model &lt;- glm(y ~ x1 + x2, data = dataset, family = \"binomial\")\nsummary(glm_model)\n# Régression logistique en Python (y binaire à expliquer)\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X, y)\n\n\n\n\n\nUsage: Utilisée pour traiter le problème de multicollinéarité dans les données. Ajoute une pénalité au carré des coefficients. Principe: Minimise une somme pondérée des carrés des résidus et des carrés des coefficients.\n# Régression Ridge en R\nlibrary(glmnet)\nridge_model &lt;- glmnet(x, y, alpha = 0, lambda = lambda_value)\n# Régression Ridge en Python\nfrom sklearn.linear_model import Ridge\n\nmodel = Ridge(alpha=1.0)\nmodel.fit(X, y)\n\n\n\nUsage: Usage: Permet de sélectionner des variables en réduisant les coefficients de certaines à zéro.\nPrincipe: Semblable à Ridge, mais ajoute une pénalité absolue aux coefficients.\n# Régression Lasso en R\nlibrary(glmnet)\nlasso_model &lt;- glmnet(x, y, alpha = 1, lambda = lambda_value)\n# Régression Lasso en Python\nfrom sklearn.linear_model import Lasso\n\nmodel = Lasso(alpha=1.0)\nmodel.fit(X, y)"
  },
  {
    "objectID": "M2SEP.html#test-dindependance",
    "href": "M2SEP.html#test-dindependance",
    "title": "DATA Camp M2",
    "section": "",
    "text": "Les tests d’indépendance, sont utilisés en statistique pour déterminer si deux variables semblent être liées ou non. L’intérêt principal de ces tests est de vérifier l’existence d’une association ou d’une relation entre les variables.\nCas 1: Les deux variables sont nominales\n# Tableaux des effectifs croisés ou fréquences croisées\ntab &lt;- table(var1, var2)\nprint(tab)\nprop_table &lt;- prop.table(tab, margin = 2)\nprint(prop_tab)\n\n# Représentation graphique des profils\nbarplot(tab, legend = TRUE, beside = TRUE)\nbarplot(prop_table, legend = TRUE, beside = TRUE)\n\n# Test d'indépendance du khi-carré\nchi_sq_test &lt;- chisq.test(tab)\nprint(chi_sq_test)\n\n# Si chi_sq_test$p.value &lt; 0.05 & all(chi_sq_test$expected &gt; 5)\n# Alors test significatif et effectifs espérés supérieurs à 5, il y a dependance. \n\n# Analyse des résidus standardisés via leur représentation avec la fonction mosaicplot()\nmosaicplot(tab)\nCas 2: Une variable est quantitative et l’autre est nominale binaire\n# var1 -&gt; quantitative \n# var2 -&gt; nominale binaire\n\n# Sous-populations définies par la variable binaire\ngroupe1 &lt;- df$var1[df$var2 == \"Oui\"]\ngroupe2 &lt;- df$var1[df$var2 == \"Non\"]\n\n# Indicateurs statistiques \nsummary(groupe1)\nsummary(groupe2)\n\n# Representation graphique\nggplot(df, aes(x = variable_nominale, y = variable_quantitative)) +\n  geom_boxplot() +\n  theme_minimal()\n\n# Tester la normalité\nshapiro1 &lt;- shapiro.test(groupe1)\nshapiro2 &lt;- shapiro.test(groupe2)\nprint(shapiro1)\nprint(shapiro2)\n\n# Si shapiro1$p.value &gt; 0.05 et shapiro2$p.value &gt; 0.05\n# Normalité non rejetté \n\n# Procédure paramétrique\n\n# Tester l'égalité des variances\nvar_test &lt;- var.test(groupe1, groupe2)\nprint(var_test)\n\n# Si var_test$p.value &gt; 0.05\n# Égalité des variances non rejeté \n# Faire un test de comparasion des moyennes \nt_test &lt;- t.test(var_quanti ~ var_nominale, var.equal = TRUE)\nprint(t_test)\n\n# Si var_test$p.value &lt; 0.05\n# Égalité des variances rejetée\n# les variables ne sont pas indépendantes\n# Faire un test de comparasion des moyennes \nt_test &lt;- t.test(var_quanti ~ var_nominale, var.equal = FALSE)\nprint(t_test)\n\n# Procédure non paramétrique (shapiro1$p.value &lt; 0.05 ou shapiro2$p.value &lt; 0.05)\n\n# Tester l'égalité des variances\nansari_test &lt;- ansari.test(groupe1, groupe2)\nprint(ansari_test)\n\n# Si ansari_test$p.value &gt; 0.05\n# Égalité des variances non rejetée\n# Faire un test de comparaison des medianes \nwilcox_test &lt;- wilcox.test(var_quanti ~ var_nominale)\nprint(wilcox_test)\n\n# Si ansari_test$p.value &lt; 0.05\n# Égalité des variances rejetée\n\n\"Les distributions conditionnelles de X connaissant Y diffèrent d'un paramètre d'échelle\"\nCas 3 : une variable est quantitative et l’autre nominale non binaire\n# var1 -&gt; quantitative \n# var2 -&gt; nominale non binaire\n\n# Indicateurs statistiques\nindicateurs &lt;- df %&gt;%\n  group_by(var2) %&gt;%\n  summarise(moyenne = mean(var1),\n            mediane = median(var1),\n            ecart_type = sd(var1),\n            minimum = min(var1),\n            maximum = max(var1),\n            q1 = quantile(var1, 0.25),\n            q3 = quantile(var1, 0.75))\nindicateurs\n\n# Représentations graphiques\nggplot(df, aes(x = choux$var2, y = choux$var1)) +\n  geom_boxplot(outlier.colour = \"red\", outlier.size = 2) +\n  scale_fill_manual(values = c(\"lightgray\", \"lightblue\"), guide = FALSE) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(x = \"\", y = \"Ventes \", title = \"Boîtes à Moustaches des ...\")\n\n# Test de normalité\nnormality &lt;- df %&gt;%\n  group_by(var2) %&gt;%\n  summarise(shapiro.test(var1)$p.value)\nnormality\n\n# si tous les shapiro.test(var1)$p.value &gt; 0.05\n# Normalité non rejetté \n# procédure Paramétrique\n\nbartlett_res &lt;- bartlett.test(var1 ~ var2, data = df)\nprint(bartlett_res)\n\n#si bartlett_res$p.value &gt; 0.05 \n#l’égalité des variances n’est pas rejetée\n\noneway_res &lt;- oneway.test(var1 ~ var2, data = df, var.equal = TRUE)\nprint(oneway_res)\n\n# Vérifier l'indépendance: \n\n##si oneway_res$p.value &gt; 0.05\n##alors Les variables sont indépendantes (pas de relation significative)\n\n##si oneway_res$p.value &lt; 0.05\n##Les variables ne sont pas indépendantes (relation significative)\n\n#si bartlett_res$p.value &lt; 0.05 (l’égalité des variances est rejetée)\n#Les variables ne sont pas indépendantes\n\n#si au moins un shapiro.test(tonnage)$p.value &lt; 0.05\n#Procédure Non paramétrique\n\nfligner_res &lt;- fligner.test(var1 ~ var2, data = df)\nprint(fligner_res)\n\n#si fligner_res$p.value &gt; 0.05 \n\n##l’égalité des variances n’est pas rejetée\nkruskal_res &lt;- kruskal.test(var1 ~ var2, data = df)\nprint(kruskal_res)\n\n## Vérifier l'indépendance\n\n## Si kruskal_res$p.value &gt; 0.05\n##Les variables sont indépendantes (pas de relation significative)\n\n## Si kruskal_res$p.value &lt; 0.05\n##Les variables ne sont pas indépendantes (relation significative)\n\n## Comparaison deux-à-deux\npairwise_wilcox_res &lt;- pairwise.wilcox.test(df$var_quanti, df$var_nominale)\nprint(pairwise_wilcox_res)\n\n#si fligner_res$p.value &gt; 0.05 \n#l’égalité des variances est rejetée\n\n'Les distributions conditionnelles de X connaissant Y diffèrent d un paramètre d echelle'\nCas 4 :Les deux variables sont quantitatives\n# Indicateurs statistiques\nsummary(var1)\nsummary(var2)\n\n# Représentation du nuage de points\nggplot() +\n  geom_point(aes(x = var1, y = var2)) +\n  theme_minimal()\n\n# Tester la normalité des couples d'observations\nmshapiro_test &lt;- shapiro.test(cbind(var1, var2))\nprint(mshapiro_test)\n\n# Si mshapiro_test$p.value &gt; 0.05\n# Normalité non rejeté\n\n## Test de non-corrélation de Pearson\npearson_test &lt;- cor.test(var1, var2, method = \"pearson\")\nprint(pearson_test)\n\n## Si la p-value &lt; 0,05 on peut rejeter l'hypothèse nulle de non-corrélation, \n## Conclure qu'il y a une corrélation significative entre les deux variables\n\n# Si mshapiro_test$p.value &lt; 0.05\n# Normalité rejetée\n\n# Test de non-corrélation monotone de Spearman\nspearman_test &lt;- cor.test(var1, var2, method = \"spearman\")\nprint(spearman_test)\n\n# Si la p-value &lt; 0,05 on peut rejeter l'hypothèse nulle de non-corrélation, \n# Conclure qu'il y a une corrélation significative entre les deux variables"
  },
  {
    "objectID": "intro.html#implication-dans-la-vie-universitaire",
    "href": "intro.html#implication-dans-la-vie-universitaire",
    "title": "Introduction au Data Camp",
    "section": "",
    "text": "Le module d’Implication dans la Vie Universitaire, fil rouge de la formation M2 Statistiques pour l’Évaluation et la Prévision, a pour but de montrer comment les étudiants peuvent s’investir dans la vie universitaire ou dans le monde associatif. Il a pour objectif la réalisation d’une mission d’utilité publique, qui va au-delà d’un module de cours classique en matière d’investissement dans un projet collectif et de prise d’initiative."
  },
  {
    "objectID": "Mathématiques.html#probabilités",
    "href": "Mathématiques.html#probabilités",
    "title": "Prérequis des mathématiques",
    "section": "Probabilités",
    "text": "Probabilités\n\nDéfinition\nUne variable aléatoire est une fonction mesurable définie sur un espace probabilisé \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) vers un espace mesurable \\((E, \\mathcal{E})\\). Autrement dit, c’est une fonction \\(X : \\Omega \\to E\\) telle que pour tout ensemble mesurable \\(B \\in \\mathcal{E}\\), l’ensemble des issues \\(\\{\\omega \\in \\Omega : X(\\omega) \\in B\\}\\) appartient à \\(\\mathcal{F}\\).\n\n\nTypes de Variables Aléatoires\n\nVariable aléatoire discrète : Peut prendre un nombre fini ou dénombrable de valeurs. Par exemple, le résultat d’un lancer de dé.\nVariable aléatoire continue : Peut prendre une infinité de valeurs dans un intervalle. Par exemple, la température mesurée à un moment donné.\n\n\n\nLoi de Probabilité\nLa loi de probabilité d’une variable aléatoire \\(X\\) décrit la distribution des probabilités associées aux différentes valeurs que \\(X\\) peut prendre.\n\n\nExemples\n\nLancer de dé : Si \\(X\\) représente le résultat d’un lancer de dé, alors \\(X\\) peut prendre les valeurs \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nTemps d’attente : Si \\(Y\\) représente le temps d’attente à un arrêt de bus, alors \\(Y\\) peut prendre n’importe quelle valeur positive.\n\nLa loi de probabilité d’une variable aléatoire peut être décrite via une fonction de densité.\n\n\nFonction de Densité\nUne fonction de densité \\(f_X\\) d’une variable aléatoire continue \\(X\\) est une fonction telle que pour tout intervalle \\([a, b]\\) : \\[\n\\mathbb{P}(a \\leq X \\leq b) = \\int_{a}^{b} f_X(x) \\, dx\n\\] La fonction de densité \\(f_X\\) est utilisée pour décrire la distribution des probabilités d’une variable aléatoire continue.\n\nPropriétés\n\nPositivité : \\(f_X(x) \\geq 0\\) pour tout \\(x\\).\nIntégrale égale à 1 : \\[\n\\int_{-\\infty}^{\\infty} f_X(x) \\, dx = 1\n\\]\n\nOn calcule aussi la fonction de répartition lorsqu’on cherche la probabilité que la variable aléatoire (X) prenne une valeur inférieure ou égale à (x).\n\n\n\nFonction de Répartition\nLa fonction de répartition d’une variable aléatoire \\(X\\) est la fonction \\(F_X\\) définie pour tout réel \\(x\\) par : \\[\nF_X(x) = \\mathbb{P}(X \\leq x)\n\\] Cette fonction donne la probabilité que la variable aléatoire \\(X\\) prenne une valeur inférieure ou égale à \\(x\\).\n\nPropriétés\n\nCroissance : \\(F_X\\) est une fonction croissante.\nLimites :\n\n\\(\\lim_{x \\to -\\infty} F_X(x) = 0\\)\n\\(\\lim_{x \\to \\infty} F_X(x) = 1\\)\n\nContinuité à droite : \\(F_X\\) est continue à droite, c’est-à-dire que pour tout \\(x\\), \\(\\lim_{h \\to 0^+} F_X(x + h) = F_X(x)\\).\nRelation avec la fonction de densité : \\[\nF_X(x) = \\int_{-\\infty}^{x} f_X(t) \\, dt\n\\]\n\n\n\n\nFormules Importantes\n\nEspérance (ou moyenne) : \\[\n\\mathbb{E}[X] = \\sum_{i} x_i \\mathbb{P}(X = x_i) \\quad \\text{(discrète)}\n\\] \\[\n\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_X(x) \\, dx \\quad \\text{(continue)}\n\\]\nVariance : \\[\n\\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2]\n\\]\n\nCes concepts sont fondamentaux en probabilités et en statistiques pour modéliser et analyser des phénomènes aléatoires."
  },
  {
    "objectID": "Mathématiques.html#algèbre-linéaire",
    "href": "Mathématiques.html#algèbre-linéaire",
    "title": "Prérequis des mathématiques",
    "section": "Algèbre Linéaire",
    "text": "Algèbre Linéaire\nNous allons vous rappeler les notions essentielles à connaître sur les matrices."
  },
  {
    "objectID": "Mathématiques.html#trace-dune-matrice",
    "href": "Mathématiques.html#trace-dune-matrice",
    "title": "Prérequis des mathématiques",
    "section": "Trace d’une matrice",
    "text": "Trace d’une matrice\n\nLa trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés : - La trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\] - Invariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\n\nNote\n\n\n\nLa trace d’une matrice ne change pas lorsqu’on change de base.\n\n\n\nDéterminant d’une matrice\n\nLe déterminant d’une matrice \\(A \\in \\mathcal{M}_{n\\times n}\\) peut être calculé en utilisant le développement par rapport à une ligne ou une colonne : \\[\\text{det}(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\text{det}(A_{ij})\\] où (\\(A_{ij}\\)) est la matrice obtenue en supprimant la (\\(i\\))-ème ligne et la (\\(j\\))-ème colonne de (\\(A\\)).\n\n\n\n\n\n\n\nTip\n\n\n\nDans certains cas, il peut être long de calculer le déterminant d’une matrice. Pour remédier à cela, il est utile de connaître par coeur le calcul d’un déterminant d’une matrice de taille \\(2 \\times 2\\) et d’une matrice diagonale.\n\n\n\n\nDéterminant d’une matrice \\((2 \\times 2)\\)\nPour une matrice \\(A \\in \\mathcal{M}_{2 \\times 2}\\) de la forme : \\[A = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)\\] le déterminant se calcule en utilisant la formule suivante : \\[\\text{det}(A) = ad - bc \\]\n\n\nDéterminant d’une matrice diagonale\nPour une matrice diagonale de la forme : \\[D =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)\n\\] le déterminant est le produit des éléments diagonaux : \\[\\text{det}(D) = d_1 \\times d_2 \\times \\cdots \\times d_n\\]\nLes déterminants sont particulièrement utiles en algèbre linéaire pour déterminer si une matrice est inversible (une matrice est inversible si et seulement si son déterminant est non nul) et pour résoudre des systèmes d’équations linéaires."
  },
  {
    "objectID": "Mathématiques.html#espace-euclidien",
    "href": "Mathématiques.html#espace-euclidien",
    "title": "Prérequis des mathématiques",
    "section": "Espace Euclidien",
    "text": "Espace Euclidien\n\nUn espace euclidien est un espace vectoriel réel de dimension finie muni d’une forme bilinéaire symétrique définie positive, appelée produit scalaire : \\[\\langle x, y \\rangle = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n\\]\n\nQuelques propriétés importantes du produit scalaire : - \\(\\langle v, v \\rangle = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\) - \\(\\langle v, w \\rangle = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle = \\langle w, v \\rangle\\) - \\(\\langle v, w \\rangle = 0 \\iff v \\perp w\\)\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leq \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leq \\|x\\| + \\|y\\|\\]"
  },
  {
    "objectID": "Mathématiques.html#orthogonalité",
    "href": "Mathématiques.html#orthogonalité",
    "title": "Prérequis des mathématiques",
    "section": "Orthogonalité",
    "text": "Orthogonalité\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) associé à la norme euclidienne \\(\\|\\cdot\\|_2\\).On note \\(v = (v_1, \\ldots, v_n)^t\\) et \\(w = (w_1, \\ldots, w_n)^t\\) où $ v_i$ et \\(w_j\\) sont des scalaires (i.e. des réels).\n\nNormalisation d’un vecteur\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|x\\|_2 = 1\\). Un espace vectoriel engendré par \\(v_1, \\ldots, v_p\\) est identique à celui engendré par leurs versions normalisées.\nDeux vecteurs \\(x\\) et \\(y\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle x, y \\rangle = 0\\] Une base orthonormale est une base où tous les vecteurs sont orthogonaux et de norme 1.\n\n\nMatrice de Projection Orthogonale\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\nPropriétés\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\n\\Pi_{W^\\perp} B = B - \\Pi_{W} B\n\\]\n\n\n\nConstruction de matrice de projection Orthogonale\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leq n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(W = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection \\(W\\) de \\(\\mathbb{R}^n\\) sur \\(W\\) est : \\[\nW = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de \\(W\\), alors : \\[\nW = V V^t\n\\]"
  },
  {
    "objectID": "Mathématiques.html#procédé-dorthogonalisation-de-gram-schmidt",
    "href": "Mathématiques.html#procédé-dorthogonalisation-de-gram-schmidt",
    "title": "Prérequis des mathématiques",
    "section": "Procédé d’orthogonalisation de Gram-Schmidt",
    "text": "Procédé d’orthogonalisation de Gram-Schmidt\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\n\n\n\n\n\n\nTip\n\n\n\nAvant de recourir au procédé de Gram-Schmidt, il faut s’assurer que les vecteurs ne soient pas déjà orthogonaux, cela serait une perte de temps de les recalculer. Ce calcul est long, il faut bien prendre son temps pour le faire et ne pas se précipiter.\n\n\nÉtapes du Procédé\nLe premier vecteur orthogonal ( u_1 ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où \\(( k \\geq 2 )\\)), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]"
  },
  {
    "objectID": "Mathématiques.html#base-duale",
    "href": "Mathématiques.html#base-duale",
    "title": "Prérequis des mathématiques",
    "section": "Base duale",
    "text": "Base duale\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite."
  },
  {
    "objectID": "Mathématiques.html#diagonalisation-dune-matrice",
    "href": "Mathématiques.html#diagonalisation-dune-matrice",
    "title": "Prérequis des mathématiques",
    "section": "Diagonalisation d’une matrice",
    "text": "Diagonalisation d’une matrice\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\]\n\\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\)\n\n\nDiagonalisation d’une matrice symétrique réelle\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\] où \\(Q\\) est une matrice orthogonale.\n\n\n\n\n\n\nWarning\n\n\n\nPour que la propriété soit vérifiée, il est essentiel que la matrice soit réelle, c’est-à-dire sans composantes complexes. En effet, la symétrie d’une matrice complexe n’implique pas nécessairement la propriété en question"
  },
  {
    "objectID": "Mathématiques.html#définitions",
    "href": "Mathématiques.html#définitions",
    "title": "Prérequis des mathématiques",
    "section": "Définitions",
    "text": "Définitions\n\nCovariance : La covariance entre deux variables \\(X\\) et \\(Y\\) mesure la manière dont deux variables varient ensemble. Elle est donnée par deux formules :\n\n\nPour un échantillon de données : \\[\n\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n\\] où \\(x_i\\) et \\(y_i\\) sont les valeurs des échantillons, et \\(\\bar{x}\\) et \\(\\bar{y}\\) sont les moyennes des échantillons.\nPour des variables aléatoires : \\[\n\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n\\] où \\(\\mathbb{E}[X]\\) et \\(\\mathbb{E}[Y]\\) sont les espérances (moyennes théoriques) des variables aléatoires \\(X\\) et \\(Y\\).\n\n\nRégression linéaire:\n\nLa régression linéaire est une méthode statistique qui permet de modéliser la relation entre deux variables en ajustant une ligne droite à un ensemble de données. L’équation de la régression linéaire est : \\[\ny = a + bx\n\\] où \\(y\\) est la variable dépendante, \\(x\\) est la variable indépendante, \\(a\\) est l’ordonnée à l’origine (l’interception de la ligne avec l’axe des ordonnées), et \\(b\\) est la pente de la ligne (le taux de changement de \\(y\\) par rapport à \\(x\\))."
  },
  {
    "objectID": "M1SEP.html#algèbre-linéaire",
    "href": "M1SEP.html#algèbre-linéaire",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Rappelons les notions essentielles à connaître sur les matrices.\n\n\n\nLa trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés :\n\nLa trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\]\nInvariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\n\n\nNote\n\n\n\nLa trace d’une matrice ne change pas lorsqu’on change de base.\n\n\n\n\n\n\nLe déterminant d’une matrice \\(A \\in \\mathcal{M}_{n\\times n}\\) peut être calculé en utilisant le développement par rapport à une ligne ou une colonne : \\[\\text{det}(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\text{det}(A_{ij})\\] où (\\(A_{ij}\\)) est la matrice obtenue en supprimant la (\\(i\\))-ème ligne et la (\\(j\\))-ème colonne de (\\(A\\)).\n\n\n\n\n\n\n\nTip\n\n\n\nDans certains cas, il peut être long de calculer le déterminant d’une matrice. Pour remédier à cela, il est utile de connaître par coeur le calcul d’un déterminant d’une matrice de taille \\(2 \\times 2\\) et d’une matrice diagonale.\n\n\n\n\n\nPour une matrice \\(A \\in \\mathcal{M}_{2 \\times 2}\\) de la forme : \\[A = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)\\] le déterminant se calcule en utilisant la formule suivante : \\[\\text{det}(A) = ad - bc \\]\n\n\n\nPour une matrice diagonale de la forme : \\[D =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)\n\\] le déterminant est le produit des éléments diagonaux : \\[\\text{det}(D) = d_1 \\times d_2 \\times \\cdots \\times d_n\\]\nLes déterminants sont particulièrement utiles en algèbre linéaire pour déterminer si une matrice est inversible (une matrice est inversible si et seulement si son déterminant est non nul) et pour résoudre des systèmes d’équations linéaires. En algèbre, on définit un espace où les vecteurs appartiennent et on utilise le plus souvent un espace euclidien. C’est un espace où est rattaché une distance qu’on appelle produit scalaire. ### Espace euclidien\n\nUn espace euclidien est un espace vectoriel réel de dimension finie muni d’une forme bilinéaire symétrique définie positive, appelée produit scalaire : \\[\\langle x, y \\rangle = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n\\]\n\nQuelques propriétés importantes du produit scalaire : - \\(\\langle v, v \\rangle = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\) - \\(\\langle v, w \\rangle = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle = \\langle w, v \\rangle\\) - \\(\\langle v, w \\rangle = 0 \\iff v \\perp w\\)\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leq \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leq \\|x\\| + \\|y\\|\\]\n\n\n\n\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) associé à la norme euclidienne \\(\\|\\cdot\\|_2\\).On note \\(v = (v_1, \\ldots, v_n)^t\\) et \\(w = (w_1, \\ldots, w_n)^t\\) où $ v_i$ et \\(w_j\\) sont des scalaires (i.e. des réels).\n\n\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|x\\|_2 = 1\\). Un espace vectoriel engendré par \\(v_1, \\ldots, v_p\\) est identique à celui engendré par leurs versions normalisées.\nDeux vecteurs \\(x\\) et \\(y\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle x, y \\rangle = 0\\] Une base orthonormale est une base où tous les vecteurs sont orthogonaux et de norme 1.\n\n\n\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\n\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\n\\Pi_{W^\\perp} B = B - \\Pi_{W} B\n\\]\n\n\n\n\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leq n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(W = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection \\(W\\) de \\(\\mathbb{R}^n\\) sur \\(W\\) est : \\[\nW = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de \\(W\\), alors : \\[\nW = V V^t\n\\]\n\n\n\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\n\n\n\n\n\n\nTip\n\n\n\nAvant de recourir au procédé de Gram-Schmidt, il faut s’assurer que les vecteurs ne soient pas déjà orthogonaux, cela serait une perte de temps de les recalculer. Ce calcul est long, il faut bien prendre son temps pour le faire et ne pas se précipiter.\n\n\nÉtapes du Procédé\nLe premier vecteur orthogonal ( u_1 ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où \\(( k \\geq 2 )\\)), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]\n\n\n\n\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite.\n\n\n\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\]\n\\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\)\n\n\n\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\] où \\(Q\\) est une matrice orthogonale.\n\n\n\n\n\n\nWarning\n\n\n\nPour que la propriété soit vérifiée, il est essentiel que la matrice soit réelle, c’est-à-dire sans composantes complexes. En effet, la symétrie d’une matrice complexe n’implique pas nécessairement la propriété en question"
  },
  {
    "objectID": "M1SEP.html#trace-dune-matrice",
    "href": "M1SEP.html#trace-dune-matrice",
    "title": "DATA Camp M1",
    "section": "Trace d’une matrice",
    "text": "Trace d’une matrice\n\nLa trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés : - La trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\] - Invariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\n\nNote\n\n\n\nLa trace d’une matrice ne change pas lorsqu’on change de base."
  },
  {
    "objectID": "M1SEP.html#espace-euclidien",
    "href": "M1SEP.html#espace-euclidien",
    "title": "DATA Camp M1",
    "section": "Espace Euclidien",
    "text": "Espace Euclidien\n\nUn espace euclidien est un espace vectoriel réel de dimension finie muni d’une forme bilinéaire symétrique définie positive, appelée produit scalaire : \\[\\langle x, y \\rangle = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n\\]\n\nQuelques propriétés importantes du produit scalaire : - \\(\\langle v, v \\rangle = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\) - \\(\\langle v, w \\rangle = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle = \\langle w, v \\rangle\\) - \\(\\langle v, w \\rangle = 0 \\iff v \\perp w\\)\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leq \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leq \\|x\\| + \\|y\\|\\]"
  },
  {
    "objectID": "M1SEP.html#procédé-dorthogonalisation-de-gram-schmidt",
    "href": "M1SEP.html#procédé-dorthogonalisation-de-gram-schmidt",
    "title": "Prérequis des mathématiques",
    "section": "Procédé d’orthogonalisation de Gram-Schmidt",
    "text": "Procédé d’orthogonalisation de Gram-Schmidt\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\n\n\n\n\n\n\nTip\n\n\n\nAvant de recourir au procédé de Gram-Schmidt, il faut s’assurer que les vecteurs ne soient pas déjà orthogonaux, cela serait une perte de temps de les recalculer. Ce calcul est long, il faut bien prendre son temps pour le faire et ne pas se précipiter.\n\n\nÉtapes du Procédé\nLe premier vecteur orthogonal ( u_1 ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où \\(( k \\geq 2 )\\)), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]"
  },
  {
    "objectID": "M1SEP.html#base-duale",
    "href": "M1SEP.html#base-duale",
    "title": "DATA Camp M1",
    "section": "Base duale",
    "text": "Base duale\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite."
  },
  {
    "objectID": "M1SEP.html#diagonalisation-dune-matrice",
    "href": "M1SEP.html#diagonalisation-dune-matrice",
    "title": "DATA Camp M1",
    "section": "Diagonalisation d’une matrice",
    "text": "Diagonalisation d’une matrice\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\]\n\\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\)\n\n\nDiagonalisation d’une matrice symétrique réelle\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\] où \\(Q\\) est une matrice orthogonale.\n\n\n\n\n\n\nWarning\n\n\n\nPour que la propriété soit vérifiée, il est essentiel que la matrice soit réelle, c’est-à-dire sans composantes complexes. En effet, la symétrie d’une matrice complexe n’implique pas nécessairement la propriété en question"
  },
  {
    "objectID": "M1SEP.html#propriétés-3",
    "href": "M1SEP.html#propriétés-3",
    "title": "Prérequis des mathématiques",
    "section": "Propriétés",
    "text": "Propriétés\nLe produit est distributif par rapport à l’addition. C’est-à-dire : \\[\nA (B + C) = AB + AC \\quad \\text{et} \\quad (B + C)A = BA + CA\n\\]\nLe produit est associatif, c’est-à-dire : \\[\nABC = A(BC) = (AB)C\n\\]\nSi A est une matrice carrée d’ordre n, alors \\[A I_n = I_n A = A\\]\nLe produit de deux matrices peut être nul sans que l’une des deux matrices ne soit la matrice nulle, par exemple : \\[\n\\begin{bmatrix}\n1 & 2 \\\\\n2 & 4\n\\end{bmatrix} \\times\n\\begin{bmatrix}\n-2 & 10 \\\\\n1 & -5\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "M1SEP.html#orthogonalité-1",
    "href": "M1SEP.html#orthogonalité-1",
    "title": "Prérequis des mathématiques",
    "section": "Orthogonalité",
    "text": "Orthogonalité\nDeux vecteurs \\(x\\) et \\(y\\) sont dits orthogonaux si \\(\\langle x, y \\rangle = 0\\). On note \\(x \\perp y\\).\nUne famille de vecteurs \\(\\{x_i\\}\\) est dite orthogonale si tous ses vecteurs sont deux à deux orthogonaux. Toute famille orthogonale \\(\\{x_i\\}_{i=1}^p\\) vérifie le théorème de Pythagore : \\[\n\\left\\|\\sum_{i=1}^n x_i\\right\\|^2 = \\sum_{i=1}^n \\|x_i\\|^2\n\\]\nSoit \\(E\\) un espace muni d’un produit scalaire et \\(X\\) une partie de \\(E\\). On appelle orthogonal de \\(X\\) et on note \\(X^\\perp\\) l’ensemble : \\(X^\\perp = \\{y \\in E \\,|\\, \\forall x \\in X, \\langle x, y \\rangle = 0\\}\\).\nOn dit que \\(\\{e_i\\}_{i=1}^p\\) est une base orthonormée de \\(E\\) si et seulement si : - Si \\(a_1e_1 + a_2e_2 + \\ldots + a_ne_n = 0\\), alors \\(a_i = 0\\) pour tout \\(i \\in \\{1, \\ldots, n\\}\\).\n- Pour tout \\(x \\in E\\), il existe \\(a_1, a_2, \\ldots, a_n \\in \\mathbb{R}\\) tels que \\(x = a_1e_1 + a_2e_2 + \\ldots + a_ne_n\\).\n- \\(e_i\\) est orthogonal à \\(e_j\\) pour tout \\(i \\neq j\\).\n- Pour tout \\(i \\in \\{1, \\ldots, n\\}\\), \\(\\|e_i\\| = 1\\)."
  },
  {
    "objectID": "M1SEP.html#probabilités-1",
    "href": "M1SEP.html#probabilités-1",
    "title": "Prérequis des mathématiques",
    "section": "Probabilités",
    "text": "Probabilités\nSoit \\(E\\) un ensemble muni d’une tribu \\(T\\). On appelle probabilité toute application \\(P : T \\rightarrow \\mathbb{R}^+\\) telle que : - \\(P(\\emptyset) = 0\\) - Si \\((A_n)\\) est une suite d’éléments de \\(T\\) deux à deux disjoints alors : \\[P\\left(\\bigcup_n A_n\\right) = \\sum_n P(A_n).\\]"
  },
  {
    "objectID": "M1SEP.html#fonction-de-répartition-1",
    "href": "M1SEP.html#fonction-de-répartition-1",
    "title": "Prérequis des mathématiques",
    "section": "Fonction de répartition",
    "text": "Fonction de répartition\nUne variable aléatoire traduit le résultat d’une expérience aléatoire en nombre réel. La fonction de répartition transporte le calcul des probabilités concernant les réalisations de la variable aléatoire. C’est la fonction définie par : \\[F_X(x) = P(X \\leq x)\\] \nPour tout \\(x\\), \\(0 \\leq F_X(x) \\leq 1\\) \\(F_X\\) est une fonction croissante. \\(\\lim_{x \\to -\\infty} F_X(x) = 0\\) et \\(\\lim_{x \\to \\infty} F_X(x) = 1\\)"
  },
  {
    "objectID": "M1SEP.html#propriétés-4",
    "href": "M1SEP.html#propriétés-4",
    "title": "Prérequis des mathématiques",
    "section": "Propriétés",
    "text": "Propriétés\n \\[\n\\mathbb{E}(aX + bY) = a\\mathbb{E}(X) + b\\mathbb{E}(Y)\n\\] \\[\n\\mathbb{E}(a) = a\n\\]\n \\[\n\\text{Var}(aX) = a^2\\text{Var}(X)\n\\] \\[\n\\text{Var}(a) = 0\n\\] \\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\n\\] \\[\n\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\text{Cov}(X,Y)\n\\]\n \\[\n\\text{Cov}(X, Y) = \\text{Cov}(Y, X)\n\\] \\[\n\\text{Cov}(aX + b, cY + d) = ac\\text{Cov}(X, Y)\n\\] \\[\n\\text{Cov}(aX + bY, U) = a\\text{Cov}(X, U) + b\\text{Cov}(Y, U)\n\\] \\[\n\\text{Cov}(X, cU + dV) = c\\text{Cov}(X, U) + d\\text{Cov}(X, V)\n\\] \\[\n\\text{Cov}(aX + bY, cU + dV) = ac\\text{Cov}(X, U) + ad\\text{Cov}(X, V) + bc\\text{Cov}(Y, U) + bd\\text{Cov}(Y, V)\n\\]"
  },
  {
    "objectID": "M1SEP.html#définitions-1",
    "href": "M1SEP.html#définitions-1",
    "title": "DATA Camp M1",
    "section": "Définitions",
    "text": "Définitions\n\nMacroéconomie\n\n\n\n\n\nLa macroéconomie est l’étude économique d’un système ou de phénomènes à un niveau global de l’économie.\n\n\nMicroéconomie\nLa microéconomie se concentre sur l’observation et l’analyse des interactions à petite échelle.\n\n\nBien économique\n“Chose utile à satisfaire un besoin, il faut que le bien soit disponible et en quantité limitée.\nUn bien non économique est un bien qui s’obtient gratuitement, comme l’oxygène, contrairement à un bien économique qui s’obtient en payant.”\n\n\nAgent économique\n“Un agent économique est un individu ou un groupe d’individus constituant un centre de décision économique indépendant.”\n\n\nMarché\n\n\n\n\n\n“Le marché c’est une institution sociale qui permet l’échange entre l’offre et la demande.”\n\n\nAsymétrie d’information\n“L’asymétrie d’information concerne les situations où les agents d’un marché ne possèdent pas de la même information sur un produit que ce soit au sujet de ses qualités ou de ses défauts”\n\n\nConcurrence Pure et Parfaite\nLa CPP repose sur cinq fondements :\n\nL’Atomicité du marché\n\nExistence d’un grand nombre d’agent économique sur le marché, à tel un point que ni l’offre ni la demande ne peut exercer une action quelconque sur la production et les prix ;\n\nL’Homogénéité des produits\n\nLa préférence d’un produit à un autre du point de vue de l’acheteur se fait uniquement selon son prix ;\n\nLibre entrée et sortie sur le marché\n\nAucune firme ne peut s’opposer à l’arrivée d’un concurrent sur le marché, tout le monde est libre de l’intégrer ;\n\nLibre circulation des facteurs de production\n\nLes facteurs de production (capital et travail) doivent être libre de se déplacer librement sans obstacle d’une industrie à l’autre ;\n\nLa transparence de l’information\n\nOffreurs et demandeurs sont parfaitement conscient des caractéristiques et prix des produits.\n\n\nMonopole\n“Le monopole est une situation dans un marché où un vendeur fait face aux multitudes vendeurs.”\n\n\nSegmentation de marché\n“La segmentation de marché est un découpage du marché en groupes homogènes selon des critères spécifiques, que ce soit des critères démographiques ou bien géo-graphiques.”\n\n\nDiscrimination par les prix\n“La discrimination par les prix est le pouvoir de pratiquer des prix différents pour un même produit, peut s’appliquer sur la quantité ou bien selon la segmentation du marché.”\n\n\nUtilité\n“L’utilité mesure le bien-être liée à la consommation d’un bien.”\n\n\nActualisation\n“L’Actualisation est un calcul permettant de transformer une valeur future en une valeur présente.”\nQue vaut aujourd’hui les X euros que j’aurais demain ?\n\\[\nV_a = \\frac{V_f}{(1+i)^t}\n\\]\n\\[\nV_a : Valeur\\ Actuelle\n\\]\n\\[\nV_f : Valeur\\ future\n\\] \\[\ni : Taux\\ sans\\ risque\\\\\n\\]\n\\[\nt : Temps\n\\]\n\n\nProblèmes macroéconomiques\nIl existe 4 grands problèmes macroéconomiques :\n\nCrises et récessions Ralentissement et/ou régression de l’activité économique ;\nInflations Augmentation générale et durable du niveau des prix entraînant une perte du pouvoir d’achat de la monnaie ;\nChômage Inactivité due au manque de travail ;\nProblème de l’équilibre extérieur Quand les importations sont plus importantes que les exportations, la balance commerciale est déséquilibrée."
  },
  {
    "objectID": "M1SEP.html#déterminant-dune-matrice",
    "href": "M1SEP.html#déterminant-dune-matrice",
    "title": "DATA Camp M1",
    "section": "Déterminant d’une matrice",
    "text": "Déterminant d’une matrice\n\nLe déterminant d’une matrice \\(A \\in \\mathcal{M}_{n\\times n}\\) peut être calculé en utilisant le développement par rapport à une ligne ou une colonne : \\[\\text{det}(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\text{det}(A_{ij})\\] où (\\(A_{ij}\\)) est la matrice obtenue en supprimant la (\\(i\\))-ème ligne et la (\\(j\\))-ème colonne de (\\(A\\)).\n\n\n\n\n\n\n\nTip\n\n\n\nDans certains cas, il peut être long de calculer le déterminant d’une matrice. Pour remédier à cela, il est utile de connaître par coeur le calcul d’un déterminant d’une matrice de taille \\(2 \\times 2\\) et d’une matrice diagonale."
  },
  {
    "objectID": "M1SEP.html#déterminant-dune-matrice-2-times-2",
    "href": "M1SEP.html#déterminant-dune-matrice-2-times-2",
    "title": "DATA Camp M1",
    "section": "Déterminant d’une matrice \\((2 \\times 2)\\)",
    "text": "Déterminant d’une matrice \\((2 \\times 2)\\)\nPour une matrice \\(A \\in \\mathcal{M}_{2 \\times 2}\\) de la forme : \\[A = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)\\] le déterminant se calcule en utilisant la formule suivante : \\[\\text{det}(A) = ad - bc \\]"
  },
  {
    "objectID": "M1SEP.html#déterminant-dune-matrice-diagonale",
    "href": "M1SEP.html#déterminant-dune-matrice-diagonale",
    "title": "DATA Camp M1",
    "section": "Déterminant d’une matrice diagonale",
    "text": "Déterminant d’une matrice diagonale\nPour une matrice diagonale de la forme : \\[D =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)\n\\] le déterminant est le produit des éléments diagonaux : \\[\\text{det}(D) = d_1 \\times d_2 \\times \\cdots \\times d_n\\]\nLes déterminants sont particulièrement utiles en algèbre linéaire pour déterminer si une matrice est inversible (une matrice est inversible si et seulement si son déterminant est non nul) et pour résoudre des systèmes d’équations linéaires."
  },
  {
    "objectID": "M1SEP.html#fondements-de-probabilités-niveau-basique",
    "href": "M1SEP.html#fondements-de-probabilités-niveau-basique",
    "title": "DATA Camp M1",
    "section": "Fondements de probabilités : niveau basique",
    "text": "Fondements de probabilités : niveau basique\n\nMoments\n\nL’espérance d’une variable aléatoire est sa valeur attendue. C’est une mesure de localisation de la distribution.\nDans le cas discret : \\[E(X) = \\sum k \\cdot P(X = k)\\] \\[k \\in X(\\Omega)\\] Alors que dans le cas continu : \\[E(X) = \\int x \\cdot f_X(x) \\, dx\\] \\[x \\in X(\\Omega)\\]\n \\[E(g(X)) = \\sum g(k) \\cdot P(X = k)\\] \\[\\forall k \\in X(\\Omega)\\] \\[E(g(X)) = \\int g(x) \\cdot f_X(x) \\, dx\\] \\[\\forall x \\in X(\\Omega)\\] \nLa variance d’une variable aléatoire décrit la dispersion de la variable aléatoire autour de sa valeur moyenne (son espérance).\nElle est définie par : \\[Var(X) = E(X^2) - (E(X))^2 = E((x - E(X))^2)\\] Sa racine carrée est appelée écart-type et notée généralement : \\[\\sigma(X) = \\sqrt{Var(X)}\\]\n\nLe centrage consiste à localiser la distribution autour de l’origine et la réduction consiste à normaliser la dispersion. La technique est simple : \\[Y = \\frac{X - E(X)}{\\sigma(X)}\\]\n\nLe moment d’ordre r est défini par : \\[\\mu_r = E(X^r)\\] Le moment centré d’ordre r est défini ainsi : \\[\\mũ_r = E((X - E(X))^r)\\]\n\n\nCouples aléatoires\nLa fonction conjointe \\[F_{X, Y}(x, y) = P(X \\leq x \\cap Y \\leq y)\\] est appelée la distribution conjointe de X et Y.\nDans le cas continu, la fonction définie par : \\[f_{X, Y}(x, y) = \\frac{\\partial^2 F_{X, Y}(x, y)}{\\partial x \\partial y}\\] est la densité conjointe du couple (X, Y). On a donc : \\[F_{X, Y}(x, y) = \\int \\int f_{X, Y}(t, u) \\, dt \\, du, \\text{ où } -\\infty &lt; x, y &lt; +\\infty,\\]\nDans le cas discret, on définit la fonction de probabilité conjointe : \\[P(X = x_i, Y = y_j) = p_{ij}\\] On a donc : \\[F_{X, Y}(x, y) = \\sum \\sum p_{ij}, \\text{ où } x_i \\leq x \\text{ et } y_j \\leq y\\]\n\nLa loi marginale de X est définie comme suit : \\[f_X(x) = \\int f_{X, Y}(x, y) \\, dy, \\text{ où } -\\infty &lt; x &lt; \\infty,\\] dans le cas continu, ou encore : \\[f_X(x_i) = \\sum p_{ij}, \\text{ où } j \\text{ tel que } y_j \\leq y\\]\nSi X et Y sont indépendants, alors : \\[f_{X, Y}(x, y) = f_X(x) \\cdot f_Y(y)\\]\n\nLa covariance mesure l’intensité de la relation linéaire entre deux variables aléatoires X et Y. Elle est définie comme suit : \\[Cov(X, Y) = E(XY) - E(X) \\cdot E(Y)\\]\nSi X et Y sont indépendants, alors : \\[Cov(X, Y) = 0\\]"
  },
  {
    "objectID": "M1SEP.html#statistiques-descriptives-univariées",
    "href": "M1SEP.html#statistiques-descriptives-univariées",
    "title": "DATA Camp M1",
    "section": "Statistiques descriptives univariées",
    "text": "Statistiques descriptives univariées\n\nLa moyenne arithmétique d’une série de valeurs \\(x_1, x_2, \\ldots, x_n\\) est donnée par : \\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\nLa médiane est la valeur qui sépare la série en deux parties égales. Pour une série ordonnée, si \\(n\\) est impair, la médiane est la valeur centrale. Si \\(n\\) est pair, c’est la moyenne des deux valeurs centrales.\nLa variance est une mesure de la dispersion des valeurs autour de la moyenne : \\[\\sigma_x^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\\]\nL’écart-type est la racine carrée de la variance : \\[\\sigma = \\sqrt{\\sigma_x^2}\\]\n\n\n\n\n\n\n\nNote\n\n\n\nPlus l’écart-type est grand, plus les données sont dispersées autour de la moyenne.\n\n\nLes statistiques descriptives univariées sont essentielles pour résumer et comprendre les caractéristiques principales d’une seule variable. Elles sont largement utilisées en analyse de données pour obtenir une vue d’ensemble rapide et efficace. Elles permettent aussi d’identifier rapidement des valeurs extrêmes."
  },
  {
    "objectID": "M1SEP.html#statistiques-descriptives-bivariées",
    "href": "M1SEP.html#statistiques-descriptives-bivariées",
    "title": "DATA Camp M1",
    "section": "Statistiques descriptives bivariées",
    "text": "Statistiques descriptives bivariées\n\nDéfinitions\n\nLes nuages de points (ou diagrammes de dispersion) sont une méthode graphique utilisée pour observer la relation entre deux variables quantitatives. Chaque point du graphique représente une paire de valeurs \\((x,y)\\) pour ces deux variables. Ce type de graphique permet de visualiser des tendances, des corrélations (positives, négatives ou nulles), ainsi que la présence d’éventuelles anomalies ou valeurs aberrantes. Si les points semblent s’aligner le long d’une ligne droite, cela peut indiquer une relation linéaire entre les deux variables.\nLes boxplots (ou boîtes à moustaches) sont un autre outil graphique, souvent utilisé pour représenter la distribution d’une variable quantitative en fonction d’une variable qualitative. Ils montrent la médiane, les quartiles, ainsi que les valeurs extrêmes ou aberrantes d’un jeu de données. Dans un boxplot, la boîte représente l’intervalle interquartile (de Q1 à Q3), la ligne médiane à l’intérieur de la boîte représente la médiane de la distribution, et les moustaches s’étendent jusqu’aux valeurs non aberrantes les plus extrêmes. Ces graphiques sont utiles pour comparer rapidement la dispersion et la symétrie des distributions entre différentes catégories d’une variable qualitative."
  },
  {
    "objectID": "M1SEP.html#fondements-de-probabilités",
    "href": "M1SEP.html#fondements-de-probabilités",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Les variables \\(X_1, \\ldots, X_n\\) sont deux à deux indépendantes si et seulement si : \\(\\forall i \\neq j, X_i\\) et \\(X_j\\) sont indépendantes.\n\nLes variables \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes si et seulement si : \\[P(X_1 = x_1, \\ldots, X_n = x_n) = P(X_1 = x_1) \\times \\ldots \\times P(X_n = x_n)\\]\n\nSi \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes, alors pour toute famille de fonctions réelles \\(f_i\\), on a : \\((f_1(X_1), \\ldots, f_n(X_n))\\) sont indépendantes.\n\nSoit \\(X = (X_1, \\ldots, X_n)^T\\) un vecteur aléatoire. Dans le cas multidimensionnel, l’espérance scalaire est remplacée par un vecteur espérance. \\[E(X) = (E(X_1), \\ldots, E(X_n))^T\\]\nLa variance unidimensionnelle est remplacée par la matrice symétrique de variance-covariance. Elle contient les variances en diagonale et les covariances ailleurs. On la note généralement \\(\\Sigma_X\\). \\[\\Sigma_X = \\begin{bmatrix}\nV(X_1) & \\ldots & \\text{Cov}(X_1, X_n) \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(X_n, X_1) & \\ldots & V(X_n)\n\\end{bmatrix}\\]\n\n\n\nSi l’on pense à des données, vues comme réalisation de variables aléatoires \\(X_1, \\ldots, X_n\\), il serait intéressant de se poser la question de savoir comment évolue cette suite lorsque \\(n\\) tend vers l’infini.\nOn dit que \\((X_n)\\) converge presque sûrement vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p.s.}} X\\) si et seulement si : \\(P\\left(\\lim_{{n\\to+\\infty}} X_n = X\\right) = 1\\)\nOn dit que \\((X_n)\\) converge en probabilité vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p}} X\\) si et seulement si : \\(\\forall \\varepsilon &gt; 0, \\quad P(|X_n - X| &gt; \\varepsilon) \\rightarrow 0\\)\nOn dit que \\((X_n)\\) converge en loi vers \\(X\\) et on note \\(X_n \\xrightarrow{\\mathcal{L}} X\\) si et seulement si : \\(F_{X_n} \\xrightarrow{n \\to +\\infty} F_X\\) Où \\(F_X\\) dénote la fonction de répartition de \\(X\\).\nOn dit que \\((X_n)\\) converge en moyenne quadratique vers \\(X\\) et on note \\(X_n \\xrightarrow{m.q.} X\\) si et seulement si : \\(\\mathbb{E}((X_n - X)^2) \\rightarrow 0\\) Cette définition peut se généraliser jusqu’à l’ordre \\(n\\), mais nous n’en aurons pas besoin.\n\n\n\n\n\n\n\n\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\) alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p} \\mu \\]\n\n\n\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p.s.} \\mu\\]\n\n\n\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors : \\[\\sqrt{n}\\frac{\\overline{X}_n - \\mu}{\\sigma} \\xrightarrow{\\mathcal{Loi}} \\mathcal{N}(0, 1)\\]"
  },
  {
    "objectID": "M1SEP.html#statistique-inférentielle-niveau-basique",
    "href": "M1SEP.html#statistique-inférentielle-niveau-basique",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Le point de départ est un vecteur (ou un tableau dans le cas multidimensionnel) de données. Ces données peuvent être vues comme les réalisations \\((x_1, x_2, \\ldots, x_n)\\) d’une variable aléatoire \\(X\\) qui dépend d’un certain paramètre \\(\\theta\\) que nous allons chercher à estimer. Pour ce faire, nous allons construire un échantillon de cette variable. Un échantillon \\((X_1, X_2, \\ldots, X_n)\\) est un n-uplet de variables aléatoires indépendantes qui suivent toutes la même loi (celle de \\(X\\)). Un estimateur de \\(\\theta\\) est une fonction \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) de notre échantillon, qui possède une loi de probabilité. Lorsque l’aléa est réalisé, \\(\\hat{\\theta}(\\omega) = f(x_1, x_2, \\ldots, x_n)\\) est une estimation de \\(\\theta\\). Le but de ce cours est de construire le meilleur estimateur possible de \\(\\theta\\).\n\n\n\nPour que l’estimation soit bonne, il faut que \\(\\hat{\\theta}\\) soit proche de \\(\\theta\\). Comme \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) est une variable aléatoire, on ne peut imposer de condition qu’à sa valeur moyenne.\nOn définit ainsi le biais : \\[b_n(\\hat{\\theta}, \\theta) = \\mathbb{E}(\\hat{\\theta}_n) - \\theta\\]\nUn estimateur est dit sans biais si \\(b_n(\\hat{\\theta}, \\theta) = 0\\), c’est-à-dire : \\[\\mathbb{E}(\\hat{\\theta}_n) = \\theta\\]\n\n\n\nUn estimateur est dit convergent s’il converge en probabilité vers le paramètre à estimer : \\[\\hat{\\theta}_n \\xrightarrow{P} \\theta\\]\nEn pratique, tout estimateur sans biais et dont la variance tend vers 0 est convergent.\n\n\n\nLa qualité d’un estimateur est mesurée à travers son erreur quadratique moyenne définie par : \\[EQM(\\hat{\\theta}_n) = (b_n(\\hat{\\theta}, \\theta))^2 + V(\\hat{\\theta}_n)\\] Comme nous cherchons tout le temps (presque) des estimateurs sans biais, il reste à comparer les variances.\nUn estimateur 𝜃̂1 est meilleur que 𝜃̂2 si : \\[V(\\hat{\\theta}_1) &lt; V(\\hat{\\theta}_2)\\]\n\nOn définit la quantité d’information apportée par l’estimateur par : \\[\nI(\\hat{\\theta}_n) = -\\left( \\mathbb{E} \\left( \\frac{\\partial L}{\\partial \\theta} \\right) \\right)^2\n\\] Où 𝐿(𝑥, 𝜃) = ∏ 𝑓(𝑥𝑖) (nous reviendrons sur sa définition)\nL’inégalité de Rao-Cramer postule que la variance d’un estimateur ne peut pas aller en delà d’un certain seuil : \\[V(\\hat{\\theta}_n) \\geq \\frac{1}{I(\\hat{\\theta}_n)}\\] Un estimateur est optimal (ou efficace) si sa variance vérifie le cas d’égalité.\n\n\n\nUn estimateur est une valeur qu’on ne peut pas obtenir en théorie donc on essaye de l’estimer. Par exemple, on ne peut pas calculer l’espérence d’une série de données et donc pour essayer d’obtenir une valeur on calculer une estimation. On recours à plusieurs estimateurs tels que le maximum de vraisemblance ou bien la méthode des moments.\n\n\n\n\n\n\nNote\n\n\n\nLa méthode du maximum de vraisemblance est la plus souvent utilisé dans les modèles de prédiction.\n\n\n\nLa méthode du maximum de vraisemblance consiste à affecter \\(𝜃\\) la valeur qui maximise la probabilité d’observer \\((𝑥_1, 𝑥_2, … , 𝑥_𝑛)\\) lorsque l’aléa du vecteur \\((𝑋_1, 𝑋_2, … , 𝑋_𝑛)\\) tombe. Sans trop rentrer dans la théorie de la vraisemblance, nous allons présenter un algorithme en cinq étapes pour calculer cet estimateur (qui présente des propriétés assez séduisantes) :\n\nEtape 1 : Calculer la fonction de vraisemblance\nDans le cas continu : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} f(x_i)\\]\nDans le cas discret : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} P(X_i = x_i)\\]\nEtape 2 : Calculer le log-vraisemblance Il s’agit de calculer un maximum, ce qui revient à dériver. Il s’agit ici d’un produit de n facteurs, ce qui rend la dérivation assez coriace. La fonction logarithmique présente des propriétés assez sympas pour faciliter cette tâche.\nEtape 3 : Calculer la dérivée de la log-vraisemblance\nEtape 4 : Résoudre l’équation d’inconnue \\(𝜽\\)} \\[\\frac{\\partial (\\ln(L))}{\\partial \\theta} = 0 \\Rightarrow \\theta = \\theta_0\\]\nEtape 5: Vérifier qu’il s’agit d’un maximum.\nEn s’assurant que : \\[\\frac{\\partial^2 (\\ln(L))}{\\partial \\theta^2} &lt; 0\\]\n\nLa méthode des moments consiste à égaliser les moments théoriques (espérance, variance) à leurs équivalents empiriques et à en dégager une estimation ponctuelle.\n\nEn pratique, il faut résoudre l’(les) équation(s) : \\[\\mathbb{E}(X) = \\overline{X} \\text{ et } \\text{Var}(X) = S_n^2\\] avec : \\[\\overline{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\hspace{2cm}\nS_n^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\overline{X})^2\\]\nIl existe une autre méthode d’estimateurs qu’est la méthode des moindres carrés ordinaires.\n\nLorsqu’il s’agit de prendre une mesure 𝜃 avec un appareil doté d’une imprécision \\(𝜀\\), alors le problème d’estimation peut s’écrire : \\(𝑋 = 𝜃 + 𝜀\\). La méthode des moindres-carrés ordinaires consiste à trouver le paramètre \\(𝜃\\) qui minimise la somme des carrées des erreurs : \\[𝜃_{𝑀𝐶𝑂} = \\arg\\min \\left( \\sum_{i=0}^n \\varepsilon_i^2 \\right) = \\arg\\min \\left( \\sum_{i=0}^n (X_i - \\theta)^2 \\right)\\]\n\n\n\n\nUn intervalle de confiance [\\(A\\), \\(B\\)] de niveau \\(1 - \\alpha\\) est un intervalle aléatoire qui a la probabilité \\(1 - \\alpha\\) de contenir le paramètre à estimer \\(\\theta\\). Formellement, on écrit : \\(P (t_1 (\\theta) \\leq f(X_1, \\ldots, X_n) \\leq t_2 (\\theta)) = P(A \\leq \\theta \\leq B) = 1 - \\alpha\\)\n\n\n\nDans le cadre d’un test d’hypothèse, nous cherchons à faire valoir une hypothèse en dépit d’une autre, qui lui est contradictoire.\nOn appellera la première (celle dont le rejet à tort sera le plus préjudiciable) « Hypothèse nulle » et la deuxième « Hypothèse alternative ».\n\n\n\n\n\nLes calculs qui se cachent derrière le choix de l’hypothèse à garder sont compliqués. Mais BONNE NOUVELLE, la machine fera tour à notre place. Il suffit juste de suivre correctement la méthode :\nEtape 1 : Choisir judicieusement les hypothèses à évaluer et fixer le risque \\(𝛼\\)\nEtape 2 : Choisir le test adapté à la procédure\nEtape 3 : Rentrer la commande correspondante sur R et exécuter\nEtape 4: Lire dans les sorties la p-value. si elle est supérieure à α on conserve l’hypothèse nulle H0. Si elle lui est inférieure, on rejette H0 et on accepte l’hypothèse alternative H1.\n\n\n\nLes intervalles de confiance sont des outils essentiels en statistique pour estimer des paramètres inconnus tout en mesurant l’incertitude associée à cette estimation. Ci-dessous, vous trouverez un tableau présentant la construction des intervalles de confiance pour différents paramètres."
  },
  {
    "objectID": "M1SEP.html#concepts-de-base",
    "href": "M1SEP.html#concepts-de-base",
    "title": "DATA Camp M1",
    "section": "Concepts de base",
    "text": "Concepts de base\n\nMacroéconomie\n\n\n\n\n\nLa macroéconomie est l’étude économique d’un système ou de phénomènes à un niveau global de l’économie.\n\n\nMicroéconomie\nLa microéconomie se concentre sur l’observation et l’analyse des interactions à petite échelle.\n\n\nBien économique\n“Chose utile à satisfaire un besoin, il faut que le bien soit disponible et en quantité limitée.\nUn bien non économique est un bien qui s’obtient gratuitement, comme l’oxygène, contrairement à un bien économique qui s’obtient en payant.”\n\n\nAgent économique\n“Un agent économique est un individu ou un groupe d’individus constituant un centre de décision économique indépendant.”\n\n\nMarché\n\n\n\n\n\n“Le marché c’est une institution sociale qui permet l’échange entre l’offre et la demande.”\n\n\nAsymétrie d’information\n“L’asymétrie d’information concerne les situations où les agents d’un marché ne possèdent pas de la même information sur un produit que ce soit au sujet de ses qualités ou de ses défauts”\n\n\nExternalité\nL’externalité désigne la conséquence (positive ou négative) d’une activité d’un agent économique sur un autre, sans qu’aucun des deux ne reçoive ou ne paye une compensation pour cet effet.\n\n\nConcurrence Pure et Parfaite\nLa CPP repose sur cinq fondements :\n\nL’Atomicité du marché\n\nExistence d’un grand nombre d’agent économique sur le marché, à tel un point que ni l’offre ni la demande ne peut exercer une action quelconque sur la production et les prix ;\n\nL’Homogénéité des produits\n\nLa préférence d’un produit à un autre du point de vue de l’acheteur se fait uniquement selon son prix ;\n\nLibre entrée et sortie sur le marché\n\nAucune firme ne peut s’opposer à l’arrivée d’un concurrent sur le marché, tout le monde est libre de l’intégrer ;\n\nLibre circulation des facteurs de production\n\nLes facteurs de production (capital et travail) doivent être libre de se déplacer librement sans obstacle d’une industrie à l’autre ;\n\nLa transparence de l’information\n\nOffreurs et demandeurs sont parfaitement conscient des caractéristiques et prix des produits.\n\n\nMonopole\n“Le monopole est une situation dans un marché où un vendeur fait face aux multitudes vendeurs.”\n\n\nSegmentation de marché\n“La segmentation de marché est un découpage du marché en groupes homogènes selon des critères spécifiques, que ce soit des critères démographiques ou bien géo-graphiques.”\n\n\nDiscrimination par les prix\n“La discrimination par les prix est le pouvoir de pratiquer des prix différents pour un même produit, peut s’appliquer sur la quantité ou bien selon la segmentation du marché.”\n\n\nUtilité\n“L’utilité mesure le bien-être liée à la consommation d’un bien.”\n\n\nActualisation\n“L’Actualisation est un calcul permettant de transformer une valeur future en une valeur présente.”\nQue vaut aujourd’hui les X euros que j’aurais demain ?\n\\[\nV_a = \\frac{V_f}{(1+i)^t}\n\\]\n\\[\nV_a : Valeur\\ Actuelle\n\\]\n\\[\nV_f : Valeur\\ future\n\\] \\[\ni : Taux\\ sans\\ risque\\\\\n\\]\n\\[\nt : Temps\n\\]\n\n\nProblèmes macroéconomiques\nIl existe 4 grands problèmes macroéconomiques :\n\nCrises et récessions Ralentissement et/ou régression de l’activité économique ;\nInflations Augmentation générale et durable du niveau des prix entraînant une perte du pouvoir d’achat de la monnaie ;\nChômage Inactivité due au manque de travail ;\nProblème de l’équilibre extérieur Quand les importations sont plus importantes que les exportations, la balance commerciale est déséquilibrée."
  },
  {
    "objectID": "M2SEP.html#étapes-simples-pour-débuter",
    "href": "M2SEP.html#étapes-simples-pour-débuter",
    "title": "DATA Camp M2",
    "section": "Étapes simples pour débuter",
    "text": "Étapes simples pour débuter\n\nAccéder à l’éditeur VBA\n\nAllez dans Excel, puis activez l’onglet Développeur si nécessaire. Dans l’onglet développeur, cliquez sur Visual Basic pour ouvrir l’éditeur VBA.\n\n\n\nCréer une macro\n\nDans l’éditeur, insérez un module (Insertion &gt; Module). Vous pourrez y écrire votre code.\n\n\n\nÉcrire un exemple de macro\nCommencez par des tâches simples, comme écrire dans une cellule.\nExemple :\nSub first_macro()\n\n  Range(\"A1\").value = \"Test Macro\" ' Change la valeur de A1\n\nEnd Sub\nCe code dit à Excel : Change la valeur de la cellule A1 par ” Test Macro “.\n\n\nExécuter la macro\nRetournez dans Excel, appuyez sur Alt + F8, sélectionnez votre macro (first_macro) et cliquez sur Exécuter.\n\n\n\n\n\n\nTip\n\n\n\nCommencez par enregistrer une macro avec l’outil Enregistreur de macro d’Excel (dans l’onglet Développeur). Cela génère automatiquement du code VBA que vous pouvez observer et modifier pour apprendre."
  },
  {
    "objectID": "M2SEP.html#schumpeter-le-père-de-la-théorie-de-linnovation",
    "href": "M2SEP.html#schumpeter-le-père-de-la-théorie-de-linnovation",
    "title": "DATA Camp M2",
    "section": "Schumpeter, le père de la théorie de l’innovation",
    "text": "Schumpeter, le père de la théorie de l’innovation\nJoseph Schumpeter, économiste du 20ᵉ siècle, a expliqué comment l’innovation est le moteur principal de la croissance économique.\n\nRôle clé de l’innovation\n\nSchumpeter distingue plusieurs types d’innovations :\n\nNouveaux produits (ex. le smartphone).\nNouvelles méthodes de production (ex. impression 3D).\nNouveaux marchés (ex. l’économie numérique).\nNouvelles organisations (ex. chaînes logistiques).\n\n\n\n\nDestruction créatrice\n\nL’innovation bouleverse l’économie en rendant obsolètes certaines activités (par ex., le courrier papier remplacé par les emails) tout en créant de nouvelles opportunités.\nC’est ce processus de “destruction créatrice” qui renouvelle en permanence les structures économiques.\n\n\n\nLe rôle de l’entrepreneur\n\nSchumpeter place l’entrepreneur au centre de l’innovation. C’est lui qui prend des risques, introduit des changements, et stimule la concurrence."
  },
  {
    "objectID": "M2SEP.html#un-cercle-vertueux-léconomie-circulaire",
    "href": "M2SEP.html#un-cercle-vertueux-léconomie-circulaire",
    "title": "DATA Camp M2",
    "section": "Un cercle vertueux : l’économie circulaire",
    "text": "Un cercle vertueux : l’économie circulaire\nL’économie circulaire est un modèle économique qui cherche à limiter les déchets et à optimiser l’utilisation des ressources naturelles.\n\nPrincipe de base : réduire, réutiliser, recycler (3R)\n\nRéduire : Utiliser moins de matières premières.\nRéutiliser : Prolonger la vie des produits (ex. réparer un téléphone au lieu d’en acheter un neuf).\nRecycler : Transformer les déchets en nouvelles ressources (ex. plastique recyclé).\n\n\n\nBoucles fermées\n\nContrairement à l’économie traditionnelle (linéaire), où les ressources sont extraites, utilisées, puis jetées, l’économie circulaire fonctionne en boucle. Par exemple, une bouteille en verre peut être recyclée pour fabriquer une nouvelle bouteille.\nDans ce concept, les déchets des uns sont les matières premières des autres.\n\n\n\nAvantages\n\nMoins de déchets et de pollution.\nConservation des ressources naturelles.\nCréation de nouvelles activités (ex. recyclage, réparation, conception éco-responsable).\n\nL’économie circulaire cherche à innover en adoptant un modèle durable et respectueux de l’environnement, en transformant les déchets en ressources."
  },
  {
    "objectID": "M2SEP.html#la-gestion-de-projet-son-origine",
    "href": "M2SEP.html#la-gestion-de-projet-son-origine",
    "title": "DATA Camp M2",
    "section": "La gestion de projet : son origine",
    "text": "La gestion de projet : son origine\nOn situe les origines de la gestion de projet moderne au début du 20ᵉ siècle avec le Fordisme. Henry Ford révolutionne la production en introduisant le travail à la chaîne. Chaque étape est minutieusement planifiée pour maximiser la productivité. Toyota améliore le modèle fordiste avec des méthodes comme le “Juste à Temps” (JIT) et le “Kaizen” (amélioration continue). L’accent est mis sur la réduction des gaspillages et l’implication des équipes, ouvrant la voie à des concepts clés comme l’optimisation et la flexibilité.\nCet art est basé sur des concepts majeurs :\n\nDiagramme de Gantt\n\nUn outil visuel qui montre les tâches d’un projet, leur durée, et leur ordre.\nLes barres horizontales représentent les activités, permettant de suivre l’avancement.\nExemple :\n\n\n\n\n\n\nSource\n\n\nRoue de Deming (PCDA)\n\nUn cycle itératif pour l’amélioration continue :\n\nPlan (planifier) : Définir les objectifs et les actions nécessaires.\nDo (faire) : Exécuter le plan.\nCheck (vérifier) : Mesurer et analyser les résultats.\nAct (agir) : Ajuster et améliorer en fonction des retours.\n\nUtilisé pour garantir que chaque étape est maîtrisée et optimisée.\n\n\n\n\n\n\nSource\n\n\nLes 0 Olympiques (Objectif “Zéro”)\n\nInspiré du toyotisme, cela vise :\n\nZéro défaut : Produire sans erreur.\nZéro pannes : Maintenir régulièrement pour éviter les pannes.\nZéro papiers : Réduire les frais administratifs(monétaire et temporel).\nZéro délais : Minimiser les retards.\nZéro stocks : Éviter les surplus inutiles.\n\n\n\n\n\n\n\nSource\n\n\nMéthode des 5S (complément toyotiste)\n\nSeiri (Trier), Seiton (Ranger), Seiso (Nettoyer), Seiketsu (Standardiser), Shitsuke (Soutenir).\nUne méthode pour organiser efficacement les espaces de travail et garantir un environnement productif.\n\n\n\nChemin critique (Critical Path Method)\n\nAnalyse des tâches pour identifier celles qui déterminent la durée totale du projet.\nCela permet de se concentrer sur les étapes les plus critiques pour respecter les délais."
  },
  {
    "objectID": "M2SEP.html#une-application-cest-quoi",
    "href": "M2SEP.html#une-application-cest-quoi",
    "title": "DATA Camp M2",
    "section": "Une application, c’est quoi ?",
    "text": "Une application, c’est quoi ?\nUne application est un programme informatique conçu pour répondre à un besoin précis, comme envoyer des messages, faire des achats en ligne ou gérer des données. Elle est utilisée par des utilisateurs via des interfaces (smartphones, ordinateurs).\n\nComment ça marche ?\n\nFrontend (partie visible) :\nC’est l’interface que vous voyez et utilisez (boutons, formulaires, pages web). Elle est conçue pour être intuitive et agréable à utiliser.\nBackend (partie invisible) :\nC’est la “machinerie” qui fait fonctionner l’application. Elle traite les données, exécute les calculs et gère les demandes de l’utilisateur.\nExemple : Sur une page web d’achat en ligne, vous pouvez voir un bouton “Commander”, parfaitement mis en valeur pour que vous puissiez cliquer dessus sans trop chercher (frontend), quand vous cliquerez sur “Commander”, votre commande sera enregistrée et votre paiement validé (backend).\n\n\n\nPourquoi une application ?\nUne application est créée pour résoudre un problème ou simplifier une tâche, c’est une solution qui répond à un besoin, par exemple :\n\nCommander un repas sans avoir à se déplacer.\nGérer des rendez-vous professionnels.\nAnalyser des données dans une entreprise.\n\n\n\nPenser design et interface\nUne application bien conçue doit :\n\nÊtre simple à utiliser : l’utilisateur ne doit pas se perdre ou être frustré.\nÊtre agréable visuellement : des couleurs, polices et boutons clairs.\nS’adapter à tous les appareils : ordinateurs, smartphones, tablettes (design “responsive”).\n\nLa culture applicative, c’est comprendre qu’une application est une combinaison entre ce que l’utilisateur voit (frontend) et la technologie qui fonctionne en arrière-plan (backend), avec comme objectif de rendre la vie plus simple et agréable grâce à un bon design et une utilité claire."
  },
  {
    "objectID": "M2SEP.html#rigueur-est-mère-de-réussite-le-génie-logiciel",
    "href": "M2SEP.html#rigueur-est-mère-de-réussite-le-génie-logiciel",
    "title": "DATA Camp M2",
    "section": "Rigueur est mère de réussite : le génie logiciel",
    "text": "Rigueur est mère de réussite : le génie logiciel\nPour atteindre ses objectifs de façon rigoureuse, il est possible d’appliquer plusieurs concepts :\n\nLe software engineering (ou génie logiciel) est la discipline qui consiste à concevoir, développer, tester, et maintenir des logiciels de manière organisée et efficace.\n\n\nConception structurée\nAvant de coder, on planifie comment le logiciel va fonctionner (quelles sont ses fonctionnalités, sa structure). Cela inclut des étapes comme la création de diagrammes ou l’écriture d’un cahier des charges.\n\n\nBonnes pratiques de code\nÉcrire du code de qualité est crucial pour garantir que le logiciel soit lisible, réutilisable, et facile à maintenir. Voici quelques bonnes pratiques :\n\nDRY (Don’t Repeat Yourself) : Éviter de dupliquer le code ; si une fonctionnalité doit être réutilisée, elle doit être écrite une seule fois et utilisée partout.\nKISS (Keep It Simple, Stupid) : Rendre le code aussi simple que possible pour éviter des solutions inutiles ou complexes.\nSOLID : Ensemble de principes qui facilitent la conception orientée objet :\n\nS : Single Responsibility Principle (chaque classe doit avoir une seule responsabilité).\nO : Open/Closed Principle (le code doit être ouvert à l’extension mais fermé à la modification).\nL : Liskov Substitution Principle (les sous-classes doivent pouvoir remplacer leurs classes parentes).\nI : Interface Segregation Principle (les interfaces doivent être spécifiques à un usage).\nD : Dependency Inversion Principle (les modules de haut niveau ne doivent pas dépendre de modules de bas niveau, mais des abstractions).\n\nPEP8 (Python Enhancement Proposal) : Un guide de style pour écrire du code Python clair et lisible, couvrant des aspects comme les indentations, les noms de variables, et les espaces.\n\n\n\nStructurer un projet\nUn projet bien structuré est essentiel pour être déployable en production et maintenable dans le temps. Cela inclut :\n\nUne organisation claire des fichiers et des dossiers.\nUne séparation entre le code source, les tests, et la configuration.\nUne documentation complète expliquant le fonctionnement du logiciel et les étapes pour contribuer au projet.\n\n\n\nTests et qualité\nTester un logiciel garantit qu’il fonctionne correctement et répond aux besoins.\n\nTests unitaires : Vérifient des petites parties du code (ex. une seule fonction).\nTests d’intégration : Vérifient que différentes parties du code fonctionnent ensemble.\nAutomatisation des tests : Les outils comme pytest (en Python) permettent d’automatiser les tests pour gagner du temps.\n\nPour renforcer la qualité, on utilise des linters (ex. pylint, flake8) qui analysent le code pour repérer les erreurs de style ou de logique avant qu’elles ne causent des problèmes.\n\n\nCollaboration et gestion des versions\nLe développement logiciel est souvent un travail d’équipe. Des outils comme Git permettent de :\n\nGérer différentes versions du code.\nSuivre l’historique des modifications.\nCollaborer efficacement en évitant les conflits entre les contributions des développeurs.\n\n\n\nAdopter des patterns de design\nLes design patterns sont des solutions éprouvées pour résoudre des problèmes fréquents de conception logicielle. Par exemple :\n\nSingleton : Garantir qu’une classe n’ait qu’une seule instance.\nFactory : Centraliser la création d’objets complexes.\nObserver : Réagir aux changements d’état dans un système.\n\n\n\nLe Zen of Python\nUne philosophie de développement Python, illustrée par des principes comme :\n\n“Beautiful is better than ugly” (un code lisible est préférable).\n“Simple is better than complex” (la simplicité est essentielle).\n“Errors should never pass silently” (les erreurs doivent être explicites).\n\n\nCes pratiques sont essentielles pour concevoir des logiciels efficaces, maintenables et collaboratifs.\nPour conclure, le génie logiciel, c’est comme construire une maison : il faut des plans solides, des matériaux adaptés (le code), un contrôle qualité (tests), et un design qui facilite les rénovations futures (maintenance)."
  },
  {
    "objectID": "M2SEP.html#commencer-sur-de-bonnes-bases-python",
    "href": "M2SEP.html#commencer-sur-de-bonnes-bases-python",
    "title": "DATA Camp M2",
    "section": "Commencer sur de bonnes bases : Python",
    "text": "Commencer sur de bonnes bases : Python\n\nLes fonctions\nUne fonction est un bloc de code qui effectue une tâche spécifique. Vous pouvez la réutiliser plusieurs fois.\nExemple :\ndef dire_bonjour(nom):\n    return f\"Bonjour, {nom} !\"\n\nprint(dire_bonjour(\"Alice\"))\nIci, la fonction dire_bonjour prend un nom et retourne un message personnalisé.\n\n\nTests unitaires\nLes tests unitaires permettent de vérifier qu’une partie précise de votre code (comme une fonction) fonctionne correctement.\nExemple avec la bibliothèque unittest :\nimport unittest\n\ndef addition(a, b):\n    return a + b\n\nclass TestAddition(unittest.TestCase):\n    def test_positif(self):\n        self.assertEqual(addition(2, 3), 5)\n\nif __name__ == \"__main__\":\n    unittest.main()\nCela permet de détecter les erreurs dès que le code change.\n\n\nObjets et classes (programmation orientée objet)\nPython permet de créer des classes, des “modèles” pour structurer vos données et comportements.\n\nExemple :\nclass Animal:\n    def __init__(self, nom):\n        self.nom = nom\n\n    def parler(self):\n        return f\"{self.nom} fait un bruit.\"\n\nchien = Animal(\"Rex\")\nprint(chien.parler())  # Rex fait un bruit.\n\nUne classe regroupe des données (nom) et des comportements (parler).\n\n\nEnvironnements virtuels (avec Docker)\nUn environnement virtuel permet d’isoler les dépendances (bibliothèques, versions de Python) d’un projet pour éviter les conflits avec d’autres projets.\n\nAvec Python :\n\npython -m venv mon_env\nsource mon_env/bin/activate  # Active l'environnement\npip install numpy            # Installe une bibliothèque uniquement pour cet environnement\n\nAvec Docker (outil pour des environnements plus complexes) :\nDocker crée des conteneurs, qui isolent tout un système (pas seulement Python).\nExemple d’un fichier Dockerfile :\n\nFROM python:3.9\nWORKDIR /app\nCOPY . .\nRUN pip install -r requirements.txt\nCMD [\"python\", \"main.py\"]\nCela garantit que votre application fonctionnera partout de la même manière.\nEn résumé, maîtriser ces bases vous aide à écrire un code réutilisable, fiable, et bien organisé, tout en travaillant dans des environnements adaptés."
  },
  {
    "objectID": "M2SEP.html#plus-on-est-de-pro-plus-on-rit",
    "href": "M2SEP.html#plus-on-est-de-pro-plus-on-rit",
    "title": "DATA Camp M2",
    "section": "Plus on est de pro, plus on rit",
    "text": "Plus on est de pro, plus on rit\nDe votre rôle de professionnel de la donnée, dans les projets, vous serez amenez à travailler avec divers métiers, il est important de comprendre les fonctionnements et les missions de vos futurs collaborateurs.\nParmi ces individus avec lesquels vous allez collaborer fréquemment :\nLe Product Manager (PM)\n\nRôle : Définit la stratégie et les objectifs d’un produit ou d’un projet en s’appuyant sur des analyses de données.\nCollaboration : Il travaille avec des data scientists et data analysts pour comprendre les tendances utilisateurs et prendre des décisions stratégiques basées sur les données.\n\nLe Développeur Backend\n\nRôle : Construit les systèmes qui collectent et rendent accessibles les données (APIs, bases de données).\nCollaboration : Il travaille avec les data engineers pour intégrer les pipelines de données et avec les data scientists pour fournir les données nécessaires à leurs analyses.\n\nLe Développeur Frontend\n\nRôle : Développe des interfaces utilisateur (sites web, tableaux de bord, applications) pour visualiser ou interagir avec les données.\nCollaboration : Il travaille avec des data analysts et des business intelligence analysts pour présenter les données de manière compréhensible et esthétique.\n\nLe Spécialiste en Cybersécurité\n\nRôle : Protège les systèmes et les données contre les attaques et les intrusions.\nCollaboration : Il s’associe à des data governance specialists et des data engineers pour sécuriser les pipelines de données et garantir la conformité aux régulations.\n\nLe Cloud Architect\n\nRôle : Conçoit les infrastructures cloud pour héberger et traiter les données à grande échelle.\nCollaboration : Il travaille avec des data engineers et des big data engineers pour s’assurer que les systèmes cloud répondent aux besoins de stockage et de calcul.\n\nLe Consultant en Transformation Digitale\n\nRôle : Aide les entreprises à intégrer les données dans leurs processus décisionnels et leurs outils numériques.\nCollaboration : Il collabore avec des chief data officers, data scientists et business intelligence analysts pour orienter les projets.\n\nL’UX Designer (Designer d’expérience utilisateur)\n\nRôle : Conçoit des interfaces utilisateur et des parcours fluides en se basant sur les données utilisateurs.\nCollaboration : Il utilise les insights des data analysts et des product managers pour optimiser l’expérience utilisateur.\n\nL’Ingénieur DevOps\n\nRôle : Automatise et optimise le déploiement des applications, y compris les modèles d’apprentissage automatique ou les systèmes de traitement de données.\nCollaboration : Il travaille avec les machine learning engineers et data engineers pour déployer les solutions en production.\n\nL’Analyste Marketing\n\nRôle : Utilise les données pour mesurer l’efficacité des campagnes publicitaires et comprendre le comportement des clients.\nCollaboration : Il collabore avec les data analysts et les business intelligence analysts pour extraire et interpréter les métriques marketing.\n\nLe Responsable de la Conformité (Compliance Officer)\n\nRôle : S’assure que l’entreprise respecte les lois et régulations liées aux données (comme le RGPD).\nCollaboration : Il travaille avec les data governance specialists pour encadrer l’usage des données de manière légale et éthique.\n\nCes métiers feront certainement parti de l’écosystème auquel vous appartiendrez et contribuerons à vos projets de près ou de loin."
  },
  {
    "objectID": "M1SEP.html#algèbre-linéaire-1",
    "href": "M1SEP.html#algèbre-linéaire-1",
    "title": "DATA Camp M1",
    "section": "Algèbre Linéaire",
    "text": "Algèbre Linéaire\nRappelons les notions essentielles à connaître sur les matrices.\n\nTrace d’une matrice\n\nLa trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés : - La trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\] - Invariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\n\nNote\n\n\n\nLa trace d’une matrice ne change pas lorsqu’on change de base.\n\n\n\n\nDéterminant d’une matrice\n\nLe déterminant d’une matrice \\(A \\in \\mathcal{M}_{n\\times n}\\) peut être calculé en utilisant le développement par rapport à une ligne ou une colonne : \\[\\text{det}(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\text{det}(A_{ij})\\] où (\\(A_{ij}\\)) est la matrice obtenue en supprimant la (\\(i\\))-ème ligne et la (\\(j\\))-ème colonne de (\\(A\\)).\n\n\n\n\n\n\n\nTip\n\n\n\nDans certains cas, il peut être long de calculer le déterminant d’une matrice. Pour remédier à cela, il est utile de connaître par coeur le calcul d’un déterminant d’une matrice de taille \\(2 \\times 2\\) et d’une matrice diagonale.\n\n\n\n\nDéterminant d’une matrice \\((2 \\times 2)\\)\nPour une matrice \\(A \\in \\mathcal{M}_{2 \\times 2}\\) de la forme : \\[A = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)\\] le déterminant se calcule en utilisant la formule suivante : \\[\\text{det}(A) = ad - bc \\]\n\n\nDéterminant d’une matrice diagonale\nPour une matrice diagonale de la forme : \\[D =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)\n\\] le déterminant est le produit des éléments diagonaux : \\[\\text{det}(D) = d_1 \\times d_2 \\times \\cdots \\times d_n\\]\nLes déterminants sont particulièrement utiles en algèbre linéaire pour déterminer si une matrice est inversible (une matrice est inversible si et seulement si son déterminant est non nul) et pour résoudre des systèmes d’équations linéaires. En algèbre, on définit un espace où les vecteurs appartiennent et on utilise le plus souvent un espace euclidien. C’est un espace où est rattaché une distance qu’on appelle produit scalaire. ### Espace euclidien\n\nUn espace euclidien est un espace vectoriel réel de dimension finie muni d’une forme bilinéaire symétrique définie positive, appelée produit scalaire : \\[\\langle x, y \\rangle = x_1 y_1 + x_2 y_2 + \\cdots + x_n y_n\\]\n\nQuelques propriétés importantes du produit scalaire : - \\(\\langle v, v \\rangle = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\) - \\(\\langle v, w \\rangle = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle = \\langle w, v \\rangle\\) - \\(\\langle v, w \\rangle = 0 \\iff v \\perp w\\)\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leq \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leq \\|x\\| + \\|y\\|\\]\n\n\n\nOrthogonalité\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) associé à la norme euclidienne \\(\\|\\cdot\\|_2\\).On note \\(v = (v_1, \\ldots, v_n)^t\\) et \\(w = (w_1, \\ldots, w_n)^t\\) où $ v_i$ et \\(w_j\\) sont des scalaires (i.e. des réels).\n\nNormalisation d’un vecteur\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|x\\|_2 = 1\\). Un espace vectoriel engendré par \\(v_1, \\ldots, v_p\\) est identique à celui engendré par leurs versions normalisées.\nDeux vecteurs \\(x\\) et \\(y\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle x, y \\rangle = 0\\] Une base orthonormale est une base où tous les vecteurs sont orthogonaux et de norme 1.\n\n\nMatrice de Projection Orthogonale\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\nPropriétés\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\n\\Pi_{W^\\perp} B = B - \\Pi_{W} B\n\\]\n\n\n\nConstruction de matrice de projection orthogonale\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leq n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(W = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection \\(W\\) de \\(\\mathbb{R}^n\\) sur \\(W\\) est : \\[\nW = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de \\(W\\), alors : \\[\nW = V V^t\n\\]\n\n\nProcédé d’orthogonalisation de Gram-Schmidt\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\n\n\n\n\n\n\nTip\n\n\n\nAvant de recourir au procédé de Gram-Schmidt, il faut s’assurer que les vecteurs ne soient pas déjà orthogonaux, cela serait une perte de temps de les recalculer. Ce calcul est long, il faut bien prendre son temps pour le faire et ne pas se précipiter.\n\n\nÉtapes du Procédé\nLe premier vecteur orthogonal ( u_1 ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où \\(( k \\geq 2 )\\)), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]\n\n\n\nBase duale\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite.\n\n\nDiagonalisation d’une matrice\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\]\n\\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\)\n\n\nDiagonalisation d’une matrice symétrique réelle\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\] où \\(Q\\) est une matrice orthogonale.\n\n\n\n\n\n\nWarning\n\n\n\nPour que la propriété soit vérifiée, il est essentiel que la matrice soit réelle, c’est-à-dire sans composantes complexes. En effet, la symétrie d’une matrice complexe n’implique pas nécessairement la propriété en question"
  },
  {
    "objectID": "M1SEP.html#statistiques-descriptives-univariées-1",
    "href": "M1SEP.html#statistiques-descriptives-univariées-1",
    "title": "DATA Camp M1",
    "section": "",
    "text": "La moyenne arithmétique d’une série de valeurs \\(x_1, x_2, \\ldots, x_n\\) est donnée par : \\[\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\\]\nLa médiane est la valeur qui sépare la série en deux parties égales. Pour une série ordonnée, si \\(n\\) est impair, la médiane est la valeur centrale. Si \\(n\\) est pair, c’est la moyenne des deux valeurs centrales.\nLa variance est une mesure de la dispersion des valeurs autour de la moyenne : \\[\\sigma_x^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\\]\nL’écart-type est la racine carrée de la variance : \\[\\sigma = \\sqrt{\\sigma_x^2}\\]\n\n\n\n\n\n\n\nNote\n\n\n\nPlus l’écart-type est grand, plus les données sont dispersées autour de la moyenne.\n\n\nLes statistiques descriptives univariées sont essentielles pour résumer et comprendre les caractéristiques principales d’une seule variable. Elles sont largement utilisées en analyse de données pour obtenir une vue d’ensemble rapide et efficace. Elles permettent aussi d’identifier rapidement des valeurs extrêmes."
  },
  {
    "objectID": "M1SEP.html#statistiques-descriptives-bivariées-1",
    "href": "M1SEP.html#statistiques-descriptives-bivariées-1",
    "title": "DATA Camp M1",
    "section": "",
    "text": "Covariance : La covariance entre deux variables \\(X\\) et \\(Y\\) mesure la manière dont deux variables varient ensemble.\n\n\nPour un échantillon de données : \\[\n\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n\\] où \\(x_i\\) et \\(y_i\\) sont les valeurs des échantillons, et \\(\\bar{x}\\) et \\(\\bar{y}\\) sont les moyennes des échantillons.\nPour des variables aléatoires : \\[\n\\text{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n\\] où \\(\\mathbb{E}[X]\\) et \\(\\mathbb{E}[Y]\\) sont les espérances des variables aléatoires \\(X\\) et \\(Y\\)."
  },
  {
    "objectID": "M1SEP.html#fondements-de-probabilités-1",
    "href": "M1SEP.html#fondements-de-probabilités-1",
    "title": "DATA Camp M1",
    "section": "Fondements de probabilités",
    "text": "Fondements de probabilités\n\nVecteurs aléatoires\n\nLes variables \\(X_1, \\ldots, X_n\\) sont deux à deux indépendantes si et seulement si : \\(\\forall i \\neq j, X_i\\) et \\(X_j\\) sont indépendantes.\n\nLes variables \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes si et seulement si : \\[P(X_1 = x_1, \\ldots, X_n = x_n) = P(X_1 = x_1) \\times \\ldots \\times P(X_n = x_n)\\]\n\nSi \\(X_1, \\ldots, X_n\\) sont mutuellement indépendantes, alors pour toute famille de fonctions réelles \\(f_i\\), on a : \\((f_1(X_1), \\ldots, f_n(X_n))\\) sont indépendantes.\n\nSoit \\(X = (X_1, \\ldots, X_n)^T\\) un vecteur aléatoire. Dans le cas multidimensionnel, l’espérance scalaire est remplacée par un vecteur espérance. \\[E(X) = (E(X_1), \\ldots, E(X_n))^T\\]\nLa variance unidimensionnelle est remplacée par la matrice symétrique de variance-covariance. Elle contient les variances en diagonale et les covariances ailleurs. On la note généralement \\(\\Sigma_X\\). \\[\\Sigma_X = \\begin{bmatrix}\nV(X_1) & \\ldots & \\text{Cov}(X_1, X_n) \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\text{Cov}(X_n, X_1) & \\ldots & V(X_n)\n\\end{bmatrix}\\]\n\n\nNotions de convergence\nSi l’on pense à des données, vues comme réalisation de variables aléatoires \\(X_1, \\ldots, X_n\\), il serait intéressant de se poser la question de savoir comment évolue cette suite lorsque \\(n\\) tend vers l’infini.\nOn dit que \\((X_n)\\) converge presque sûrement vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p.s.}} X\\) si et seulement si : \\(P\\left(\\lim_{{n\\to+\\infty}} X_n = X\\right) = 1\\)\nOn dit que \\((X_n)\\) converge en probabilité vers \\(X\\) et on note \\(X_n \\xrightarrow{\\text{p}} X\\) si et seulement si : \\(\\forall \\varepsilon &gt; 0, \\quad P(|X_n - X| &gt; \\varepsilon) \\rightarrow 0\\)\nOn dit que \\((X_n)\\) converge en loi vers \\(X\\) et on note \\(X_n \\xrightarrow{\\mathcal{L}} X\\) si et seulement si : \\(F_{X_n} \\xrightarrow{n \\to +\\infty} F_X\\) Où \\(F_X\\) dénote la fonction de répartition de \\(X\\).\nOn dit que \\((X_n)\\) converge en moyenne quadratique vers \\(X\\) et on note \\(X_n \\xrightarrow{m.q.} X\\) si et seulement si : \\(\\mathbb{E}((X_n - X)^2) \\rightarrow 0\\) Cette définition peut se généraliser jusqu’à l’ordre \\(n\\), mais nous n’en aurons pas besoin.\n\n\n\n\n\n\n\nLoi faible des grands nombres\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\) alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p} \\mu \\]\n\n\nLoi forte des grands nombres\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors :\n\\[\\frac{1}{n} \\sum_{i=1}^{n} X_i \\xrightarrow{p.s.} \\mu\\]\n\n\nThéorème Central Limite\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables aléatoires indépendantes et de même loi telles que : \\(\\mathbb{E}(X_i) = \\mu\\) et \\(\\text{Var}(X_i) = \\sigma^2\\), alors : \\[\\sqrt{n}\\frac{\\overline{X}_n - \\mu}{\\sigma} \\xrightarrow{\\mathcal{Loi}} \\mathcal{N}(0, 1)\\]"
  },
  {
    "objectID": "M1SEP.html#statistique-inférentielle-niveau-basique-1",
    "href": "M1SEP.html#statistique-inférentielle-niveau-basique-1",
    "title": "DATA Camp M1",
    "section": "Statistique inférentielle : niveau basique",
    "text": "Statistique inférentielle : niveau basique\n\nEchantillon / Estimateur\nLe point de départ est un vecteur (ou un tableau dans le cas multidimensionnel) de données. Ces données peuvent être vues comme les réalisations \\((x_1, x_2, \\ldots, x_n)\\) d’une variable aléatoire \\(X\\) qui dépend d’un certain paramètre \\(\\theta\\) que nous allons chercher à estimer. Pour ce faire, nous allons construire un échantillon de cette variable. Un échantillon \\((X_1, X_2, \\ldots, X_n)\\) est un n-uplet de variables aléatoires indépendantes qui suivent toutes la même loi (celle de \\(X\\)). Un estimateur de \\(\\theta\\) est une fonction \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) de notre échantillon, qui possède une loi de probabilité. Lorsque l’aléa est réalisé, \\(\\hat{\\theta}(\\omega) = f(x_1, x_2, \\ldots, x_n)\\) est une estimation de \\(\\theta\\). Le but de ce cours est de construire le meilleur estimateur possible de \\(\\theta\\).\n\n\nEstimateur sans biais\nPour que l’estimation soit bonne, il faut que \\(\\hat{\\theta}\\) soit proche de \\(\\theta\\). Comme \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) est une variable aléatoire, on ne peut imposer de condition qu’à sa valeur moyenne.\nOn définit ainsi le biais : \\[b_n(\\hat{\\theta}, \\theta) = \\mathbb{E}(\\hat{\\theta}_n) - \\theta\\]\nUn estimateur est dit sans biais si \\(b_n(\\hat{\\theta}, \\theta) = 0\\), c’est-à-dire : \\[\\mathbb{E}(\\hat{\\theta}_n) = \\theta\\]\n\n\nEstimateur convergent\nUn estimateur est dit convergent s’il converge en probabilité vers le paramètre à estimer : \\[\\hat{\\theta}_n \\xrightarrow{P} \\theta\\]\nEn pratique, tout estimateur sans biais et dont la variance tend vers 0 est convergent.\n\n\nEstimateur optimal\nLa qualité d’un estimateur est mesurée à travers son erreur quadratique moyenne définie par : \\[EQM(\\hat{\\theta}_n) = (b_n(\\hat{\\theta}, \\theta))^2 + V(\\hat{\\theta}_n)\\] Comme nous cherchons tout le temps (presque) des estimateurs sans biais, il reste à comparer les variances.\nUn estimateur 𝜃̂1 est meilleur que 𝜃̂2 si : \\[V(\\hat{\\theta}_1) &lt; V(\\hat{\\theta}_2)\\]\n\nOn définit la quantité d’information apportée par l’estimateur par : \\[\nI(\\hat{\\theta}_n) = -\\left( \\mathbb{E} \\left( \\frac{\\partial L}{\\partial \\theta} \\right) \\right)^2\n\\] Où 𝐿(𝑥, 𝜃) = ∏ 𝑓(𝑥𝑖) (nous reviendrons sur sa définition)\nL’inégalité de Rao-Cramer postule que la variance d’un estimateur ne peut pas aller en delà d’un certain seuil : \\[V(\\hat{\\theta}_n) \\geq \\frac{1}{I(\\hat{\\theta}_n)}\\] Un estimateur est optimal (ou efficace) si sa variance vérifie le cas d’égalité.\n\n\nConstruction d’un estimateur\nUn estimateur est une valeur qu’on ne peut pas obtenir en théorie donc on essaye de l’estimer. Par exemple, on ne peut pas calculer l’espérence d’une série de données et donc pour essayer d’obtenir une valeur on calculer une estimation. On recours à plusieurs estimateurs tels que le maximum de vraisemblance ou bien la méthode des moments.\n\n\n\n\n\n\nNote\n\n\n\nLa méthode du maximum de vraisemblance est la plus souvent utilisé dans les modèles de prédiction.\n\n\n\nLa méthode du maximum de vraisemblance consiste à affecter \\(𝜃\\) la valeur qui maximise la probabilité d’observer \\((𝑥_1, 𝑥_2, … , 𝑥_𝑛)\\) lorsque l’aléa du vecteur \\((𝑋_1, 𝑋_2, … , 𝑋_𝑛)\\) tombe. Sans trop rentrer dans la théorie de la vraisemblance, nous allons présenter un algorithme en cinq étapes pour calculer cet estimateur (qui présente des propriétés assez séduisantes) :\n\nEtape 1 : Calculer la fonction de vraisemblance\nDans le cas continu : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} f(x_i)\\]\nDans le cas discret : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} P(X_i = x_i)\\]\nEtape 2 : Calculer le log-vraisemblance Il s’agit de calculer un maximum, ce qui revient à dériver. Il s’agit ici d’un produit de n facteurs, ce qui rend la dérivation assez coriace. La fonction logarithmique présente des propriétés assez sympas pour faciliter cette tâche.\nEtape 3 : Calculer la dérivée de la log-vraisemblance\nEtape 4 : Résoudre l’équation d’inconnue \\(𝜽\\)} \\[\\frac{\\partial (\\ln(L))}{\\partial \\theta} = 0 \\Rightarrow \\theta = \\theta_0\\]\nEtape 5: Vérifier qu’il s’agit d’un maximum.\nEn s’assurant que : \\[\\frac{\\partial^2 (\\ln(L))}{\\partial \\theta^2} &lt; 0\\]\n\nLa méthode des moments consiste à égaliser les moments théoriques (espérance, variance) à leurs équivalents empiriques et à en dégager une estimation ponctuelle.\n\nEn pratique, il faut résoudre l’(les) équation(s) : \\[\\mathbb{E}(X) = \\overline{X} \\text{ et } \\text{Var}(X) = S_n^2\\] avec : \\[\\overline{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\hspace{2cm}\nS_n^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\overline{X})^2\\]\nIl existe une autre méthode d’estimateurs qu’est la méthode des moindres carrés ordinaires.\n\nLorsqu’il s’agit de prendre une mesure 𝜃 avec un appareil doté d’une imprécision \\(𝜀\\), alors le problème d’estimation peut s’écrire : \\(𝑋 = 𝜃 + 𝜀\\). La méthode des moindres-carrés ordinaires consiste à trouver le paramètre \\(𝜃\\) qui minimise la somme des carrées des erreurs : \\[𝜃_{𝑀𝐶𝑂} = \\arg\\min \\left( \\sum_{i=0}^n \\varepsilon_i^2 \\right) = \\arg\\min \\left( \\sum_{i=0}^n (X_i - \\theta)^2 \\right)\\]\n\n\n\nIntervalles de confiance\nUn intervalle de confiance [\\(A\\), \\(B\\)] de niveau \\(1 - \\alpha\\) est un intervalle aléatoire qui a la probabilité \\(1 - \\alpha\\) de contenir le paramètre à estimer \\(\\theta\\). Formellement, on écrit : \\(P (t_1 (\\theta) \\leq f(X_1, \\ldots, X_n) \\leq t_2 (\\theta)) = P(A \\leq \\theta \\leq B) = 1 - \\alpha\\)\n\n\nTest d’hypothèses\nDans le cadre d’un test d’hypothèse, nous cherchons à faire valoir une hypothèse en dépit d’une autre, qui lui est contradictoire.\nOn appellera la première (celle dont le rejet à tort sera le plus préjudiciable) « Hypothèse nulle » et la deuxième « Hypothèse alternative ».\n\n\n\n\n\nLes calculs qui se cachent derrière le choix de l’hypothèse à garder sont compliqués. Mais BONNE NOUVELLE, la machine fera tour à notre place. Il suffit juste de suivre correctement la méthode :\nEtape 1 : Choisir judicieusement les hypothèses à évaluer et fixer le risque \\(𝛼\\)\nEtape 2 : Choisir le test adapté à la procédure\nEtape 3 : Rentrer la commande correspondante sur R et exécuter\nEtape 4: Lire dans les sorties la p-value. si elle est supérieure à α on conserve l’hypothèse nulle H0. Si elle lui est inférieure, on rejette H0 et on accepte l’hypothèse alternative H1.\n\n\nConstruction d’intervalles de confiance\nLes intervalles de confiance sont des outils essentiels en statistique pour estimer des paramètres inconnus tout en mesurant l’incertitude associée à cette estimation. Ci-dessous, vous trouverez un tableau présentant la construction des intervalles de confiance pour différents paramètres."
  },
  {
    "objectID": "M1SEP.html#concepts-de-base-1",
    "href": "M1SEP.html#concepts-de-base-1",
    "title": "DATA Camp M1",
    "section": "Concepts de base",
    "text": "Concepts de base\n\nMacroéconomie\n\n\n\n\n\nLa macroéconomie est l’étude économique d’un système ou de phénomènes à un niveau global de l’économie.\n\n\nMicroéconomie\nLa microéconomie se concentre sur l’observation et l’analyse des interactions à petite échelle.\n\n\nBien économique\n“Chose utile à satisfaire un besoin, il faut que le bien soit disponible et en quantité limitée.\nUn bien non économique est un bien qui s’obtient gratuitement, comme l’oxygène, contrairement à un bien économique qui s’obtient en payant.”\n\n\nAgent économique\n“Un agent économique est un individu ou un groupe d’individus constituant un centre de décision économique indépendant.”\n\n\nMarché\n\n\n\n\n\n“Le marché c’est une institution sociale qui permet l’échange entre l’offre et la demande.”\n\n\nAsymétrie d’information\n“L’asymétrie d’information concerne les situations où les agents d’un marché ne possèdent pas de la même information sur un produit que ce soit au sujet de ses qualités ou de ses défauts”\n\n\nExternalité\nL’externalité désigne la conséquence (positive ou négative) d’une activité d’un agent économique sur un autre, sans qu’aucun des deux ne reçoive ou ne paye une compensation pour cet effet.\n\n\nConcurrence Pure et Parfaite\nLa CPP repose sur cinq fondements :\n\nL’Atomicité du marché\n\nExistence d’un grand nombre d’agent économique sur le marché, à tel un point que ni l’offre ni la demande ne peut exercer une action quelconque sur la production et les prix ;\n\nL’Homogénéité des produits\n\nLa préférence d’un produit à un autre du point de vue de l’acheteur se fait uniquement selon son prix ;\n\nLibre entrée et sortie sur le marché\n\nAucune firme ne peut s’opposer à l’arrivée d’un concurrent sur le marché, tout le monde est libre de l’intégrer ;\n\nLibre circulation des facteurs de production\n\nLes facteurs de production (capital et travail) doivent être libre de se déplacer librement sans obstacle d’une industrie à l’autre ;\n\nLa transparence de l’information\n\nOffreurs et demandeurs sont parfaitement conscient des caractéristiques et prix des produits.\n\n\nMonopole\n“Le monopole est une situation dans un marché où un vendeur fait face aux multitudes vendeurs.”\n\n\nSegmentation de marché\n“La segmentation de marché est un découpage du marché en groupes homogènes selon des critères spécifiques, que ce soit des critères démographiques ou bien géo-graphiques.”\n\n\nDiscrimination par les prix\n“La discrimination par les prix est le pouvoir de pratiquer des prix différents pour un même produit, peut s’appliquer sur la quantité ou bien selon la segmentation du marché.”\n\n\nUtilité\n“L’utilité mesure le bien-être liée à la consommation d’un bien.”\n\n\nActualisation\n“L’Actualisation est un calcul permettant de transformer une valeur future en une valeur présente.”\nQue vaut aujourd’hui les X euros que j’aurais demain ?\n\\[\nV_a = \\frac{V_f}{(1+i)^t}\n\\]\n\\[\nV_a : Valeur\\ Actuelle\n\\]\n\\[\nV_f : Valeur\\ future\n\\] \\[\ni : Taux\\ sans\\ risque\\\\\n\\]\n\\[\nt : Temps\n\\]\n\n\nProblèmes macroéconomiques\nIl existe 4 grands problèmes macroéconomiques :\n\nCrises et récessions Ralentissement et/ou régression de l’activité économique ;\nInflations Augmentation générale et durable du niveau des prix entraînant une perte du pouvoir d’achat de la monnaie ;\nChômage Inactivité due au manque de travail ;\nProblème de l’équilibre extérieur Quand les importations sont plus importantes que les exportations, la balance commerciale est déséquilibrée."
  },
  {
    "objectID": "M1SEP.html#la-dissertation-en-économie-1",
    "href": "M1SEP.html#la-dissertation-en-économie-1",
    "title": "DATA Camp M1",
    "section": "La dissertation en économie",
    "text": "La dissertation en économie\n“On tient tout d’abord à remercier l’enseignant chercheur (en Philosophie économique, Théories économiques de la justice, Redistribution des revenus, Economie sociale, Economie publique), monsieur Jean-Sébastien Gharbi pour cette rubrique d’aide à la dissertation.”\n\n\n\n\n\nOn pense souvent que la dissertation en économie est un exercice difficile et qui récompense mal le travail. C’est totalement faux. La dissertation est un exercice dans lequel il est facile d’obtenir la moyenne, et même (avec un peu d’entraînement) d’obtenir systématiquement de très bonnes notes. C’est un exercice relativement facile parce que c’est un exercice en très grande partie formel : tout est une question de méthode.\nFaire une dissertation, c’est montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances pour répondre à une question de manière argumentée (c’est-à-dire sous la forme d’un raisonnement). Autrement dit :\n\nUne dissertation n’est pas une question de cours.\n\nLa première chose à faire, c’est de différencier question de cours et dissertation (qui sont souvent confondues). Une question de cours demande simplement de réciter un cours. Si vous ne faites que réciter votre cours dans un exercice de dissertation, vous aurez une mauvaise note. Pourquoi ? Parce que l’exercice de dissertation suppose de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances (dans un temps limité) – pas seulement de réciter une leçon apprise plus ou moins par cœur. Comme la question de cours, la dissertation suppose donc que vous savez des choses sur le sujet, mais il est important de comprendre que la dissertation porte tout autant sur votre aptitude à organiser vos idées que sur vos connaissances.\n\nDans une dissertation, la réponse donnée n’est pas importante !\n\nUne dissertation consiste toujours à répondre à une question. Les étudiants pensent parfois qu’il y a une « bonne » réponse à la question posée – qu’il s’agirait de trouver. D’ailleurs, cela contribue à l’idée (fausse) que la dissertation est un exercice aléatoire : si vous ne trouvez pas la bonne réponse, vous avez perdu. Cela aussi est faux : il n’y a (en général) pas de « bonne » réponse à la question posée par la dissertation. L’exercice de dissertation vient de la philosophie. Pensez-vous sérieusement que l’on puisse demander à un étudiant (ou à un professeur, d’ailleurs) de régler de façon définitive un débat philosophique qui a donné lieu à des controverses pendant des siècles en trois, quatre ou même sept heures ? La réponse évidente est « non ».\n\nDans une dissertation, le plus important c’est l’argumentation !\n\nSi on ne s’intéresse pas à la réponse donnée. C’est tout simplement, parce que ce qui intéresse votre lecteur, c’est la manière dont vous répondez : votre aptitude à utiliser vos connaissances de manière argumentative pour défendre une conclusion. Sur le principe, il serait donc possible de défendre une conclusion choquante ou même offensante dans une dissertation, pour la bonne raison qu’on n’évalue pas la réponse que vous donnez, mais la manière dont vous amenez votre réponse. Votre réponse, à la limite, on ne s’y intéresse pas. Une fois cela dit, il est assez évident qu’il est beaucoup plus facile de défendre une position modérée et consensuelle, qu’une position offensante pour de nombreuses personnes. C’est la raison pour laquelle, il n’est pas du tout conseillé de chercher la provocation gratuite dans une dissertation.\nComment on fait une dissertation ?\n\n\n\n\n\n\nAnalyse du sujet\nL’analyse du sujet est la première étape de la dissertation et l’une des plus importantes. Une dissertation se présente sous la forme d’un sujet. Il faut isoler la ou les deux notions principales du sujet.\nIl y a quatre grands types de sujets : les sujets ne contenant qu’une seule notion (ex : « Les discriminations en France »), les couples de notions (ex : « Capitalisme et démocratie »), les citations (ex : « Le système de production capitaliste est une démocratie économique dans laquelle chaque sou donne un droit de vote. Les consommateurs constituent le peuple souverain », Ludwig von Mises) ou une question (ex : « La croissance économique s’oppose-t-elle à la préservation de l’environnement ? »).\nDans tous les cas, l’objectif est d’arriver à une question (donc les sujets les plus simples à traiter à ce stade, ce sont les questions : ils vous donnent immédiatement le problème à traiter). Mais la première chose à faire (même quand on a déjà la question), c’est de trouver le couple de notions impliquées dans le sujet. Souvent, c’est absolument évident, mais parfois il faut un peu chercher.\nIl faut éviter à tout prix de faire un exposé quand on attend de vous une dissertation. Un hors-sujet, c’est de ne pas traiter le bon sujet. Si vous répondez de manière factuelle à un sujet de dissertation, vous faites pire : vous faites un hors-exercice.\n\n\nRecherche des idées\nUne fois qu’on a identifié un couple de notions, il faut (au brouillon) essayer de faire la liste des éléments du cours qui relient les deux notions. Il est important de ne noter que les éléments qui relient les deux notions (pour ne pas risquer de se perdre dans des éléments qui concernent seulement une seule des deux notions). Sur chacune des notions que vous aurez à traiter en dissertation, on a écrit des livres entiers. Il est impossible de tout dire dessus dans une dissertation. On se limite donc à ce qui relie les deux notions de notre sujet. Évidemment, si un élément pertinent vous vient en tête et qu’il ne se trouve pas dans votre cours, n’hésitez pas à le noter. Si cet élément peut être utilisé dans votre raisonnement, même comme exemple, ce sera un plus indiscutable.\nDans un premier temps, on note tout ce qui se présente à l’esprit. Ce n’est que dans un deuxième temps, quand on a un certain nombre d’éléments que l’on se pose la question : « Est-ce qu’il y a une manière qui saute aux yeux de relier tous ces éléments en répondant à la question (si elle a été posée de manière directe) ou pour répondre à une question comprenant le couple de notions (si la question n’a pas été formulée dans le sujet) ? ». Si la réponse est positive, on a trouvé la question qui structurera notre devoir. Si ce n’est pas le cas, il faut essayer de trouver une question qui relie le plus grand nombre des éléments que l’on a noté sur son brouillon – et donc laisser de côté les éléments qui ne servent pas. Il arrive souvent qu’une partie des éléments que l’on note sur son brouillon ne soit pas utilisée dans le devoir. Bref, si notre sujet est un couple de notions ou une citation, il faut que l’on arrive à une question. Évidemment, quand notre sujet est déjà une question, on n’a pas autant de marge de manœuvre, mais en vérité, si on vous pose une question précise, c’est que vous avez les éléments pour y répondre dans le cours (donc la différence n’est pas très importante).\n\n\nMise en évidence d’un problème\nPuisqu’elle ne doit pas être une question de fait, la question qui relie le plus d’éléments possibles parmi ceux qui associent les deux notions dans votre cours doit être une question conceptuelle. Pour le dire autrement, cette question doit être un problème (on parle souvent de « problématique » pour désigner ce problème dans le cadre d’une dissertation). Qu’est-ce qu’un problème ? C’est une question qui met en tension deux concepts et qui analyse les différents aspects de leur relation (conceptuelle).\nSouvent les étudiants ont peur de ne pas trouver le « bon » problème. Pourtant, si on suit la méthode de dissertation, il n’y a pas de risque de se tromper. En effet, on ne doit pas choisir un problème d’abord (sans savoir si on a de quoi le traiter) et le traiter ensuite. Vous aurez noté qu’on procède exactement dans le sens inverse : on voit à quelle question on peut répondre avec les éléments qu’on a sur son brouillon et on pose précisément la question à laquelle on sait qu’on peut répondre.\n\n\nConstruction du plan\nPour la même raison qu’au-dessus, la construction du plan ne doit pas être très difficile : il s’agit de rassembler les différents éléments qui permettent de répondre à la question (au problème que l’on va poser) de façon à y apporter une réponse.\nOn va apporter la réponse que les éléments disponibles nous permettent d’atteindre. Il y a une seule contrainte : votre plan doit être suffisamment détaillé. Comme l’objectif de la dissertation, c’est de montrer que vous êtes capable d’utiliser et de réorganiser vos connaissances. Si vous ne faites que deux parties sans sous-parties à l’intérieur (il n’y aurait donc qu’une seule articulation logique), on trouvera que vous n’avez pas assez structuré votre devoir. Le découpage minimal, c’est d’avoir quatre éléments (en général, on fait deux grandes parties avec deux sous-parties chacune, donc on a trois articulations).\nVos parties et vos sous-parties doivent correspondre à des étapes de votre raisonnement (on dit souvent qu’il faut une idée par sous-partie), donc votre plan doit donner la structure du raisonnement grâce auquel vous allez répondre à la question posée. Le plan (qui est annoncé à la fin de l’introduction et qui doit être apparent dans le devoir, nous reviendrons sur ce point un peu plus loin) doit permettre de comprendre la structure de votre devoir d’un coup d’œil – simplement en lisant les titres.\nUn élément qui permet de savoir si votre plan est bon, c’est de se demander si à la fin de la première partie, on est arrivé à un état de la réflexion différent de celui de la fin de l’introduction.\nQu’est-ce que la première partie a permis de comprendre ? Et est-ce que la seconde partie apporte quelque chose d’autre ? Si chaque partie représente une étape dans un raisonnement et que votre devoir complet est donc un raisonnement, votre plan est forcément bon : vu que c’est précisément ce qu’on attend de vous.\nIl ne faut jamais faire deux sous-parties dans une partie sous la forme d’une seule phrase coupée par des points de suspension (ex : « A) L’organisation scientifique du travail a permis la croissance des trente glorieuses… », « B) mais, elle a aussi eu des conséquences négatives, notamment sur le plan social »). En effet, cela revient à pointer du doigt que vous opérez une coupure arbitraire (donc que vous n’articulez pas de manière assez nette les différentes parties de votre devoir). Sur le principe, les deux sous-parties sont reliées par les points de suspension et donc ne forment qu’une partie sans coupure. Préférez toujours les titres qui se succèdent sans être grammaticalement liés les uns aux autres. Dans l’exemple ci-dessus, il suffit de faire deux phrases pour découper les deux idées. Si on ne peut pas couper grammaticalement les deux titres, c’est la preuve que l’articulation pose problème.\nDans l’idéal, un plan est équilibré : chaque partie comprend le même nombre de sous-parties que l’autre et elles font à peu près la même longueur. Et si vous faites plus de sous-parties dans une partie que dans l’autre, il faut que les sous-parties soient un peu plus longues dans la partie qui contient moins de sous-parties. Remarquez que si vous faites un plan avec deux parties, deux sous-parties, ce dernier problème ne se pose pas.\nUn point important et souvent totalement négligé par les étudiants : même quand c’est tentant, on ne fait jamais de plan centré sur les auteurs. Un plan par auteurs conduit très souvent à suivre l’ordre chronologique et à présenter les positions des auteurs sans les confronter réellement les unes aux autres . Ce qui doit structurer le plan, ce sont les concepts (c’est-à-dire les notions qui nous avaient permis de construire le problème à résoudre).\nEn réalité, il n’est pas rare qu’on suive plus ou moins l’ordre chronologie, mais il est essentiel de se focaliser sur les concepts, et pas sur les auteurs. Pourquoi ? Parce que l’enchaînement ou l’opposition de concepts constitue un raisonnement (ce que vous devez faire !), alors que l’enchaînement ou l’opposition d’auteurs constitue un exposé (ce que vous ne devez pas faire !). En réalité, c’est assez facile à faire il suffit de s’interdire de mentionner le nom des auteurs dans les titres de partie ou de sous-partie.\nVu que l’objectif du plan, c’est de répondre à une question qui met les deux notions du sujet en relation, les parties (ou les sous-parties) qui se focalisent sur une seule des deux notions sont à éviter à tout prix : elles sont simplement hors-sujet. Sur un sujet comme « capitalisme et démocratie », le plan « première partie : capitalisme », « deuxième partie : démocratie » est parmi les pires possibles.\nJusqu’à présent, nous n’avons encore rien écrit sur la copie elle-même. Nous n’avons travaillé que sur le brouillon. Nous avons deux notions clés, un problème et un plan. Ce sont les éléments fondamentaux du devoir. Il faut à présent passer à la rédaction. Nous allons nous intéresser d’abord à l’introduction.\n\n\nLa rédaction\n(Introduction, Conclusion, Développement)\nL’introduction est la partie la plus importante de la dissertation. Elle permet de savoir pourquoi le problème se pose, comment il se pose et comment il va être résolu. A quoi sert l’introduction ?\nLe rôle de l’introduction, sa raison d’être, c’est de construire et d’énoncer le problème (la problématique) auquel le reste du devoir va répondre. Il ne suffit donc pas de poser la question (pour cela deux lignes suffiraient) et de commencer le développement. L’introduction, comme son nom le dit très bien, va introduire le problème, c’est-à-dire qu’elle va nous y amener, rapidement, certes, mais en plusieurs étapes très codifiées.\nUne introduction de dissertation comprend obligatoirement (au minimum) cinq éléments : une accroche, une définition des termes du sujets, la construction du problème, l’énoncé du problème et l’annonce du plan. Comme une introduction de dissertation fait entre 20 lignes et une page et demie (grand maximum), il faut être efficace.\n\nL’accroche\n\nUne introduction de dissertation suit des règles assez rigides. Elle commence toujours par une accroche.\nUne « accroche », c’est une phrase ou deux qui vont contenir la ou les deux notion(s) du sujet. Son rôle est d’amener par étapes le lecteur vers la question que vous allez poser. Elle sert donc d’introduction à l’introduction. Une accroche peut être une citation (il y en a toujours dans un cours) ou un fait récent (le chômage a-t-il baissé récemment ? Un candidat à l’élection présidentielle a-t-il dit qu’il fallait juger sa politique en fonction de son impact sur le niveau de chômage ?). Si on n’a pas de citation ou de fait relevant de l’actualité, on peut amener le sujet de façon plus habituelle.\nIl est important d’éviter un certain nombre de formules toutes faites et souvent utilisées comme « De tous temps… », « De tous temps, les hommes… » ou encore les affirmations très générales (et que vous ne justifierez pas) comme : « Le chômage est un phénomène économique important, c’est pourquoi il faut l’étudier ». Le défaut de tous ces débuts d’accroche, c’est qu’ils peuvent servir pour n’importe quel sujet et que cela se voit.\nOn met une accroche parce que cela permet de mentionner les termes du sujet sans commencer directement par une définition – ce qui constitue l’étape suivante.\n\nDéfinition des termes du sujet\n\nL’accroche a introduit les notions, mais sans les définir – comme si tout le monde savait précisément de quoi il s’agit (ce qui n’est pas si surprenant, on ne passe pas son temps à définir tous les mots qu’on utilise). Mais, pour utiliser les deux notions du sujet de façon un peu plus précise, il faut les définir. Les définitions que l’on va donner dans une introduction n’ont pas pour objectif de définir les notions de manière exhaustive ou dans l’absolu. Elles doivent permettre de comprendre le lien (ou l’opposition) entre les deux notions et orienter l’introduction de façon à ce que l’on puisse construire le problème – avant de l’énoncer (autrement dit, elles doivent ouvrir la voie aux deux étapes suivantes de l’introduction).\nDu coup, les définitions que l’on va donner vont dépendre du problème que l’on souhaite atteindre.\n\nConstruction du problème\n\nComme on sait à quelle question on doit arriver (que cette question nous ait été donnée par le sujet ou que ce soit la question à laquelle on est le mieux armé pour apporter une réponse), il ne va pas être difficile de passer des définitions au problème. Cela suppose juste de montrer qu’avec les définitions que l’on vient de donner, il y a une question se pose avec force.\nEncore une fois, cela peut sembler très artificiel (et ça l’est). Toutefois, l’intérêt de cet aspect artificiel, c’est qu’il nous garantit que l’on ne va pas se perdre en chemin. Quand on fait une dissertation, on ne cherche pas son chemin : on sait où on va et on ne fait qu’expliquer pourquoi on y va. Le sujet que l’on construit ne tombe pas du ciel, il vient de notre cours. Les définitions ne tombent pas du ciel, elles donnent les éléments qui vont nous permettre de poser la question à laquelle on sait déjà comment on va répondre. Bref, l’étape de construction du problème est importante parce qu’elle montre que vous avez des aptitudes pour vous faire comprendre à l’écrit (et il ne faut surtout pas la négliger), mais elle n’est pas une étape difficile ou magique.\nVous pourriez être surpris que l’on construise le sujet, alors qu’il nous est parfois donné sous forme de question (dans les autres cas, on comprend mieux pourquoi il est nécessaire de construire le problème). En fait, c’est une manière de montrer que vous êtes capable de vous approprier le sujet. Vous ne traitez pas le sujet parce qu’on vous l’a donné (même si vous c’est une des raisons pour lesquelles vous faites une dissertation), mais parce que vous comprenez pourquoi la question se pose. Et comment mieux montrer qu’on comprend un problème qu’en montrant en quoi il est problématique ? Autrement dit, même quand votre sujet a la forme d’une question, vous devez passer par l’étape de construction du sujet dans l’introduction.\n\nEnoncé du problème\n\nL’énoncé du problème doit prendre la forme d’une question. Il est le point final de l’étape juste précédente. Une fois qu’on a les éléments qui permettent de comprendre que le problème se pose, il faut explicitement exprimer le problème lui-même. On exprime toujours le problème sous la forme d’une question (parce que c’est une manière de montrer qu’il appelle une réponse) et d’une question unique. Poser deux, trois ou quatre questions ce serait soit redire plusieurs fois la même chose (et si votre première question est claire, c’est inutile), soit poser (volontairement ou pas) plusieurs questions différentes. Or, vous ne pourrez pas répondre convenablement et dans les règles de la dissertation à plusieurs questions en un seul devoir. Vous devrez donc choisir entre ne pas traiter certaines des questions que vous avez explicitement posées (et dans ce cas pourquoi les poser explicitement) ou essayer de les traiter toutes (ce qui vous conduira à un devoir dont la ligne directrice sera au mieux difficile à suivre, au pire inexistante). Si on se rappelle du côté formel et rhétorique d’une dissertation, on comprend qu’il ne faut poser qu’une seule question : celle à laquelle vous apportez une réponse.\nLorsque le sujet est une question, faut-il répéter mot pour mot le sujet comme énoncé du problème ? Il y a deux écoles : la première dit qu’il faut reformuler la question pour montrer que vous la comprenez. Ainsi un sujet comme « Les dépenses publiques permettent-elles de réduire le chômage ? », on pourrait proposer une problématique comme « les dépenses publiques sont-elles efficaces à court et à long terme pour lutter contre le chômage ? ».\nSi vous faites correctement votre travail de définition des termes et de construction du sujet (dans les deux étapes précédentes), je pense qu’aucun correcteur ne vous reprochera de reprendre le sujet mot pour mot dans votre énoncé du problème. Ce qui pose problème pour les partisans de la première façon de faire, c’est quand on peut se demander si l’étudiant comprend que la question qu’il pose est un problème conceptuel, c’est-à-dire qui vient d’une tension entre deux notions. Dans une introduction qui remplit correctement son rôle de construction du problème, le fait de répéter le sujet mot pour mot n’est pas un souci.\n\nAnnonce du plan\n\nUne introduction doit toujours se terminer par une annonce du plan (ce n’est pas une option, c’est une obligation). L’annonce de plan dit à votre lecteur comment vous allez répondre au problème que vous venez de poser. Dans une dissertation, on ne joue pas sur le suspens. On ne cherche pas à surprendre son correcteur. Il faut donc annoncer le plan de manière à ce qu’il comprenne que vous allez répondre au problème posé par un raisonnement et qu’il comprenne aussi quels vont être les principales étapes de votre raisonnement (c’est-à-dire de votre devoir).\nVous allez donc annoncer vos (deux ou trois) grandes parties. Il est conseillé fortement d’utiliser les formules (un peu lourdes en termes de style, mais très claires) « dans une première partie, nous montrerons que… », puis « dans une deuxième partie, nous verrons que … ». Quand vous ne le faites pas, il arrive trop souvent que votre lecteur ne sache pas si vous allez faire formellement deux ou trois parties – pour peu que vous utilisiez des mots comme « et », « puis » ou « ensuite », qui peuvent aussi bien marquer des étapes à l’intérieur d’une grande partie que le passage d’une partie à une autre.\nLa conclusion\nVous pourriez être surpris de voir la conclusion arriver aussi tôt dans le devoir. La raison, c’est qu’il est inconcevable de ne pas répondre à la question posée en introduction – si vous ne répondez pas le devoir n’aura, littéralement, servi à rien. Or, il est évident qu’en partiel, on est souvent pris par le temps. On rédige donc la conclusion juste après avoir rédigé l’introduction au brouillon (on la rédige aussi au brouillon, d’ailleurs). Comme ça si on est pris par le temps, on pourra recopier la conclusion déjà prête avant de rendre le devoir. S’il faut couper quelque chose en raison du temps limité de l’épreuve, il vaut mieux couper un bout du développement que rendre une dissertation sans conclusion.\nLa première phrase de votre conclusion doit apporter la réponse à la question que vous avez posée en introduction. Elle doit le faire de façon absolument claire et donc il est conseillé de reprendre exactement la question en la tournant en une phrase affirmative ou en une phrase négative selon votre réponse. Le rôle de la conclusion, c’est de répondre à la question. Il ne faut pas qu’on relise la conclusion en se demandant quelle était la réponse – et même en se demandant si une réponse a été donnée. Cela ne vous empêche pas de donner une réponse nuancée, mais il faut une réponse claire.\nUne conclusion de dissertation ne résume pas le devoir (on vient de le lire, c’est tout à fait inutile). Une conclusion n’introduit jamais un élément qui n’a pas été abordé dans le devoir, mais qui aurait pu y être discuté. Si jamais votre correcteur n’a pas vu que vous avez oublié de parler de quelque chose d’important, vous n’allez tout de même pas lui dire qu’il manque quelque chose dans votre devoir (chacun son boulot). La dissertation est un exercice de rhétorique, votre objectif, c’est de convaincre votre lecteur : ce n’est pas à vous de dire qu’il manque quelque chose, même si vous le savez.\nOn conseille parfois de finir sa dissertation sur une ouverture. Une ouverture est un nouveau problème qui se pose une fois que vous avez répondu au problème de votre devoir. Cela revient à suggérer une autre dissertation possible une fois qu’on considère votre réponse comme acceptée. Trop souvent, les étudiants finissent leurs devoirs de manière particulièrement maladroite parce qu’ils ne comprennent pas ce qu’est une ouverture. Mon conseil est d’éviter de faire une ouverture, au moins au début : ce n’est pas une obligation et cela peut donner une très mauvaise impression finale.\nLa rédaction du devoir\nUne fois tout cela fait, on prend sa copie (totalement vierge à ce moment) et on commence à écrire dessus : on recopie l’introduction, on rédige le développement directement sur la copie (on ne rédige jamais son développement sur le brouillon, cela prend beaucoup trop de temps à recopier). Le développement du devoir doit contenir des titres apparents pour les parties et les sous-parties. Cela signifie que le titre de votre grande partie est marqué dans votre copie (précédé d’un « I) ») et qu’il est isolé du texte et souligné. Bref, on doit pouvoir voir apparaître d’un coup d’œil votre plan en survolant votre copie du regard.\nComme dit juste au-dessus, si on manque de temps, on coupe une partie du développement et on recopie la conclusion qui se trouve sur le brouillon. Attention : si vous ne rédigez pas tout le développement, mettez tout de même le plan apparent pour les parties et sous-parties non développées. C’est précisément parce qu’on a une idée de ce que vous auriez écrit qu’il est possible (en cas de gros manque de temps) de ne pas rédiger tout le développement. Si vous ne détaillez pas votre plan, c’est la trame de votre raisonnement qui manque et c’est beaucoup plus ennuyeux. Si vous ne pouvez pas rédiger tout le développement, je vous conseille de mettre des éléments que vous auriez utilisé sous forme de liste de tirets (en plus des titres apparents qui sont obligatoires)."
  },
  {
    "objectID": "M1SEP.html#algèbre-linéaire-et-quelques-notions-en-m1-sep-sur-les-matrices",
    "href": "M1SEP.html#algèbre-linéaire-et-quelques-notions-en-m1-sep-sur-les-matrices",
    "title": "DATA Camp M1",
    "section": "",
    "text": "La trace d’une matrice carrée \\(A\\) est la somme de ses éléments diagonaux : \\[\\text{Tr}(A) = \\sum_{i=1}^{n} a_{ii}\\]\n\nPropriétés :\n\nLa trace est linéaire : \\[\\text{Tr}(A + B) = \\text{Tr}(A) + \\text{Tr}(B)\\]\nInvariance par similitude : \\[\\text{Tr}(AB) = \\text{Tr}(BA)\\]\n\n\n\n\n\nUne matrice carré \\(A\\) d’ordre \\(n\\) est dite inversible s’il existe \\(B\\) tel que : \\[AB = BA = I_n\\]\nB est alors noté \\(A^{-1}\\) l’inverse de A.\n\n\n\n\n\n\n\nTip\n\n\n\nSi le déterminant d’une matrice \\(A\\) est différent de 0 alors la matrice est inversible.\n\n\n\n\n\nInverse d’une matrice \\(A\\in \\mathcal{M}_{2 \\times 2}\\) de déterminant non nul (\\(det(A) = ad -bc \\ne 0\\)) :\n\\[A^{-1} = \\left(\\begin{array}{cc} a & b \\\\ c & d \\end{array} \\right)^{-1}\n= \\frac{1}{ad-bc}\\left(\\begin{array}{cc} d & -b \\\\ a & -c \\end{array} \\right)\n\\]\n\n\n\nInverse d’une matrice \\(A\\in \\mathcal{M}_{n \\times n}\\) de déterminant non nul (\\(det(A) = d_1 \\times d_2 \\times \\cdots \\times d_n \\ne 0\\)) : \\[D^{-1} =\n\\left(\\begin{array}{cccc}\nd_1 & 0 & \\cdots & 0 \\\\\n0 & d_2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & d_n\n\\end{array}  \\right)^{-1}\n= \\left(\\begin{array}{cccc}\n\\frac{1}{d_1} & 0 & \\cdots & 0 \\\\\n0 & \\frac{1}{d_2} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\frac{1}{d_n}\n\\end{array} \\right)\\]\n\n\n\nUn espace vectoriel est un ensemble de vecteurs qui peuvent être combinés entre eux par des opérations comme l’addition et la multiplication. Ces combinaisons permettent de construire de nouveaux vecteurs dans le même ensemble. Un vecteur \\(v = (v_1,...,v_d)\\) n’a pas de dimension mais admet une longueur de taille \\(d\\) ( = d coefficients). Mais, il est d’usage de représenter \\(v\\) avec sa représentation matricielle notée \\(V = \\left(\\begin{array}{c} v_1 \\\\\n\\cdots \\\\\nv_d\n\\end{array}\n\\right)\\), matrice de \\(d\\) lignes et une colonne. On écrit donc \\(V = v^t\\).\nSoient \\(v,u\\) deux vecteurs d’un espace vectoriel réel de dimension finie muni d’un produit scalaire usuel : \\[\\langle v, u \\rangle_2 = v_1 u_1 + v_2 u_2 + \\cdots + v_n u_n\\] (le produit scalaire est associée à la norme 2 \\(\\langle v, v \\rangle_2 = \\|v\\|_2^2\\))\nQuelques propriétés importantes du produit scalaire :\n\n\\(\\langle v, v \\rangle_2 = \\|v\\|_2^2 = \\sum_{i=1}^{n} v_i^2\\)\n\\(\\langle v, u \\rangle_2 = \\langle u, v \\rangle_2\\) (symétrie)\n\\(\\langle v, u \\rangle_2 &gt; 0\\) si \\(x\\) \\(0\\)\n\\(\\langle v, w \\rangle_2 = v^t w = \\text{trace}(vw^t)\\) - \\(\\langle v, w \\rangle_2 = \\langle w, v \\rangle_2\\)\n\nQuelques inégalités à connaître :\n\nInégalité de Cauchy-Schwarz : \\[|\\langle x, y \\rangle| \\leqslant \\|x\\| \\|y\\|\\]\nInégalité triangulaire : \\[\\|x + y\\| \\leqslant \\|x\\| + \\|y\\|\\]\n\n\n\n\nSoient \\(v\\) et \\(w\\), deux vecteurs appartenant à un espace vectoriel \\(E\\) de dimension \\(n\\), muni du produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\).\n\n\nLa normalisation d’un vecteur \\(v\\) est donnée par : \\[\nx = \\frac{v}{\\|v\\|_2}\n\\] Ainsi, \\(\\|v\\|_2 = 1\\).\nDeux vecteurs \\(v\\) et \\(u\\) sont orthogonaux si leur produit scalaire est nul : \\[\\langle v, u \\rangle = 0\\] et on note \\(v \\perp u\\)\n\n\n\n\nSoit \\(E\\) un espace vectoriel muni d’un produit scalaire \\(\\langle \\cdot, \\cdot \\rangle\\) et \\(W\\) un sous-espace vectoriel de \\(E\\). La projection orthogonale d’un élément \\(B\\) de \\(E\\) sur \\(W\\) est définie par : \\[\\Pi_W B = \\underset{a \\in W}{argmin} \\|B - a\\|_2\\] La matrice de projection orthogonale de \\(E\\) sur \\(W\\) est notée \\(\\Pi_W\\).\n\n\n\n\n\\(\\Pi_W^t = \\Pi_W\\)\n\\(\\Pi_W^2 = \\Pi_W\\)\n\\(\\text{trace}(\\Pi_W) = \\dim(\\Pi_W)\\)\n\\(\\Pi_W^\\perp = I_E - \\Pi_W\\)\n\nPour tout \\(B\\), élément de \\(E\\) : \\[\\Pi_{W^\\perp} B = B - \\Pi_{W} B\\]\n\n\n\n\nUne base \\(E\\) est un ensemble de vecteurs linéairement indépendants qui permet de décrire tous les vecteurs d’un espace (par combinaison linéaire). On note alors \\(E = \\text{Vect}(\\mathbf{v_1}, \\mathbf{v_2}, \\dots, \\mathbf{v_n})\\). Cette notation désigne l’ensemble de tous les vecteurs qui peuvent s’écrire comme une combinaison linéaire de \\(\\mathbf{v_1}, \\mathbf{v_2}, \\dots, \\mathbf{v_n}\\).\n\nSoient \\(v_1, \\ldots, v_p\\), \\(p\\) vecteurs de \\(\\mathbb{R}^n\\) avec \\(p \\leqslant n\\). Si \\((v_1, \\ldots, v_p)\\) est une base orthogonale de \\(\\mathbb{R}^p\\) et \\(\\text{W} = \\text{vect}(v_1, \\ldots, v_p)\\), alors la matrice de projection W de \\(\\mathbb{R}^n\\) sur W est : \\[\\text{W} = V (V^t V)^{-1} V^t\n\\] où \\(V\\) est la matrice dont les colonnes sont les vecteurs \\(v_1, \\ldots, v_p\\).\n\nSi \\((v_1, \\ldots, v_p)\\) est une base orthonormale de W, alors : \\[\n\\text{W} = V V^t\n\\]\n\n\n\nLe but du procédé de Gram-Schmidt est de prendre un ensemble de vecteurs linéairement indépendants \\(( {v_1, v_2, \\ldots, v_n})\\) et de produire un ensemble de vecteurs orthogonaux \\(( {u_1, u_2, \\ldots, u_n} )\\) qui engendrent le même sous-espace.\nÉtapes du Procédé\nLe premier vecteur orthogonal ( \\(u_1\\) ) est le premier vecteur de l’ensemble original : \\[u_1 = v_1\\]\nPour chaque vecteur \\(( v_k )\\) (où $ k $), on soustrait les projections orthogonales de \\(( v_k )\\) sur les vecteurs orthogonaux précédemment calculés \\(( u_1, u_2, \\ldots, u_{k-1})\\) : \\[ u_k = v_k - \\sum_{j=1}^{k-1} \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} u_j \\]\nSi l’on souhaite obtenir une base orthonormale, chaque vecteur \\(( u_k )\\) est normalisé pour obtenir \\(( e_k )\\) : \\[ e_k = \\frac{u_k}{||u_k||} \\]\n\n\n\n\n\nPour une base \\(\\{e_1, e_2, \\ldots, e_n\\}\\) d’un espace vectoriel \\(E\\), la base duale \\((e^1, e^2, \\ldots, e^n)\\) est définie par : \\[e^i(e_j) = \\delta_{ij}\\] où \\(\\delta_{ij}\\) est le symbole de Kronecker.\n\nLa base duale permet de définir des formes linéaires et de travailler avec des espaces vectoriels de manière plus abstraite.\nPour plus d’informations sur la base duale cliquez ici\n\n\n\n\nUne matrice carrée \\(A\\) est dite diagonalisable s’il existe une matrice diagonale \\(D\\) et une matrice inversible \\(P\\) telles que : \\[A = PDP^{-1}\\] \\(D\\) est une matrice diagonale contenant les valeurs propres de \\(A\\) et \\(P\\) est formé de vecteurs propres dans l’ordre des valeurs propres mis dans \\(D\\).\n\n\n\n\n\n\n\nTip\n\n\n\nSi les vecteurs propres sont normalisés alors \\(P^{-1} = P^t\\) et \\(A = PDP^t\\).\n\n\n\n\nPour les matrices symétriques réelles, on peut toujours trouver une base orthonormale de vecteurs propres, ce qui permet de les diagonaliser par une matrice orthogonale \\(Q\\) : \\[A = QDQ^T\\]"
  },
  {
    "objectID": "M1SEP.html#statistique-inférentielle",
    "href": "M1SEP.html#statistique-inférentielle",
    "title": "DATA Camp M1",
    "section": "Statistique inférentielle",
    "text": "Statistique inférentielle\n\nEchantillon / Estimateur\nLe point de départ est un vecteur (ou un tableau dans le cas multidimensionnel) de données. Ces données peuvent être vues comme les réalisations \\((x_1, x_2, \\ldots, x_n)\\) d’une variable aléatoire \\(X\\) qui dépend d’un certain paramètre \\(\\theta\\) que nous allons chercher à estimer. Pour ce faire, nous allons construire un échantillon de cette variable. Un échantillon \\((X_1, X_2, \\ldots, X_n)\\) est un n-uplet de variables aléatoires indépendantes qui suivent toutes la même loi (celle de \\(X\\)). Un estimateur de \\(\\theta\\) est une fonction \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) de notre échantillon, qui possède une loi de probabilité. Lorsque l’aléa est réalisé, \\(\\hat{\\theta}(\\omega) = f(x_1, x_2, \\ldots, x_n)\\) est une estimation de \\(\\theta\\). Le but de ce cours est de construire le meilleur estimateur possible de \\(\\theta\\).\n\n\nEstimateur sans biais\nPour que l’estimation soit bonne, il faut que \\(\\hat{\\theta}\\) soit proche de \\(\\theta\\). Comme \\(\\hat{\\theta} = f(X_1, X_2, \\ldots, X_n)\\) est une variable aléatoire, on ne peut imposer de condition qu’à sa valeur moyenne.\nOn définit ainsi le biais : \\[b_n(\\hat{\\theta}, \\theta) = \\mathbb{E}(\\hat{\\theta}_n) - \\theta\\]\nUn estimateur est dit sans biais si \\(b_n(\\hat{\\theta}, \\theta) = 0\\), c’est-à-dire : \\[\\mathbb{E}(\\hat{\\theta}_n) = \\theta\\]\nLe plus souvent, on veut estimer la moyenne et la variance.\n\nEstimations de la moyenne\nSoit un échantillon de variables aléatoires \\(X_1, X_2, \\dots, X_n\\) tirées d’une population avec une moyenne \\(\\mu = \\mathbb{E}[X_i]\\).\nLa moyenne empirique (ou moyenne d’échantillon) est définie par :\n\\[\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n\\]\nL’espérance de cet estimateur est :\n\\[\n\\mathbb{E}[\\hat{\\mu}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_i\\right] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[X_i] = \\mu\n\\]\nLa moyenne empirique est donc non biaisée. Son espérance est égale à la vraie moyenne de la population.\n\n\nEstimation de la variance\nSoit \\(X_1, X_2, \\dots, X_n\\) un échantillon de variables aléatoires \\(X_i\\) avec une variance \\(\\sigma^2 = \\mathbb{V}[X_i]\\).\nL’estimateur classique de la variance basé sur l’échantillon est :\n\\[\n\\hat{\\sigma}^2_{\\text{biaisé}} = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\hat{\\mu})^2\n\\]\nCependant, cet estimateur est biaisé. En effet, l’espérance de cet estimateur n’est pas égale à \\(\\sigma^2\\) :\n\\[\n\\mathbb{E}[\\hat{\\sigma}^2_{\\text{biaisé}}] = \\frac{n-1}{n} \\sigma^2\n\\]\nPour corriger ce biais, on peut utiliser un estimateur non biaisé de la variance. Cela se fait en divisant la somme des carrés par \\(n - 1\\) au lieu de \\(n\\). Ainsi, l’estimateur non biaisé de la variance est :\n\\[\n\\hat{\\sigma}^2_{\\text{non biaisé}} = \\frac{1}{n - 1} \\sum_{i=1}^{n} (X_i - \\hat{\\mu})^2\n\\]\nCet estimateur est non biaisé, et l’espérance de \\(\\hat{\\sigma}^2_{\\text{non biaisé}}\\) est égale à la vraie variance de la population :\n\\[\n\\mathbb{E}[\\hat{\\sigma}^2_{\\text{non biaisé}}] = \\sigma^2\n\\]\n\n\n\nEstimateur convergent\nUn estimateur est dit convergent s’il converge en probabilité vers le paramètre à estimer : \\[\\hat{\\theta}_n \\xrightarrow{P} \\theta\\]\nEn pratique, tout estimateur sans biais et dont la variance tend vers 0 est convergent.\n\n\nEstimateur optimal\nLa qualité d’un estimateur est mesurée à travers son erreur quadratique moyenne définie par : \\[EQM(\\hat{\\theta}_n) = (b_n(\\hat{\\theta}, \\theta))^2 + V(\\hat{\\theta}_n)\\] Comme nous cherchons tout le temps (presque) des estimateurs sans biais, il reste à comparer les variances.\nUn estimateur 𝜃̂1 est meilleur que 𝜃̂2 si : \\[V(\\hat{\\theta}_1) &lt; V(\\hat{\\theta}_2)\\]\n\nOn définit la quantité d’information apportée par l’estimateur par : \\[\nI(\\hat{\\theta}_n) = -\\left( \\mathbb{E} \\left( \\frac{\\partial L}{\\partial \\theta} \\right) \\right)^2\n\\] Où 𝐿(𝑥, 𝜃) = ∏ 𝑓(𝑥𝑖) (nous reviendrons sur sa définition)\nL’inégalité de Rao-Cramer postule que la variance d’un estimateur ne peut pas aller en delà d’un certain seuil : \\[V(\\hat{\\theta}_n) \\geqslant \\frac{1}{I(\\hat{\\theta}_n)}\\] Un estimateur est optimal (ou efficace) si sa variance vérifie le cas d’égalité.\n\n\nConstruction d’un estimateur\nUn estimateur est une valeur qu’on ne peut pas obtenir en théorie donc on essaye de l’estimer. Par exemple, on ne peut pas calculer l’espérence d’une série de données et donc pour essayer d’obtenir une valeur on calculer une estimation. On recours à plusieurs estimateurs tels que le maximum de vraisemblance ou bien la méthode des moments.\n\n\n\n\n\n\nNote\n\n\n\nLa méthode du maximum de vraisemblance est la plus souvent utilisé dans les modèles de prédiction.\n\n\n\nLa méthode du maximum de vraisemblance consiste à affecter \\(𝜃\\) la valeur qui maximise la probabilité d’observer \\((𝑥_1, 𝑥_2, … , 𝑥_𝑛)\\) lorsque l’aléa du vecteur \\((𝑋_1, 𝑋_2, … , 𝑋_𝑛)\\) tombe. Sans trop rentrer dans la théorie de la vraisemblance, nous allons présenter un algorithme en cinq étapes pour calculer cet estimateur :\n\nEtape 1 : Calculer la fonction de vraisemblance\nDans le cas continu : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} f(x_i)\\]\nDans le cas discret : \\[L(\\mathbf{x}, \\theta) = \\prod_{i=1}^{n} P(X_i = x_i)\\]\nEtape 2 : Calculer le log-vraisemblance Il s’agit de calculer un maximum, ce qui revient à dériver. Il s’agit ici d’un produit de n facteurs, ce qui rend la dérivation assez coriace. La fonction logarithmique présente des propriétés assez sympas pour faciliter cette tâche.\nEtape 3 : Calculer la dérivée de la log-vraisemblance\nEtape 4 : Résoudre l’équation d’inconnue \\(𝜽\\)} \\[\\frac{\\partial (\\ln(L))}{\\partial \\theta} = 0 \\Rightarrow \\theta = \\theta_0\\]\nEtape 5: Vérifier qu’il s’agit d’un maximum.\nEn s’assurant que : \\[\\frac{\\partial^2 (\\ln(L))}{\\partial \\theta^2} &lt; 0\\]\n\nLa méthode des moments consiste à égaliser les moments théoriques (espérance, variance) à leurs équivalents empiriques et à en dégager une estimation ponctuelle.\n\nEn pratique, il faut résoudre l’(les) équation(s) : \\[\\mathbb{E}(X) = \\overline{X} \\text{ et } \\text{Var}(X) = S_n^2\\] avec : \\[\\overline{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\hspace{2cm}\nS_n^2 = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\overline{X})^2\\]\nIl existe une autre méthode d’estimateurs qu’est la méthode des moindres carrés ordinaires.\n\nLorsqu’il s’agit de prendre une mesure 𝜃 avec un appareil doté d’une imprécision \\(𝜀\\), alors le problème d’estimation peut s’écrire : \\(𝑋 = 𝜃 + 𝜀\\). La méthode des moindres-carrés ordinaires consiste à trouver le paramètre \\(𝜃\\) qui minimise la somme des carrées des erreurs : \\[𝜃_{𝑀𝐶𝑂} = \\arg\\min \\left( \\sum_{i=0}^n \\varepsilon_i^2 \\right) = \\arg\\min \\left( \\sum_{i=0}^n (X_i - \\theta)^2 \\right)\\]\n\n\n\nIntervalles de confiance\nUn intervalle de confiance [\\(A\\), \\(B\\)] de niveau \\(1 - \\alpha\\) est un intervalle aléatoire qui a la probabilité \\(1 - \\alpha\\) de contenir le paramètre à estimer \\(\\theta\\). Formellement, on écrit : \\(P (t_1 (\\theta) \\leqslant f(X_1, \\ldots, X_n) \\leqslant t_2 (\\theta)) = P(A \\leqslant \\theta \\leqslant B) = 1 - \\alpha\\)\n\n\nTest d’hypothèses\nDans le cadre d’un test d’hypothèse, nous cherchons à faire valoir une hypothèse en dépit d’une autre, qui lui est contradictoire.\nOn appellera la première (celle dont le rejet à tort sera le plus préjudiciable) « Hypothèse nulle » et la deuxième « Hypothèse alternative ».\n\n\n\n\n\nLes calculs qui se cachent derrière le choix de l’hypothèse à garder sont compliqués. Mais BONNE NOUVELLE, la machine fera tour à notre place. Il suffit juste de suivre correctement la méthode :\nEtape 1 : Choisir judicieusement les hypothèses à évaluer et fixer le risque \\(𝛼\\)\nEtape 2 : Choisir le test adapté à la procédure\nEtape 3 : Rentrer la commande correspondante sur R et exécuter\nEtape 4: Lire dans les sorties la p-value. si elle est supérieure à α on conserve l’hypothèse nulle H0. Si elle lui est inférieure, on rejette H0 et on accepte l’hypothèse alternative H1.\n\n\nConstruction d’intervalles de confiance\nLes intervalles de confiance sont des outils essentiels en statistique pour estimer des paramètres inconnus tout en mesurant l’incertitude associée à cette estimation. Ci-dessous, vous trouverez un tableau présentant la construction des intervalles de confiance pour différents paramètres."
  }
]